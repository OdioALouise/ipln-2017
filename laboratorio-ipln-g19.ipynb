{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pln1.png)\n",
    "![title](imagenes/pdf/pln2.png)\n",
    "![title](imagenes/pdf/pln3.png)\n",
    "![title](imagenes/pdf/pln4.png)\n",
    "![title](imagenes/pdf/pln5.png)\n",
    "![title](imagenes/pdf/pln6.png)\n",
    "![title](imagenes/pdf/pln7.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de votos 26943\n",
      "No humor, votos 14131  porcentaje  52.4477600861\n",
      "Humor 1 estrella, votos  2960  porcentaje  10.9861559589\n",
      "Humor 2 estrellas, votos  2421  porcentaje  8.98563634339\n",
      "Humor 3 estrellas, votos  3274  porcentaje  12.1515792599\n",
      "Humor 4 estrellas, votos  2541  porcentaje  9.43102104443\n",
      "Humor 5 estrellas, votos  1616  porcentaje  5.99784730728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sebastiandaloia/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTACION Cantidad de votos por calificacion, promedio de estrellas, fraccion de votos de humor\n",
    "\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "fraccion_votos_humor = (total - no_humor)/total\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total de votos\", total)\n",
    "print(\"No humor, votos\", no_humor,\" porcentaje \", no_humor/total*100)\n",
    "print(\"Humor 1 estrella, votos \", humor_e1, \" porcentaje \", humor_e1/total*100)\n",
    "print(\"Humor 2 estrellas, votos \", humor_e2, \" porcentaje \", humor_e2/total*100)\n",
    "print(\"Humor 3 estrellas, votos \", humor_e3, \" porcentaje \", humor_e3/total*100)\n",
    "print(\"Humor 4 estrellas, votos \", humor_e4, \" porcentaje \", humor_e4/total*100)\n",
    "print(\"Humor 5 estrellas, votos \", humor_e5, \" porcentaje \", humor_e5/total*100)\n",
    "print(\"Promedio de estrellas PV \", promedio_estrellas_pv) \n",
    "print(\"Promedio de estrellas PVP \", promedio_estrellas_pvp)\n",
    "print(\"Fracción votos de humor\", fraccion_votos_humor)\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sebastiandaloia', api_key='cMoSSDnwQHyafA8prIEv')\n",
    "\n",
    "\n",
    "\n",
    "#Impresion de valores usando ploly\n",
    "labels = ['No humor','1 Estrella','2 Estrellas','3 Estrellas', '4 Estrellas', '5 Estrellas']\n",
    "values = [no_humor, humor_e1, humor_e2, humor_e3, humor_e4, humor_e5]\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "plotly.plotly.iplot([trace], filename='basic_pie_chart')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pln8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets  12106\n",
      "Los tweets mas votados tienen  21 votos\n",
      "Los tweets con dos o menos votos forman un total de  8668\n",
      "Los chistes mas graciosos son\n",
      "1 \n",
      " —¿A dónde vas tan maquillada? —A una fiesta, mamá. —¿Eres el payaso? —¡MAMÁAAA! :( —JAJAJÁ, cállate y hazme reír o no vas. —Ok. :(\n",
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~sebastiandaloia/0 or inside your plot.ly account where it is named 'mpl-basic-histogram'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~sebastiandaloia/0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTACION Cantidad de votos por tweet\n",
    "#Vectores\n",
    "vec_ids=corpus['id'][:]\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "#Variables\n",
    "cant_tweets=len(corpus)\n",
    "\n",
    "print(\"Cantidad de tweets \", cant_tweets)\n",
    "\n",
    "tweet_id_vot=np.zeros((cant_tweets, 2), np.int64)\n",
    "\n",
    "contador=0\n",
    "for i in range(0, cant_tweets):\n",
    "    tweet_id_vot[i, 0]=vec_ids[i]\n",
    "    tweet_id_vot[i,1]=vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i]\n",
    "\n",
    "\n",
    "array=tweet_id_vot[:,1]\n",
    "array=np.sort(array, axis=None)\n",
    "last=array[len(array) - 1]\n",
    "\n",
    "lesseq_3=0\n",
    "for i in range(0, cant_tweets):\n",
    "    if( array[i] > 2 ):\n",
    "        break;\n",
    "    lesseq_3+=1\n",
    "\n",
    "print(\"Los tweets mas votados tienen \", last, \"votos\")\n",
    "print(\"Los tweets con dos o menos votos forman un total de \", lesseq_3)\n",
    "\n",
    "contador=1\n",
    "print(\"Los chistes mas graciosos son\")\n",
    "for i in range(0, cant_tweets):\n",
    "    if( vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] == 21 ):\n",
    "        print(contador, \"\\n\", corpus['text'][i])\n",
    "\n",
    "plotly.tools.set_credentials_file(username='sebastiandaloia', api_key='cMoSSDnwQHyafA8prIEv')\n",
    "\n",
    "votos_nums = tweet_id_vot[:,1]\n",
    "\n",
    "plt.hist(votos_nums)\n",
    "plt.title(\"Histograma de votos por tweet\")\n",
    "plt.xlabel(\"Votos\")\n",
    "plt.ylabel(\"Tweets\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "plotly.plotly.plot_mpl(fig, filename='mpl-basic-histogram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fracción votos de humor 0.475522399139\n"
     ]
    }
   ],
   "source": [
    "#iMPLEMENTACION Fraccion de votos de humor\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "fraccion_votos_humor = (total - no_humor)/total\n",
    "\n",
    "print(\"Fracción votos de humor\", fraccion_votos_humor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pln9.png)\n",
    "![title](imagenes/pdf/pln10.png)\n",
    "![title](imagenes/pdf/pln11.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de estrellas PV  1.3312548714\n",
      "Promedio de estrellas PVP  2.79956290977\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION Promedio de estrellas\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "print(\"Promedio de estrellas PV \", promedio_estrellas_pv) \n",
    "print(\"Promedio de estrellas PVP \", promedio_estrellas_pvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los chistes mas graciosos son: \n",
      "1  - PV : 4.75 votos:  4\n",
      "   -Mamá tuvimos un examen sorpresa en la escuela - ¿Y que pasó hijo? -Estuve muy sorprendido mamá.\n",
      "2  - PV : 4.5 votos:  4\n",
      "   ¿Cómo se llama la secretaria de Batman? Bati la fea... #chistes #fb\n",
      "3  - PV : 4.5 votos:  4\n",
      "   Quedarse atrapado en la esquina de la ducha porque el agua sale muy fría.\n",
      "4  - PV : 4.4 votos:  5\n",
      "   —Amor, ¿Ya está dentro? —Sí ¿Te lastima? —Sí amor, mételo despacito, duele cuando entra. —Ok, vamos a intentar otro número de zapato :)\n",
      "5  - PV : 4.25 votos:  4\n",
      "   —Violarte es mi sueño —¿QUÉ? —Que estudio diseño —No, ¡ahora me violas!\n",
      "6  - PV : 4.25 votos:  4\n",
      "   — ¡Profe! ¿Puedo ir al baño?. *Regresa con comida*.\n",
      "7  - PV : 4.25 votos:  4\n",
      "   Las mujeres de hoy en día con tal de no hacer limpieza en la casa, se inventan que les gusta el fútbol.\n",
      "8  - PV : 4.25 votos:  4\n",
      "   Siempre será mejor hablar en clases que en el recreo.\n",
      "9  - PV : 4.25 votos:  4\n",
      "   Lunes Martes Miércoles Jueves Casi Sábado Sábado Casi Lunes.\n",
      "10  - PV : 4.25 votos:  4\n",
      "   Todo es comestible hasta que la diarrea demuestre lo contrario...\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTACION Mejores chistes:\n",
    "# 1: Para ser considerados deben tener al menos 3 votos en total 1 de ellos debe ser de humor.\n",
    "# 2: Entre los candidatos los mas graciosos seran los que tengan mejor promedio de estrellas y entre estos los de mas votos.\n",
    "# 3: Se listan los mejores 10 chistes, esto puede cambiarse cambiando el valor de cantidad_mejores_chistes.\n",
    "mejores_chistes = np.array([])\n",
    "cant_votos = []\n",
    "prom_estrellas_pv = []\n",
    "votos_humor = []\n",
    "minimo_votos = 3\n",
    "cantidad_mejores_chistes = 10\n",
    "#Variables\n",
    "cant_tweets=len(corpus)\n",
    "for i in range(0, cant_tweets):\n",
    "    votos_humor.append(vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i])\n",
    "    cant_votos.append(vec_no_humor[i] + votos_humor[i])\n",
    "    prom_estrellas_pv.append((vec_e1[i] + 2*vec_e2[i] + 3*vec_e3[i] + 4*vec_e4[i] + 5*vec_e5[i])/cant_votos[i])\n",
    "    \n",
    "    #debe tener la cantidad de votos necesaria y almenos un voto de humor para ser considerado\n",
    "    if( cant_votos[i] > minimo_votos and votos_humor[i] > 0 ): \n",
    "        #solo se mostraran los 5 mejores chistes.\n",
    "        chiste = np.array([corpus['text'][i], prom_estrellas_pv[i], cant_votos[i]])\n",
    "        if (len(mejores_chistes) > 0):\n",
    "            mejores_chistes = np.vstack((mejores_chistes, chiste))\n",
    "        else :\n",
    "            mejores_chistes = np.append(mejores_chistes, chiste)\n",
    "   \n",
    "print(\"\")\n",
    "print(\"Los chistes mas graciosos son: \")\n",
    "\n",
    "ind = np.lexsort((mejores_chistes[:,2],mejores_chistes[:,1]))\n",
    "for i in range(0, cantidad_mejores_chistes):\n",
    "    j = len(mejores_chistes) - i - 1\n",
    "    print(i+1, \" - PV :\",mejores_chistes[ind][j][1], \"votos: \", mejores_chistes[ind][j][2])\n",
    "    print(\"  \", mejores_chistes[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negación general:  2.440800988551316\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION Negatividad\n",
    "pattern_tag = re.compile(r'lemma=\"(no?)\"')\n",
    "\n",
    "tam=len(corpus)\n",
    "total_no=0;\n",
    "total_token=0\n",
    "pos=0\n",
    "for i in np.random.randint(0, tam, 1000):\n",
    "    text = corpus['text'][i]\n",
    "    tweet_token=0\n",
    "    token_no=0\n",
    "    xml = analyzer.run(text.encode(), 'flush')\n",
    "    for sentence in xml:\n",
    "        for token in sentence: \n",
    "            tweet_token+=1\n",
    "            m = re.search(pattern_tag, etree.tostring(token).decode())\n",
    "            if m :\n",
    "                token_no+=1\n",
    "    pos+=1\n",
    "    print(\"Tweet numero \", pos,  end=\"\\r\")\n",
    "    time.sleep(1)\n",
    "             \n",
    "        \n",
    "    total_no+=token_no    \n",
    "    total_token+=tweet_token\n",
    "        \n",
    "print(\"Negación general: \", total_no/math.sqrt(total_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de links encontrados  3280\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION cantidad de links\n",
    "\n",
    "pattern_http = re.compile(r'http://')\n",
    "\n",
    "num_links=0\n",
    "\n",
    "for text in corpus['text'][:]:\n",
    "    result = pattern_http.findall(text) \n",
    "    num_links+=len(result)\n",
    "\n",
    "print(\"Cantidad de links encontrados \", num_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana primera persona  0.0\n",
      "Mediana segunda persona  0.0\n",
      "Media primera persona  0.183470578311\n",
      "Media segunda persona  0.16683360628\n",
      "[0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 0.48507125007266594, 0.45883146774112349, 0.23570226039551587, 0.0, 0.0, 1.0606601717798212, 0.0, 0.15075567228888181, 0.75, 0.45883146774112349, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.17677669529663687, 0.0, 0.0, 0.24253562503633297, 0.2581988897471611, 1.1470786693528088, 0.0, 0.0, 0.0, 0.3481553119113957, 0.0, 0.0, 0.0, 0.0, 0.87287156094396956, 0.18257418583505536, 0.3481553119113957, 0.0, 0.17677669529663687, 0.18257418583505536, 0.0, 0.48507125007266594, 1.2060453783110545, 0.40000000000000002, 0.41702882811414954, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.0, 1.0, 0.55470019622522915, 0.0, 1.0206207261596576, 0.40824829046386307, 0.60302268915552726, 0.16666666666666666, 0.54772255750516607, 0.0, 0.39223227027636809, 0.30151134457776363, 0.59999999999999998, 0.2581988897471611, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.47140452079103173, 0.0, 0.25, 0.0, 0.0, 0.2581988897471611, 0.34299717028501764, 0.5, 0.0, 0.43643578047198478, 0.31622776601683794, 0.20851441405707477, 0.0, 0.5388159060803247, 0.0, 0.0, 0.0, 0.0, 0.6546536707079772, 0.0, 1.0776318121606494, 0.0, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.36514837167011072, 0.63245553203367588, 1.0206207261596576, 0.0, 0.0, 0.1889822365046136, 0.32879797461071458, 0.0, 0.0, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.81649658092772615, 0.0, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38490017945975052, 0.17960530202677491, 0.70710678118654746, 0.0, 0.17149858514250882, 0.58834840541455213, 0.17407765595569785, 0.1690308509457033, 0.0, 0.0, 0.15430334996209191, 0.24253562503633297, 0.48507125007266594, 0.25, 0.0, 0.1690308509457033, 0.57735026918962584, 0.0, 0.20851441405707477, 0.0, 0.17407765595569785, 0.28867513459481292, 0.0, 0.0, 0.0, 0.60302268915552726, 0.5303300858899106, 0.0, 0.19611613513818404, 0.19611613513818404, 0.47140452079103173, 0.0, 0.0, 0.0, 0.42640143271122083, 0.0, 0.21821789023599239, 0.37139067635410372, 0.0, 0.0, 0.46852128566581819, 0.0, 0.0, 0.0, 0.35355339059327373, 0.0, 0.18569533817705186, 0.45883146774112349, 0.76980035891950105, 0.63960214906683133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.0, 0.51449575542752646, 0.0, 0.0, 0.0, 0.31234752377721214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.19245008972987526, 0.0, 0.0, 0.68599434057003528, 1.212678125181665, 0.47140452079103173, 0.0, 0.0, 0.37139067635410372, 0.0, 0.42640143271122083, 0.24253562503633297, 0.70710678118654757, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.0, 0.0, 0.67082039324993692, 0.0, 0.0, 0.0, 0.0, 0.7559289460184544, 0.0, 0.34299717028501764, 0.0, 0.0, 0.0, 0.55708601453115558, 0.0, 0.0, 0.1889822365046136, 0.0, 0.48507125007266594, 0.31622776601683794, 0.49319696191607187, 0.0, 0.0, 0.68599434057003528, 0.0, 0.0, 0.17407765595569785, 0.38490017945975052, 0.17677669529663687, 0.0, 0.0, 0.21821789023599239, 0.0, 0.73029674334022143, 0.17149858514250882, 0.0, 0.5, 0.21821789023599239, 0.0, 0.20851441405707477, 0.0, 0.25, 0.67082039324993692, 0.0, 0.36514837167011072, 0.54772255750516607, 0.0, 0.66666666666666663, 0.0, 0.0, 0.53452248382484879, 0.0, 0.44721359549995793, 0.0, 0.21821789023599239, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 1.0660035817780522, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.94491118252306805, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.21320071635561041, 0.23570226039551587, 0.0, 0.6546536707079772, 0.0, 0.73029674334022143, 0.17960530202677491, 0.0, 0.20412414523193154, 1.0, 0.0, 0.0, 1.1094003924504583, 0.0, 0.83205029433784372, 0.0, 0.23570226039551587, 0.0, 0.72760687510899891, 0.76980035891950105, 0.0, 0.0, 0.0, 0.75, 0.0, 0.34299717028501764, 0.20000000000000001, 0.30151134457776363, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.39223227027636809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.0, 0.73029674334022143, 0.0, 0.0, 0.17960530202677491, 0.28867513459481292, 0.0, 0.0, 0.5, 0.0, 0.47140452079103173, 0.0, 0.15617376188860607, 0.35355339059327373, 0.0, 0.21320071635561041, 0.0, 0.2672612419124244, 0.0, 0.57735026918962584, 0.0, 0.21821789023599239, 0.41702882811414954, 0.0, 0.35921060405354982, 0.2581988897471611, 0.0, 0.42640143271122083, 0.0, 0.18257418583505536, 0.48507125007266594, 0.0, 0.39223227027636809, 0.0, 0.35921060405354982, 0.0, 0.44721359549995793, 0.0, 0.20000000000000001, 0.0, 0.22941573387056174, 0.44721359549995793, 0.0, 0.20000000000000001, 0.0, 0.22941573387056174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.24253562503633297, 0.40824829046386307, 0.0, 0.28867513459481292, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 0.17960530202677491, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.17960530202677491, 0.0, 0.0, 0.21821789023599239, 0.72760687510899891, 0.0, 0.59999999999999998, 0.0, 0.24253562503633297, 0.40000000000000002, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.21821789023599239, 0.56694670951384085, 0.0, 0.0, 1.1094003924504583, 0.0, 0.5222329678670935, 0.37139067635410372, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.21821789023599239, 0.0, 0.14744195615489714, 0.0, 0.82199493652678646, 0.0, 0.0, 0.0, 0.98058067569092022, 0.0, 0.16439898730535729, 0.20412414523193154, 0.0, 0.1889822365046136, 0.0, 0.19611613513818404, 0.35921060405354982, 0.50709255283710997, 0.20851441405707477, 0.17149858514250882, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.19245008972987526, 0.0, 0.59999999999999998, 0.32444284226152509, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.70710678118654746, 0.0, 0.0, 0.0, 0.88388347648318433, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.0, 0.51449575542752646, 0.0, 0.27735009811261457, 0.22941573387056174, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 1.150792911137501, 0.43643578047198478, 1.1094003924504583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 0.0, 0.76980035891950105, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.47140452079103173, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.31622776601683794, 0.5388159060803247, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19245008972987526, 0.1889822365046136, 0.0, 0.17960530202677491, 1.0776318121606494, 0.0, 0.21320071635561041, 0.33333333333333331, 0.0, 0.67082039324993692, 0.20412414523193154, 0.0, 0.0, 0.0, 0.7745966692414834, 0.0, 0.0, 1.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.17149858514250882, 0.0, 0.48038446141526137, 0.0, 0.0, 0.2581988897471611, 0.17407765595569785, 0.20000000000000001, 0.42640143271122083, 0.72760687510899891, 0.0, 0.0, 0.0, 0.75, 0.17960530202677491, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.63960214906683133, 0.0, 0.0, 0.36514837167011072, 0.0, 0.72760687510899891, 0.0, 0.0, 0.0, 0.40000000000000002, 0.5303300858899106, 0.0, 0.47140452079103173, 0.5303300858899106, 0.49319696191607187, 0.27735009811261457, 0.0, 0.0, 0.0, 0.43643578047198478, 0.18257418583505536, 0.0, 0.44721359549995793, 0.0, 0.17677669529663687, 0.35921060405354982, 0.28867513459481292, 0.2672612419124244, 0.0, 0.6546536707079772, 0.0, 0.16666666666666666, 0.0, 0.0, 0.28867513459481292, 0.48507125007266594, 0.68599434057003528, 0.17407765595569785, 0.0, 0.2581988897471611, 0.41702882811414954, 0.0, 0.0, 0.0, 0.98058067569092022, 0.73029674334022143, 0.30151134457776363, 0.0, 0.0, 0.21821789023599239, 0.1889822365046136, 0.2672612419124244, 0.0, 0.0, 1.0606601717798212, 0.53452248382484879, 0.0, 0.18569533817705186, 0.68824720161168518, 0.2672612419124244, 0.0, 0.16666666666666666, 0.22360679774997896, 1.044465935734187, 0.20851441405707477, 0.0, 0.0, 0.37139067635410372, 0.0, 0.44721359549995793, 0.0, 0.37139067635410372, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 0.0, 1.386750490563073, 0.0, 0.0, 0.0, 0.64888568452305018, 0.35355339059327373, 0.0, 0.0, 0.13867504905630729, 0.0, 0.0, 0.0, 0.40824829046386307, 0.18569533817705186, 0.0, 0.0, 0.0, 0.16222142113076254, 0.0, 0.68824720161168518, 0.0, 0.0, 1.0327955589886444, 0.0, 0.0, 0.0, 0.20851441405707477, 0.0, 0.21320071635561041, 0.0, 0.0, 0.8703882797784892, 0.0, 0.27735009811261457, 0.0, 0.18569533817705186, 0.0, 0.0, 0.19611613513818404, 0.5388159060803247, 0.88388347648318433, 0.0, 0.50709255283710997, 0.16666666666666666, 0.80000000000000004, 0.0, 0.46291004988627571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22941573387056174, 0.35355339059327373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.76980035891950105, 0.0, 0.58834840541455213, 0.3481553119113957, 0.2672612419124244, 0.34299717028501764, 0.35921060405354982, 0.0, 0.42640143271122083, 0.0, 0.0, 0.0, 0.55708601453115558, 0.41702882811414954, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55708601453115558, 0.19245008972987526, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.94491118252306805, 0.0, 0.0, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 1.044465935734187, 0.0, 0.0, 0.0, 0.5303300858899106, 0.0, 0.0, 0.0, 0.2581988897471611, 0.0, 0.55708601453115558, 0.36514837167011072, 0.0, 0.0, 0.38490017945975052, 0.0, 0.0, 0.22941573387056174, 0.58834840541455213, 0.23570226039551587, 0.63245553203367588, 0.0, 0.16439898730535729, 0.0, 0.0, 0.3779644730092272, 0.76980035891950105, 0.0, 0.44721359549995793, 0.0, 0.0, 0.50709255283710997, 0.0, 0.68824720161168518, 0.2581988897471611, 0.32444284226152509, 0.0, 0.28867513459481292, 0.0, 0.17407765595569785, 0.17960530202677491, 0.0, 0.51449575542752646, 0.21821789023599239, 0.78446454055273618, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.18257418583505536, 0.17407765595569785, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.40824829046386307, 0.0, 0.0, 0.0, 0.34299717028501764, 0.0, 0.60302268915552726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48507125007266594, 0.19245008972987526, 0.20000000000000001, 0.18257418583505536, 0.0, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.30499714066520933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.21821789023599239, 0.39223227027636809, 0.40824829046386307, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.31622776601683794, 0.0, 0.0, 0.24253562503633297, 0.5, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.0, 0.0, 0.0, 0.7745966692414834, 0.31622776601683794, 0.37139067635410372, 0.0, 0.57735026918962584, 0.0, 0.0, 0.0, 0.6546536707079772, 0.0, 0.97014250014533188, 0.29814239699997197, 0.81649658092772615, 0.44721359549995793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68824720161168518, 0.18257418583505536, 0.40824829046386307, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.40824829046386307, 0.19611613513818404, 0.0, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.28867513459481292, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.40000000000000002, 0.2672612419124244, 0.91766293548224698, 0.94491118252306805, 0.0, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.54772255750516607, 0.0, 0.0, 0.0, 0.48666426339228763, 0.20000000000000001, 0.0, 0.0, 0.24253562503633297, 0.0, 0.0, 0.22360679774997896, 0.2581988897471611, 0.38490017945975052, 0.48507125007266594, 0.5, 0.22941573387056174, 0.0, 0.49319696191607187, 0.22941573387056174, 0.37139067635410372, 0.0, 0.0, 0.21320071635561041, 0.2672612419124244, 0.0, 0.0, 0.0, 0.0, 0.28867513459481292, 0.40000000000000002, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.55470019622522915, 0.40824829046386307, 0.75, 0.0, 0.24253562503633297, 0.45883146774112349, 0.0, 0.19245008972987526, 0.33806170189140661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.53452248382484879, 0.94280904158206347, 0.0, 0.0, 0.24253562503633297, 0.3481553119113957, 0.72760687510899891, 0.45883146774112349, 0.23570226039551587, 0.0, 0.0, 0.0, 0.0, 0.90453403373329089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61237243569579458, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.25, 0.0, 0.3481553119113957, 0.20412414523193154, 0.31622776601683794, 0.80178372573727319, 0.0, 0.0, 0.36514837167011072, 0.0, 0.0, 0.17677669529663687, 0.18257418583505536, 0.50709255283710997, 0.0, 0.0, 0.40000000000000002, 0.0, 0.23570226039551587, 0.57735026918962573, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 1.1666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.73029674334022143, 0.0, 0.39223227027636809, 0.0, 0.80000000000000004, 0.2581988897471611, 1.2374368670764582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.0, 0.2581988897471611, 0.17149858514250882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 0.0, 0.45883146774112349, 0.35921060405354982, 0.2581988897471611, 0.0, 0.20851441405707477, 0.39223227027636809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.23570226039551587, 0.0, 0.54772255750516607, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.0, 0.75, 0.48507125007266594, 0.0, 0.91766293548224698, 0.0, 0.0, 0.24253562503633297, 0.0, 0.83205029433784372, 0.0, 0.30151134457776363, 0.0, 0.0, 0.24253562503633297, 0.0, 0.47140452079103173, 0.0, 0.0, 0.0, 0.19245008972987526, 0.35921060405354982, 0.17677669529663687, 0.60302268915552726, 0.0, 0.78446454055273618, 0.17407765595569785, 0.1690308509457033, 0.0, 0.45883146774112349, 0.61721339984836765, 0.24253562503633297, 0.0, 0.0, 0.0, 0.50709255283710997, 0.0, 0.0, 0.0, 0.0, 0.3481553119113957, 0.0, 0.54772255750516607, 0.72760687510899891, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.19611613513818404, 0.23570226039551587, 0.0, 0.0, 0.47140452079103173, 0.0, 0.47140452079103173, 0.21821789023599239, 0.37139067635410372, 0.0, 0.0, 0.62469504755442429, 0.0, 0.0, 0.0, 0.0, 0.33333333333333331, 0.18569533817705186, 0.22941573387056174, 0.0, 0.21320071635561041, 0.20851441405707477, 0.0, 0.19245008972987526, 0.0, 0.0, 0.53452248382484879, 0.20000000000000001, 0.0, 0.0, 0.0, 0.68599434057003528, 0.0, 0.0, 0.0, 0.46852128566581819, 0.0, 0.0, 0.17149858514250882, 0.36514837167011072, 0.0, 0.0, 0.38490017945975052, 0.0, 0.42640143271122083, 0.34299717028501764, 0.0, 0.47140452079103173, 0.0, 0.18257418583505536, 0.18569533817705186, 0.23570226039551587, 0.0, 0.0, 0.47140452079103173, 0.38490017945975052, 0.0, 0.0, 0.16439898730535729, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.89442719099991586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.51449575542752646, 0.43643578047198478, 0.57735026918962584, 1.1180339887498949, 0.74278135270820744, 0.0, 0.0, 0.56694670951384085, 0.0, 0.0, 0.0, 0.32879797461071458, 0.0, 0.0, 0.0, 0.68824720161168518, 0.0, 0.0, 0.57735026918962573, 0.35355339059327373, 0.27735009811261457, 0.0, 0.0, 0.0, 0.0, 0.17149858514250882, 0.0, 0.25, 0.0, 0.43643578047198478, 0.0, 0.72760687510899891, 0.0, 0.0, 0.76980035891950105, 0.36514837167011072, 0.36514837167011072, 0.0, 0.0, 1.2510864843424487, 0.0, 0.80178372573727319, 1.0425720702853738, 0.0, 0.0, 0.43643578047198478, 0.17407765595569785, 0.5, 0.60302268915552726, 0.0, 0.0, 0.17407765595569785, 0.0, 0.1889822365046136, 0.78446454055273618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.5388159060803247, 0.0, 0.20412414523193154, 0.0, 0.5163977794943222, 0.0, 0.0, 0.83405765622829908, 0.0, 0.0, 0.0, 0.22360679774997896, 0.48507125007266594, 0.38490017945975052, 0.63960214906683133, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.60302268915552726, 0.18569533817705186, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.1889822365046136, 0.0, 0.0, 0.80178372573727319, 0.44721359549995793, 0.81649658092772615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17960530202677491, 0.0, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.31234752377721214, 0.0, 0.0, 0.0, 0.0, 0.80178372573727319, 0.0, 0.57735026918962584, 0.0, 0.43643578047198478, 0.0, 0.0, 0.35921060405354982, 0.5163977794943222, 0.28867513459481292, 0.63960214906683133, 0.0, 0.0, 0.24253562503633297, 0.44721359549995793, 0.0, 0.31622776601683794, 0.0, 0.48507125007266594, 0.0, 0.0, 0.40000000000000002, 0.0, 0.22941573387056174, 0.0, 0.97014250014533188, 0.0, 0.19245008972987526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.20412414523193154, 0.20412414523193154, 0.57735026918962584, 0.45883146774112349, 0.18569533817705186, 0.28867513459481292, 0.5222329678670935, 0.0, 0.5388159060803247, 0.0, 0.7745966692414834, 0.0, 0.68824720161168518, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.0, 0.24253562503633297, 0.40000000000000002, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74278135270820744, 0.0, 0.0, 0.0, 0.57735026918962584, 0.0, 0.0, 0.45883146774112349, 0.88465173692938281, 0.0, 1.150792911137501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 0.20851441405707477, 0.34299717028501764, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.39223227027636809, 0.48507125007266594, 0.5303300858899106, 0.0, 0.38490017945975052, 0.63960214906683133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.44721359549995793, 0.0, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.53452248382484879, 0.35921060405354982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.21821789023599239, 0.0, 0.0, 0.0, 0.33806170189140661, 0.98639392383214375, 0.21821789023599239, 0.0, 0.0, 0.0, 0.2581988897471611, 0.0, 0.86602540378443871, 0.33806170189140661, 0.0, 0.38490017945975052, 0.72760687510899891, 0.21821789023599239, 0.53452248382484879, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.0, 0.18257418583505536, 0.31622776601683794, 0.0, 0.0, 0.38490017945975052, 0.0, 0.3481553119113957, 0.0, 0.2581988897471611, 0.1690308509457033, 0.0, 0.0, 0.19245008972987526, 0.0, 0.36514837167011072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61237243569579458, 0.0, 0.0, 0.42640143271122083, 0.0, 0.20000000000000001, 0.22360679774997896, 0.40000000000000002, 0.60302268915552726, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.16012815380508713, 0.48507125007266594, 0.0, 0.0, 0.3481553119113957, 0.0, 0.42640143271122083, 0.0, 0.0, 0.20000000000000001, 0.78446454055273618, 0.0, 0.71842120810709964, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.2672612419124244, 0.63960214906683133, 0.17677669529663687, 0.0, 0.0, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.386750490563073, 0.0, 0.75, 0.34299717028501764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5388159060803247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.27735009811261457, 0.19611613513818404, 0.86602540378443871, 0.0, 0.34299717028501764, 0.17407765595569785, 0.0, 0.0, 0.20851441405707477, 0.0, 0.0, 0.48507125007266594, 0.0, 0.54772255750516607, 0.0, 0.0, 0.0, 0.43643578047198478, 0.0, 0.2672612419124244, 0.0, 0.0, 0.70710678118654746, 0.0, 0.97014250014533188, 0.18569533817705186, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.20851441405707477, 0.48507125007266594, 0.0, 0.37139067635410372, 0.0, 0.44721359549995793, 0.0, 0.37139067635410372, 0.0, 0.20851441405707477, 0.0, 0.40824829046386307, 0.23570226039551587, 0.0, 0.0, 0.27735009811261457, 0.39223227027636809, 0.53452248382484879, 0.0, 0.0, 0.0, 0.80178372573727319, 0.42640143271122083, 0.0, 0.40824829046386307, 0.0, 0.0, 0.0, 0.0, 0.40824829046386307, 0.16222142113076254, 0.0, 0.0, 0.0, 0.13867504905630729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20851441405707477, 0.0, 0.21320071635561041, 0.72760687510899891, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.18569533817705186, 0.0, 0.0, 0.0, 0.71842120810709964, 0.0, 0.0, 0.0, 0.66666666666666663, 0.20000000000000001, 0.0, 0.61721339984836765, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19245008972987526, 0.28867513459481292, 0.0, 0.30151134457776363, 0.79056941504209477, 0.0, 0.0, 0.0, 0.0, 0.39223227027636809, 0.17407765595569785, 0.0, 0.0, 0.5388159060803247, 0.0, 0.42640143271122083, 0.2672612419124244, 0.0, 0.0, 0.18569533817705186, 0.41702882811414954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.5222329678670935, 0.24253562503633297, 0.27735009811261457, 0.20000000000000001, 0.20412414523193154, 0.0, 0.69631062382279141, 0.0, 0.3481553119113957, 0.0, 0.60302268915552726, 0.0, 0.35355339059327373, 0.0, 0.0, 0.0, 0.2581988897471611, 0.21320071635561041, 0.0, 0.54772255750516607, 0.0, 0.0, 0.38490017945975052, 0.0, 0.0, 0.0, 0.0, 0.47140452079103173, 0.0, 0.39223227027636809, 0.16439898730535729, 0.53452248382484879, 0.5, 0.0, 0.19245008972987526, 0.0, 0.44721359549995793, 0.0, 0.0, 0.50709255283710997, 0.0, 0.0, 0.5163977794943222, 0.16222142113076254, 0.0, 0.0, 0.0, 0.3481553119113957, 0.17960530202677491, 0.2581988897471611, 0.68599434057003528, 0.21821789023599239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70710678118654757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21821789023599239, 0.0, 0.0, 1.0, 0.20412414523193154, 0.89442719099991586, 0.0, 1.4596008983995234, 0.17149858514250882, 0.0, 0.15075567228888181, 0.0, 0.0, 0.22360679774997896, 0.45883146774112349, 0.1690308509457033, 0.24253562503633297, 0.19245008972987526, 0.20000000000000001, 0.18257418583505536, 0.0, 0.0, 0.36514837167011072, 0.0, 0.21320071635561041, 0.2581988897471611, 0.0, 0.0, 0.55470019622522915, 0.0, 0.0, 0.0, 0.48507125007266594, 0.19245008972987526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.89442719099991586, 0.31622776601683794, 0.27735009811261457, 0.0, 0.0, 0.0, 0.22941573387056174, 0.40824829046386307, 0.0, 0.0, 0.0, 0.33333333333333331, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45883146774112349, 0.0, 0.25, 0.0, 0.14907119849998599, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.1889822365046136, 0.48038446141526137, 0.22941573387056174, 0.36514837167011072, 0.20412414523193154, 0.0, 0.19245008972987526, 0.35355339059327373, 0.16439898730535729, 0.41702882811414954, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.71842120810709964, 0.3779644730092272, 0.39223227027636809, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.67082039324993692, 0.0, 0.0, 0.5, 0.0, 0.40000000000000002, 0.53452248382484879, 0.0, 0.0, 0.28867513459481292, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.24253562503633297, 0.85280286542244166, 0.0, 0.0, 0.0, 0.19245008972987526, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.91766293548224698, 0.0, 0.41702882811414954, 0.33333333333333331, 0.0, 0.0, 0.0, 0.20000000000000001, 0.55470019622522915, 0.0, 0.0, 0.40000000000000002, 0.57735026918962573, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 1.0, 0.18569533817705186, 0.0, 0.0, 0.63245553203367588, 0.38490017945975052, 0.33806170189140661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3779644730092272]\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION primera y segunda persona\n",
    "\n",
    "pattern_tag = re.compile(r'tag=\"(.*?)\"')\n",
    "\n",
    "first_second_person=np.zeros((len(corpus), 2))\n",
    "contador=0\n",
    "\n",
    "tam=len(corpus)\n",
    "\n",
    "for i in np.random.randint(0, tam, 1000):\n",
    "    text = corpus['text'][i]\n",
    "    total_token=0\n",
    "    token_1=0\n",
    "    token_2=0\n",
    "    xml = analyzer.run(text.encode(), 'flush')\n",
    "    for sentence in xml:\n",
    "        for token in sentence:\n",
    "            m = re.search(pattern_tag, etree.tostring(token).decode())\n",
    "            tag=m.group(1)\n",
    "            if (tag[0] == 'V'):\n",
    "                if(tag[4] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[4]=='2'):\n",
    "                    token_2+=1\n",
    "            elif(tag[0] == 'P'):\n",
    "                if(tag[2] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[2]=='2'):\n",
    "                    token_2+=1\n",
    "            elif(tag[0] == 'D'):\n",
    "                if(tag[2] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[2]=='2'):\n",
    "                    token_2+=1\n",
    "            total_token+=1\n",
    "    first_second_person[contador,0]=token_1/math.sqrt(total_token)\n",
    "    first_second_person[contador,1]=token_2/math.sqrt(total_token)    \n",
    "    contador+=1\n",
    "    print (\"Dato numero \",contador, \"Porcentaje \", contador/len(corpus),  end=\"\\r\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "pp=[]   \n",
    "sp=[]\n",
    "cont=0\n",
    "for t in first_second_person:\n",
    "    if(cont<1000):\n",
    "        pp.append(t[0])\n",
    "        sp.append(t[1])    \n",
    "    cont+=1    \n",
    "#first_second_person    \n",
    "print(\"Mediana primera persona \", np.median(pp))\n",
    "print(\"Mediana segunda persona \", np.median(sp))\n",
    "\n",
    "print(\"Media primera persona \", np.mean(pp))\n",
    "print(\"Media segunda persona \", np.mean(sp))\n",
    "\n",
    "print(pp)\n",
    "\n",
    "print(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importacion de librerias utiles\n",
    "\n",
    "#Libreria para analisis de datos \n",
    "#en este proyecto para leer y grabar\n",
    "#archivos en csv\n",
    "import pandas\n",
    "\n",
    "#Librerias cientificas scipy, numpy, matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Librerias de incluidas en python time, math\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Lectura de archivos xml\n",
    "from lxml import etree\n",
    "\n",
    "#Expresiones regulares\n",
    "import re\n",
    "\n",
    "#Pyfreeling\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Para implementar modelos de aprendizajes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar comentarios con menos de tres votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga el corpus de humor\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "id_f = []\n",
    "text_f = []\n",
    "account_id_f=[]\n",
    "nh_f=[]\n",
    "sh1_f=[]\n",
    "sh2_f=[]\n",
    "sh3_f=[]\n",
    "sh4_f=[]\n",
    "sh5_f=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_id=corpus['id'][:]\n",
    "vec_text=corpus['text'][:]\n",
    "vec_account_id=corpus['account_id'][:]\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "#Para cada tweet se calcula si tiene al menos tres votos, \n",
    "#en caso afirmativo se guarda su informacion, en caso\n",
    "#negativo se descarta el tweet\n",
    "for i in range(len(corpus)):\n",
    "    if vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= 3:\n",
    "        id_f.append(vec_id[i])\n",
    "        text_f.append(vec_text[i])\n",
    "        account_id_f.append(vec_account_id[i])\n",
    "        nh_f.append(vec_no_humor[i])\n",
    "        sh1_f.append(vec_e1[i])\n",
    "        sh2_f.append(vec_e2[i])\n",
    "        sh3_f.append(vec_e3[i])\n",
    "        sh4_f.append(vec_e4[i])\n",
    "        sh5_f.append(vec_e5[i])\n",
    "        \n",
    "#El primer filtro aplicado es guardado en el archivo corpus_filtro1.csv\n",
    "d = {'id' : id_f,\n",
    "    'text' : text_f,\n",
    "    'account_id': account_id_f,\n",
    "    'n':nh_f, \n",
    "    '1':sh1_f,\n",
    "    '2':sh2_f,\n",
    "    '3':sh3_f,\n",
    "    '4':sh4_f,\n",
    "    '5':sh5_f\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_f = []\n",
    "\n",
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro1 = pandas.read_csv(\"corpus_filtro1.csv\",encoding='utf-8')\n",
    "\n",
    "#Generacion de patron de Hashtag\n",
    "pattern_hashtag = re.compile(r'#.+?\\b')\n",
    "\n",
    "\n",
    "#Se sustituye el Hashtag por el string vacio, los tweets que\n",
    "#van pasando por este procesamiento se van guardando en el arreglo\n",
    "#text_f\n",
    "for i in range(len(corpus_filtro1)):\n",
    "    text_f.append(re.sub(pattern_hashtag, \"\", corpus_filtro1['text'][i]))\n",
    "#El segundo filtro aplicado es guardado en el archivo corpus_filtro2.csv\n",
    "d = {'id' : corpus_filtro1['id'][:],\n",
    "    'text' : text_f,\n",
    "    'account_id': corpus_filtro1['account_id'][:],\n",
    "    'n':corpus_filtro1['n'][:], \n",
    "    '1':corpus_filtro1['1'][:],\n",
    "    '2':corpus_filtro1['2'][:],\n",
    "    '3':corpus_filtro1['3'][:],\n",
    "    '4':corpus_filtro1['4'][:],\n",
    "    '5':corpus_filtro1['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregar la categoria humor o no humor a los documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El criterio de humor o no humor esta basado en el criterio presentado en la letra del laboratorio, en donde se considerará humorístico si la mitad o más de los anotadores lo calificaron con una o más estrellas y no humorístico en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro2 = pandas.read_csv(\"corpus_filtro2.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "text = []\n",
    "category=[]\n",
    "h1=[]\n",
    "h2=[]\n",
    "h3=[]\n",
    "h4=[]\n",
    "h5=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_text=corpus_filtro2['text'][:]\n",
    "vec_no_humor =corpus_filtro2['n'][:]\n",
    "vec_e1 =corpus_filtro2['1'][:]\n",
    "vec_e2 =corpus_filtro2['2'][:]\n",
    "vec_e3 =corpus_filtro2['3'][:]\n",
    "vec_e4 =corpus_filtro2['4'][:]\n",
    "vec_e5 =corpus_filtro2['5'][:]\n",
    "\n",
    "#Si hay igual o mas votos de humor que de no humor la categoria tiene el valor 1\n",
    "#en caso contrario tiene el valor 0\n",
    "for i in range(len(corpus_filtro2)):\n",
    "    if  vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= vec_no_humor[i]:\n",
    "        category.append(1)\n",
    "    else:\n",
    "        category.append(0)\n",
    "    text.append(vec_text[i])\n",
    "    h1.append(vec_e1[i])\n",
    "    h2.append(vec_e2[i])\n",
    "    h3.append(vec_e3[i])\n",
    "    h4.append(vec_e4[i])\n",
    "    h5.append(vec_e5[i])\n",
    "#El tercer procesamiento aplicado sobre los tweets es guardado en el archivo corpus_filtro.3\n",
    "d = {'text' : text,\n",
    "    'category': category,\n",
    "     'n': vec_no_humor,\n",
    "     '1':h1,\n",
    "     '2':h2,\n",
    "     '3':h3,\n",
    "     '4':h4,\n",
    "     '5':h5\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category', 'n', '1','2','3','4','5'])\n",
    "df.to_csv('corpus_filtro3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar información de POS-tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro3 = pandas.read_csv(\"corpus_filtro3.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro3['text'][:]\n",
    "\n",
    "#Se genera el patron para identificar las POS de las palabras\n",
    "pattern_pos = re.compile(r'pos=\"(.*?)\"')\n",
    "\n",
    "#Variables para datos estadisticos\n",
    "num_sentences=len(corpus_filtro3)\n",
    "numsentence=1\n",
    "\n",
    "#Variable auxiliar para adherir las POS a los tweets\n",
    "pos=0\n",
    "\n",
    "#Para cada documento en el corpus de tweets que va siendo procesado\n",
    "#utilizando la herramienta freeling se analizan las categorias gramaticales\n",
    "#de todas las palabras que aparecen en cada tweet y esta informacion es\n",
    "#adherida al texto del tweet\n",
    "for d in text_list:\n",
    "    if(type(d) == str):\n",
    "        xml = analyzer.run(d.encode(), 'flush')\n",
    "        print(numsentence, \" \", math.floor( numsentence/num_sentences*100),\"%\", end=\"\\r\")\n",
    "        for sentence in xml:        \n",
    "            for token in sentence:\n",
    "                token_byte=etree.tostring(token)\n",
    "                m = re.search(pattern_pos, token_byte.decode())\n",
    "                if m is not None:\n",
    "                    text_list[ pos] = text_list[pos] + \" \" + m.group(1)\n",
    "    pos+=1\n",
    "    numsentence+=1\n",
    "\n",
    "#El procesamiento actual del corpus es guardado en el documento corpus_filtro4.csv\n",
    "d = {'text' : text_list,\n",
    "    'category': corpus_filtro3['category'][:],\n",
    "     '1':corpus_filtro3['1'][:],\n",
    "     '2':corpus_filtro3['2'][:],\n",
    "     '3':corpus_filtro3['3'][:],\n",
    "     '4':corpus_filtro3['4'][:],\n",
    "     '5':corpus_filtro3['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', '1','2','3','4','5'])\n",
    "df.to_csv('corpus_filtro4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de datos de entrenamiento y de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro4.csv\",encoding='utf-8')\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4)*20/100)\n",
    "#Se generan posiciones en el arreglo tweets al azar que representen el 20% del corpus actual\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4['text'][:]\n",
    "vec_category=corpus_filtro4['category'][:]\n",
    "\n",
    "#Se separa el 20% de corpus para desarrollo del 80% para entrenamiento\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "\n",
    "#Se guardan las instancias corpus de desarrollo en corpus_filtro5_devset.csv\n",
    "#y corpus de entrenamiento en corpus_filtro5_trainingset.csv\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset.csv')\n",
    "\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de mediana, para segundo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia salvada del corpus que se encuentra en el archivo\n",
    "#corpus_filtro4.csv\n",
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro4.csv\",encoding='utf-8')\n",
    "corpus_filtro3 = pandas.read_csv(\"corpus_filtro3.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "text_list=corpus_filtro4['text'][:]\n",
    "category_list=corpus_filtro4['category'][:]\n",
    "\n",
    "n_list=corpus_filtro3['n'][:]\n",
    "h1_list=corpus_filtro4['1'][:]\n",
    "h2_list=corpus_filtro4['2'][:]\n",
    "h3_list=corpus_filtro4['3'][:]\n",
    "h4_list=corpus_filtro4['4'][:]\n",
    "h5_list=corpus_filtro4['5'][:]\n",
    "\n",
    "medians=[]\n",
    "pos=0\n",
    "\n",
    "#Caclulo de la mediana, en values se expanden los votos de cada estrella\n",
    "#de la siguiente manera si #cant_3Estrellas_en_tweet = 4, entonces se guardan\n",
    "#en values 4 treses 3,3,3,3 para permitir el calculo de la mediana\n",
    "#Por ultimo en la estructura medians se guarda el valor discreto (0,1,2,3,4 o 5) de la mediana\n",
    "#si la cantidad de votos es par se toma el voto del medio con valor mas grande\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    values = []\n",
    "    for j in range( h1_list[i]):\n",
    "        values.append(1)\n",
    "    for j in range( h2_list[i] ):\n",
    "        values.append(2)\n",
    "    for j in range( h3_list[i] ):\n",
    "        values.append(3)\n",
    "    for j in range( h4_list[i] ):\n",
    "        values.append(4)\n",
    "    for j in range( h5_list[i] ):\n",
    "        values.append(5)\n",
    "    for j in range( n_list[i] ):\n",
    "        values.append(0)\n",
    "    mediana=np.median(values)\n",
    "    if( len(values) % 2 == 1 ):\n",
    "        medians.append(math.floor(mediana))\n",
    "    else:\n",
    "        for i in values:\n",
    "            if( i >= mediana):\n",
    "                medians.append(i)\n",
    "                break\n",
    "    pos+=1\n",
    "\n",
    "    \n",
    "#El nuevo procesamiento que suma la informacion de la mediana se guarda\n",
    "#en el archivo corpus_filtro4median.csv\n",
    "d = {'text' : corpus_filtro4['text'][:],\n",
    "    'category' : corpus_filtro4['category'][:],\n",
    "    'median': medians,\n",
    "    'n': corpus_filtro3['n'][:],\n",
    "    '1':corpus_filtro4['1'][:],\n",
    "    '2':corpus_filtro4['2'][:],\n",
    "    '3':corpus_filtro4['3'][:],\n",
    "    '4':corpus_filtro4['4'][:],\n",
    "    '5':corpus_filtro4['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', 'median', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro4median.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos de entrenamiento y desarrollo, para segundo clasificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#Se carga la instancia salvada en el bloque de codigo anterior\n",
    "corpus_filtro4median = pandas.read_csv(\"corpus_filtro4median.csv\",encoding='utf-8')\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4median)*20/100)\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4median) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "median_train=[]\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "median_dev=[]\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4median['text'][:]\n",
    "vec_median=corpus_filtro4median['median'][:]\n",
    "vec_category=corpus_filtro4median['category'][:]\n",
    "\n",
    "\n",
    "for i in range( len(corpus_filtro4median)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        median_dev.append(vec_median[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "        \n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        median_train.append(vec_median[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "d = {'text' : text_train,\n",
    "     'median' : median_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'median','category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_c2.csv')\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "     'median': median_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'median', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_c2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento, clasificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4median = pandas.read_csv(\"corpus_filtro4median.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro4median['text'][:]\n",
    "category_list=[]\n",
    "median_list=corpus_filtro4median['median'][:]\n",
    "h1_list=corpus_filtro4median['1'][:]\n",
    "h2_list=corpus_filtro4median['2'][:]\n",
    "h3_list=corpus_filtro4median['3'][:]\n",
    "h4_list=corpus_filtro4median['4'][:]\n",
    "h5_list=corpus_filtro4median['5'][:]\n",
    "pos=0\n",
    "for m in median_list:\n",
    "    if(m<1):\n",
    "        category_list.append(0)\n",
    "    else:\n",
    "        category_list.append(1)\n",
    "    pos+=1\n",
    "d = {'text' : text_list,\n",
    "    'category': category_list,\n",
    "     'median': median_list\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category','median'])\n",
    "df.to_csv('corpus_filtro4median_category.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación datos de entrenamiento y desarrollo, clasificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n",
      "[1227 3315 1345 1462  222 2945 3401 1799 3205 2057 1093 2319 2368   14 1281\n",
      "  627 2772  524  194 1579  908 1205 1718 3166 1269 2941 3024 1509 2600 1426\n",
      "  555 1343   82 1873 1973  465 2739  301  561 1827 3200 2942 1674 3336   31\n",
      " 1638 2121 1879 1844  957  724  155 1381 1106   15 1121 2624 3238 1849 2316\n",
      "  659 3207 2038 3116 2963 1186 2662  659 3410 2964 3422 1043  651 2571 3221\n",
      " 1384 1008 1077 1272   48  771 1476 1444 1859 2808  342 1606 1511  467 2254\n",
      " 3061  369 1779 1697 1923 1600  321 1715   70  832  254 2958 2638 1640 1538\n",
      " 2540 2178 3102 2026 1154 3234 1725  926 1234 1697 2367 1152 1706 1296 3059\n",
      " 2346 2885 1779 1726  857  565 3245  322 2530 1861  339 3036 1117 2713  230\n",
      " 1543 1369 2515  773  691 2108  487 3293 2794 1336  656  344  185 1219 1777\n",
      " 2269 3194 1110  379  916 2841  975  839 3049  478 1774 1983  404  283 1282\n",
      " 3101 1274 3208 2590  558 1367 3378 1080 2219 3224  692 3050 3400 1087 3170\n",
      " 2699  269 1196 3305 1936 3297 2216 1484 3031  259  649 1172  512 3176 2448\n",
      "  140 1965 1811 3261  913 2702 1135 1471  985 2460 2680    6 1865 1574  544\n",
      " 2471 1932 2904  475 3379 1997  252  212   24 1688 3049 2238  485 3040  173\n",
      " 3354  235 1779 1779  462 2532 1591 1722 3038  919 2268 3128 1776 2815 1977\n",
      "  881 2675  695  592   33 2796 1667 1821 1485 1870  249  933   45  819 1408\n",
      " 2656 1672  957 1913 2172   98  801 1092 2046  920 2105 1305  339 2331 2030\n",
      " 1892 1861  125 2236  445   60 2899 2319 1372 1285 1101  131  522   72 1780\n",
      " 2778 2489 1658 2334  675 2479 3400 2076 3065 3035 3350 1807   81 2823  568\n",
      "  919 2969  996  981  996 1831 1815 3344 1868  483 2028 2512 3433  339  295\n",
      "  444 1882  845 1549 3384 1472 1670 1319 2191 1980 1513 2675 2655 2374 3259\n",
      " 3143 3025 1607 1689 1750 2996  699  150 2429  966 3215  538  142 1788 3377\n",
      " 2070 1108 1843 2007 2610 2419   32 2662 3419 2532 3102  901 1748  395 1324\n",
      " 3110 1843   45 3355 2666 1461  611 2106 2145 2605 1610  208 3393 3419 1828\n",
      " 1892 1651 2347 1387 2121  685  985 2001 2530 1634 1831  783 1447 1789 3185\n",
      "  602 2819 1852  373 2978 3378  872 3369 1545  464 1982 1516  280 2251 2301\n",
      "  453  145 2758 2850  813 2486 1028 3212 3014 1355 1022 2560 1229   68 2248\n",
      " 1723 2971 2962 1630 3231 3278 1771 1475 1964 1620  467 1229 1566  929 3369\n",
      " 2082  779  753 3365 2661  241  380 2168  871  874 1827 1715  278 2127  972\n",
      " 1213 1585  886 2934 1356 2185 1980  229  362 2780 2796 2780 2448 1905  109\n",
      " 1789 1669 2351 2618 1955 1462 1375 3090 1158 1857  979 2697 2921 2748 2209\n",
      " 2423 3290 2340  955 2418 1359  113   78 3054 3169 2328 1289 3160 2369 1032\n",
      " 1402 2686  172 3301 3057 1497 3213  789   56  241  942  125 2980 1243 2989\n",
      "  519 1252 2360 2682 1199 1537 1696 2663 1306  639 1286 3382 2954  326 2462\n",
      "  707 2377  250 1607 2900  204 2304 2516  901 2234  648 3359  573   87 2064\n",
      " 1338 1944 3198 2772 1806 3060  468 1992 1616 3241 1381   35 3382 1041 1521\n",
      " 2591  878 2351 2687 1459  683 3178 2211  340  783  721 1618 1118  703 1430\n",
      " 1523  863 2250 1119 2212 2092 2318  807 1956 1301 3038 2044 3198 3263  133\n",
      " 1801 1825 1894 1737 2031 2631 1930  575  366 1013 2089 3381 1348  547  413\n",
      "  190 1260 1507  496  711 2691  779  111 2610 2601 2054  387 1042  238 2874\n",
      "  736 3306  996 1856 2000 3266 1328  449 1730 2558  980 1763 1248   53 2371\n",
      "  733  578 2437   80 1781  130 3026 2384 3324  938 1150 3222 1582 2125 1560\n",
      "  317 2150 1322 2290  157 2775  146 1820 2812  690 2819  549  545 2893 2661\n",
      "  670 2142 2097  173 1321 1710  143 2911 3391  876 2506 3270  409 3179 2545\n",
      " 1057 3107 1987   27  726 3265 1318 1024  383  445 1436 3373]\n"
     ]
    }
   ],
   "source": [
    "corpus_filtro4median_category = pandas.read_csv(\"corpus_filtro4median_category.csv\",encoding='utf-8')\n",
    "text=corpus_filtro4median_category['text'][:]\n",
    "category=corpus_filtro4median_category['category'][:]\n",
    "median=corpus_filtro4median_category['median'][:]\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4median_category)*20/100)\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4median_category) - 1, size=num_dev_tweets)\n",
    "\n",
    "print(num_dev_tweets)\n",
    "print(random_samples)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4median_category['text'][:]\n",
    "vec_category=corpus_filtro4median_category['category'][:]\n",
    "\n",
    "for i in range( len(corpus_filtro4median_category)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_c3.csv')\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_c3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases para los clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "class Clasificador1:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_1_train(path)\n",
    "    \n",
    "    def __clasiffier_1_train(self, path):\n",
    "        corpus_filtro5_trainingset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_list=corpus_filtro5_trainingset['text'][:]\n",
    "        category_list=corpus_filtro5_trainingset['category'][:]\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.train_features = self.vectorizer.fit_transform(text_list)\n",
    "\n",
    "        self.nb_1 = MultinomialNB()\n",
    "        self.nb_1.fit(self.train_features , category_list)\n",
    "    def predict_clasiffier_1(self, path):       \n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text'][:]\n",
    "        category_devlist=corpus_filtro5_devset['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features = self.vectorizer.transform(text_devlist)\n",
    "        return self.nb_1.predict(self.test_features)\n",
    "\n",
    "class Clasificador2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_2_train()\n",
    "        self.__median_predictor_train()\n",
    "\n",
    "    \n",
    "    def __median_predictor_train(self):\n",
    "        corpus_filtro5 = pandas.read_csv(\"corpus_filtro5_trainingset_c2.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5['text'][:]\n",
    "        median_list=corpus_filtro5['median'][:]\n",
    "        self.category_list_c1=[]\n",
    "\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.train_features_c1 = vectorizer.fit_transform(text_list)\n",
    "\n",
    "        for i in median_list:\n",
    "            if(i == 1):\n",
    "                self.category_list_c1.append(1)\n",
    "            else:\n",
    "                self.category_list_c1.append(0)\n",
    "        \n",
    "        self.nb_median1 = MultinomialNB()\n",
    "        self.nb_median1.fit(self.train_features_c1 , self.category_list_c1[:])\n",
    "\n",
    "        self.category_list_c2=[]\n",
    "        for i in median_list:\n",
    "            if(i == 2):\n",
    "                self.category_list_c2.append(1)\n",
    "            else:\n",
    "                self.category_list_c2.append(0)\n",
    "        self.nb_median2 = MultinomialNB()\n",
    "        self.nb_median2.fit(self.train_features_c1 , self.category_list_c2)\n",
    "\n",
    "        self.category_list_c3=[]\n",
    "        for i in median_list:\n",
    "            if(i == 3):\n",
    "                self.category_list_c3.append(1)\n",
    "            else:\n",
    "                self.category_list_c3.append(0)\n",
    "\n",
    "        self.nb_median3 = MultinomialNB()\n",
    "        self.nb_median3.fit(self.train_features_c1 , self.category_list_c3)       \n",
    "\n",
    "        self.category_list_c4=[]\n",
    "        for i in median_list:\n",
    "            if(i == 4):\n",
    "                self.category_list_c4.append(1)\n",
    "            else:\n",
    "                self.category_list_c4.append(0)\n",
    "\n",
    "        self.nb_median4 = MultinomialNB()\n",
    "        self.nb_median4.fit(self.train_features_c1 , self.category_list_c4[:])\n",
    "        \n",
    "        self.category_list_c5=[]\n",
    "        for i in median_list:\n",
    "            if(i == 5):\n",
    "                self.category_list_c5.append(1)\n",
    "            else:\n",
    "                self.category_list_c5.append(0)\n",
    "        self.nb_median5 = MultinomialNB()\n",
    "        self.nb_median5.fit(self.train_features_c1 , self.category_list_c5)\n",
    "\n",
    "        self.category_list_c0=[]\n",
    "        for i in median_list:\n",
    "            if(i == 0):\n",
    "                self.category_list_c0.append(1)\n",
    "            else:\n",
    "                self.category_list_c0.append(0)\n",
    "                \n",
    "        self.nb_median0 = MultinomialNB()\n",
    "        self.nb_median0.fit(self.train_features_c1 , self.category_list_c0)\n",
    "        \n",
    "    def __predict_median1_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c1=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 1:\n",
    "                self.median_list_c1.append(1)\n",
    "            else:\n",
    "                self.median_list_c1.append(0)\n",
    "            \n",
    "\n",
    "        self.test_features_c1 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median1.predict_proba(self.test_features_c1), self.nb_median1.predict(self.test_features_c1)\n",
    "    def __predict_median2_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        \n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c2=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 2:\n",
    "                self.median_list_c2.append(1)\n",
    "            else:\n",
    "                self.median_list_c2.append(0)\n",
    "\n",
    "        \n",
    "        self.test_features_c2 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median2.predict_proba(self.test_features_c2), self.nb_median2.predict(self.test_features_c2)\n",
    "    def __predict_median3_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c3=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 3:\n",
    "                self.median_list_c3.append(1)\n",
    "            else:\n",
    "                self.median_list_c3.append(0)\n",
    "\n",
    "        self.test_features_c3 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median3.predict_proba(self.test_features_c3), self.nb_median3.predict(self.test_features_c3)\n",
    "    def __predict_median4_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c4=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 4:\n",
    "                self.median_list_c4.append(1)\n",
    "            else:\n",
    "                self.median_list_c4.append(0)\n",
    "\n",
    "        self.test_features_c4 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median4.predict_proba(self.test_features_c4), self.nb_median4.predict(self.test_features_c4)\n",
    "    def __predict_median5_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c5=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 5:\n",
    "                self.median_list_c5.append(1)\n",
    "            else:\n",
    "                self.median_list_c5.append(0)\n",
    "\n",
    "        self.test_features_c5 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median5.predict_proba(self.test_features_c5), self.nb_median5.predict(self.test_features_c5)\n",
    "    def __predict_median0_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c0=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 0:\n",
    "                self.median_list_c0.append(1)\n",
    "            else:\n",
    "                self.median_list_c0.append(0)\n",
    "\n",
    "        self.test_features_c0 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median0.predict_proba(self.test_features_c0), self.nb_median0.predict(self.test_features_c0)\n",
    "    def __clasiffier_2_train(self):\n",
    "        corpus_filtro5_trainingset_c2 = pandas.read_csv(\"corpus_filtro5_trainingset_c2.csv\",encoding='utf-8')\n",
    "        text_list_c2=corpus_filtro5_trainingset_c2['text'][:]\n",
    "        category_list_c2=corpus_filtro5_trainingset_c2['category'][:]\n",
    "        pos_c2=0\n",
    "        for t in text_list_c2:\n",
    "            if type(t) != str:\n",
    "                text_list_c2[pos_c2]=\"NaN\"\n",
    "            pos_c2+=1\n",
    "        self.train_features_class2 = self.vectorizer.fit_transform(text_list_c2)\n",
    "\n",
    "        self.nb_2 = MultinomialNB()\n",
    "        self.nb_2.fit(self.train_features_class2, category_list_c2)\n",
    "\n",
    "    \n",
    "    def predict_median(self, path):\n",
    "        self.c1_pred, self.c1_predict=self.__predict_median1_c2(path)\n",
    "        self.c2_pred, self.c2_predict=self.__predict_median2_c2(path)\n",
    "        self.c3_pred, self.c3_predict=self.__predict_median3_c2(path)\n",
    "        self.c4_pred, self.c4_predict=self.__predict_median4_c2(path)\n",
    "        self.c5_pred, self.c5_predict=self.__predict_median5_c2(path)\n",
    "        self.c0_pred, self.c0_predict=self.__predict_median0_c2(path)        \n",
    "        self.predicts=[]\n",
    "        proba=[]\n",
    "        for i in range( len(self.c1_pred) ):\n",
    "            maximum=np.max([self.c1_pred[i][1],self.c2_pred[i][1],self.c3_pred[i][1],self.c4_pred[i][1],self.c5_pred[i][1],self.c0_pred[i][1]])\n",
    "            if(maximum == self.c1_pred[i][1]):\n",
    "                self.predicts.append(1)\n",
    "            elif(maximum == self.c2_pred[i][1]):\n",
    "                self.predicts.append(2)\n",
    "            elif(maximum == self.c3_pred[i][1]):\n",
    "                self.predicts.append(3)\n",
    "            elif(maximum == self.c4_pred[i][1]):\n",
    "                self.predicts.append(4)\n",
    "            elif(maximum == self.c5_pred[i][1]):\n",
    "                self.predicts.append(5)\n",
    "            elif(maximum == self.c0_pred[i][1]):\n",
    "                self.predicts.append(0)\n",
    "            proba.append(maximum)\n",
    "        self.m0 = []\n",
    "        self.m1 = []\n",
    "        self.m2 = []\n",
    "        self.m3 = []\n",
    "        self.m4 = []\n",
    "        self.m5 = []\n",
    "\n",
    "        for pred in self.predicts:\n",
    "            if pred == 0:\n",
    "                self.m0.append(1)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 1:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(1)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 2:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(1)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 3:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(1)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 4:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(1)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 5:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(1)\n",
    "\n",
    "        \n",
    "        \n",
    "        corpus_filtro5_devset_c2 = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist_c2=corpus_filtro5_devset_c2['text'][:]\n",
    "        category_devlist_c2=corpus_filtro5_devset_c2['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist_c2:\n",
    "            if type(t) != str:\n",
    "                text_devlist_c2[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features_class2 = self.vectorizer.transform(text_devlist_c2)\n",
    "                    \n",
    "        return self.predicts, proba, self.nb_2.predict(self.test_features_class2)\n",
    "\n",
    "class Clasificador3:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_3_train()\n",
    "    def __clasiffier_3_train(self):\n",
    "        corpus_filtro5_trainingset_c3 = pandas.read_csv(\"corpus_filtro5_trainingset_c3.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5_trainingset_c3['text'][:]\n",
    "        category_list=corpus_filtro5_trainingset_c3['category'][:]\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.train_features = self.vectorizer.fit_transform(text_list)\n",
    "        self.nb = MultinomialNB()\n",
    "        self.nb.fit(self.train_features , category_list)\n",
    "    def predict_clasiffier_1(self, path, test):\n",
    "        corpus_filtro5_devset_c3 = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset_c3['text'][:]\n",
    "        category_devlist=corpus_filtro5_devset_c3[test][:]\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features = self.vectorizer.transform(text_devlist)\n",
    "        return self.nb.predict(self.test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1\n",
      " 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1\n",
      " 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1\n",
      " 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador1(\"corpus_filtro5_trainingset.csv\")\n",
    "print(clasificador.predict_clasiffier_1(\"corpus_filtro5_devset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 0, 0, 3, 0, 0, 3, 0, 1, 4, 0, 1, 0, 4, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 3, 1, 0, 0, 3, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 2, 3, 3, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 2, 2, 0, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 2, 3, 0, 1, 0, 0, 0, 0, 3, 3, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 1, 3, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 4, 0, 0, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 3, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 3, 1, 0, 0, 3, 4, 3, 2, 1, 0, 3, 3, 3, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 3, 1, 3, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 1, 0, 1, 0, 3, 0, 1, 0, 4, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 3, 0, 0, 0, 3, 3, 1, 0, 4, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 4, 0, 3, 2, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 3, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 3, 0, 0, 0, 0, 2, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 0, 2, 0, 3, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 3, 4, 2, 0, 0, 0, 4, 0, 0, 3, 0, 1, 0, 0, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 3, 0, 0, 3, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 3, 0, 3, 0, 3, 0, 0, 1, 0, 4, 0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 2, 0, 3, 4, 3, 0, 0, 0, 3, 0, 0, 0, 1] \n",
      " [0.0060079039532164608, 0.00078671032972932461, 0.97357893582802579, 0.88193337198206601, 0.066406434232892067, 0.60757957705310994, 0.89488354075190513, 0.022737563333421446, 0.016297156175151949, 3.0280852737068699e-05, 0.0038706673731551669, 0.06927674086897255, 0.0069625761931821628, 0.0090864570989913039, 0.994751981772521, 0.20960053587031108, 0.90535143547331109, 0.89407611576674983, 0.29480386821702609, 0.0078403203287101316, 0.69500732014617839, 0.0067768837869561756, 0.92345040097800291, 0.12930903003415753, 0.025473398689401586, 0.013385305157047981, 0.067135767578786906, 0.54505381971975375, 0.3591353731250857, 0.0037152828856257362, 0.68468965009047333, 4.3103080132548557e-05, 0.69855968330022944, 0.26426678223577815, 1.5800483502717529e-05, 0.020262289630213398, 0.83807725892816398, 0.69045720942766631, 0.27805898706734766, 0.27533081569045914, 0.00071268211173009292, 0.051191631247507641, 3.4228096400064145e-06, 0.32395551634122954, 0.23559673542073328, 0.1791845266093352, 0.031117884341807678, 0.029833849572687053, 0.3499798729028793, 0.20334569063736421, 0.36335738905116777, 0.91450194717524513, 0.25392467146762432, 0.96870639836542638, 0.45983608103107299, 0.25198278994891654, 0.80321391875019732, 0.99509345012563943, 0.99918986210140015, 0.043113475699500955, 5.9366443853577041e-05, 0.00027225589432612732, 0.0080413583939143302, 0.049649923481839033, 0.94690829616808692, 0.74258717084001091, 0.019823144552813532, 0.97884702302421323, 0.52126442646911453, 0.94111334995945461, 0.57065117363672857, 0.014681851930430574, 0.012895015438354994, 0.79255341908277621, 0.0035844049785625546, 0.0012749804455011158, 0.99275723737166632, 0.0022369567644087785, 0.98125420569329391, 0.0086728545041935695, 0.38805521741894311, 0.21624416544988018, 0.93430264562492582, 0.95144733170463869, 0.7536568734895932, 0.14490364951441975, 0.79017534754132224, 0.95898894497790221, 0.015822620618327819, 0.85140826847051754, 0.13699927154336153, 0.022129758302921042, 0.035040180973112067, 0.37338875091201812, 0.84738674148971294, 0.68983253576297754, 0.91682809581045599, 0.031329260301252944, 0.9969975587281299, 0.036257462986669521, 0.999706805541694, 0.00050345467147318757, 0.38843299979946594, 0.0004763569587486119, 0.44556901431385304, 0.26426455542590876, 0.072583747892083356, 0.38107517010808367, 0.00069229037026469036, 0.0020274597480640895, 0.050689536414775263, 0.0034565792358368262, 0.0014946328100328547, 0.18621614178092669, 0.0036193357012220054, 0.42034424431861911, 0.78880523052733931, 0.29952595060546017, 0.020228976169586282, 0.46875016335869091, 0.62968124403060599, 0.066752351350263223, 0.30527443160449219, 0.37987713007695162, 0.16704718290619613, 0.0095691869806257754, 8.6119526888399359e-05, 0.52723444642076323, 0.29283394183608979, 0.17105872067852257, 0.032951458556288858, 0.70219357182949516, 0.0002290780324011335, 0.056079760939326963, 0.50810820213140684, 0.00038594439098691644, 0.2600169919018932, 0.74710194795082452, 0.073873010393664548, 0.29551616800650088, 0.020706214507097188, 0.0025201075194099371, 0.00029031128507005309, 0.98710564440240178, 0.33823621570165224, 0.031104521550013867, 0.00024484781052445465, 0.02201724019543546, 0.99139886128396792, 0.74409409824853523, 0.47779221234861308, 0.99999852255656385, 0.70498663623262126, 0.66329820003632156, 0.032423125416717845, 0.19071093248760332, 0.75704989729097372, 0.0071972475171708222, 0.20850874578883402, 0.29768101167798872, 0.88261477330583393, 0.51396355941181082, 0.090283505336343634, 0.37258353331338578, 0.0074447371052469595, 0.99741111052703846, 0.51437122443171757, 0.985207761511942, 0.00071036168690513451, 0.34710302556273759, 0.67003171922466398, 0.69511014256126724, 0.069235468416688553, 0.61158823362336001, 0.61865767823234907, 0.90031755889074638, 0.33786988624614628, 0.00076278463901363678, 0.99389438960075782, 0.0093141396194460109, 0.47983430644829439, 0.91553538140867685, 0.9146175919952596, 0.010252472820070619, 0.31809933219858755, 0.90935486800968157, 0.015511931201593493, 0.62747461679035754, 0.95923753700745606, 0.99982512313387495, 0.35767575288058834, 0.73617453237732366, 0.30922326912748305, 0.041087206108477513, 0.0040489412195803872, 0.3599694477659553, 0.0094744185504962025, 3.7720106147527886e-05, 0.73458481314195667, 0.90991318043479263, 0.57640381519304318, 0.99165980822431077, 0.26505472890712201, 0.00045152838498559069, 0.0088318157230706535, 0.92926273652172442, 0.29181872585264662, 0.051880415827866261, 0.60809909690781794, 0.07524978705485294, 0.011499659103488533, 0.38794044199432642, 0.40585925946273382, 0.001294027511128828, 0.064203617225262771, 0.94463475838614086, 0.0022493665469703467, 0.051807190141480511, 0.92907447641335505, 0.0044854494865299022, 0.51260087415978706, 0.77260048245342017, 0.93070720578090393, 0.0080918053060596157, 0.97679068913264133, 0.99799472381940513, 0.99517903398355734, 0.0012832632487037464, 0.006100370686429931, 0.0031224067646429088, 0.99326564928372829, 0.011153763581652383, 0.18829704319254431, 0.62750388568484949, 0.0027508796754402605, 0.00066837791290219541, 0.89078372784535931, 0.00056766711563716781, 0.19447592066773825, 0.0085233491673373327, 0.9134525476681481, 0.0055010936492809696, 0.010820446210290491, 0.034755493460265893, 0.026229763849719003, 0.73022227209070711, 0.99696438454555159, 0.99740178573854021, 0.00050925603374056799, 0.77497708388708753, 0.84374474572478431, 0.12396696168644467, 0.0019148597897655942, 0.95601313922709941, 0.00059425123638065026, 0.00017945011308864167, 0.0033788555898988134, 0.082735006390765906, 0.017543249795681448, 0.9418275486111708, 0.0062003895576248714, 0.66526418250964225, 0.57631563692415133, 0.0009997455274924343, 0.0011157149748169234, 0.93277499352373716, 0.78980604994218584, 0.99866654387317755, 0.0019935393514936891, 0.6063585866410246, 0.00026585102455339409, 0.016787165702425284, 0.89883331674438005, 0.74097499832145186, 0.66252662293318609, 0.27973107124612101, 0.078165499829476515, 0.42528516870196492, 0.23928244614279437, 0.050267221037759914, 0.31234685189704342, 0.12772399524074909, 0.32788163390818115, 0.53221331470099964, 0.078652231576075898, 0.5943825411850705, 0.98925517674917551, 0.89185289962593706, 0.008891599064584095, 0.88892041225204643, 0.0010201169283761808, 0.68022471081999669, 8.7992838205117463e-07, 0.98027191762422972, 0.0064629966022213825, 0.02725433437878861, 0.031035667759719974, 7.6816986701480915e-05, 5.9677242940568519e-05, 0.04022119350446561, 0.71264766964996717, 0.97023686953755206, 0.0054424131955257667, 0.1294439887712798, 0.96329101604092149, 0.85279831266845274, 0.8331637662353103, 0.13816277900314153, 0.057886405606681117, 0.27341721841943106, 0.00705321377674326, 0.79923165531513951, 0.14209365894070994, 0.026752259348316123, 0.0052174211460862549, 0.00017166290645538644, 0.99840284502130627, 0.3136051495301127, 0.51875583578016049, 0.0010354624773979231, 0.99649309422525867, 0.0068605736577009224, 0.020686530070406224, 0.0086125174415647762, 0.7042328629174468, 0.99790827049604724, 0.0059485539888007909, 0.021355463755687809, 0.59835836972046186, 0.91785222783115261, 0.90870213621573204, 0.59422187811494098, 0.01614292453289266, 0.04029946349107872, 0.016440016401915617, 0.69494606187980346, 0.024655178062031668, 0.48367703546132546, 0.0037657240653188981, 0.97975850979541457, 0.056596512532563224, 0.77735056198701813, 0.17828468314212037, 0.94863634054814205, 0.33176918789941201, 0.0054229692699745971, 0.98607091409675707, 0.95830142998978773, 0.0082344711469459642, 0.9144693201018762, 0.71047567231743836, 0.10888371636470937, 0.0061542563929866184, 0.88401001229746157, 5.8162109188524653e-05, 0.03195545024187612, 0.71264852883830465, 0.0007072961818894622, 0.093475141107130913, 0.12185214459393359, 0.4262983004176995, 0.62750388568484949, 0.47775244319398613, 0.96999678458556271, 0.1547394110352566, 0.012594203384887525, 0.59813965586288442, 0.0016748104486415337, 0.00036543763359194939, 0.0059450105482864784, 0.63101679954609746, 0.20283330667576854, 0.00011894702632520676, 0.36846243731139255, 0.42747922082499767, 0.2206102895102334, 0.95901007379862824, 0.90275470058257845, 0.22703666279256418, 0.99999999999994316, 0.019359317733561903, 0.97451913780032795, 0.013396443319153652, 0.90755993413648028, 0.0010423805761162598, 0.97769433229130109, 0.050448273011418063, 0.78143306565144677, 0.00010942271556430504, 0.5605439993071113, 0.038619842481124503, 0.005988356590170751, 0.78411714150960365, 0.11845509751797122, 0.99839318497294927, 0.03874893757719592, 0.97370534658486851, 0.88319967508789843, 0.016374296272691182, 0.00091553278429303789, 0.40880492116426975, 0.11853892873259458, 0.36459805514634791, 0.99827189509895797, 0.2026459250210805, 0.81318194893745432, 0.30761099987249535, 0.21906026192215639, 0.0055050788735487299, 0.46520908637841374, 0.011897183395211668, 0.57679470038826186, 0.15515193290238133, 0.31531386558619517, 0.037500790677816913, 0.79371118417268982, 0.99976788028669628, 0.0068840662959768015, 0.002647758777759288, 0.018605323652115004, 0.59114713407361563, 0.99829948004758873, 0.26243331390220759, 0.9330534130502377, 0.00030249905242460818, 0.0016662586624727326, 0.0009607978493525308, 0.00029575619110250946, 0.63293788587841804, 0.00055416521974909708, 0.00058568435185387714, 0.004542648983958824, 0.99932428117426442, 0.0043049869604235205, 0.86602852131423647, 0.28008391259547044, 0.11878012244356641, 0.10841198640365243, 0.0175186733971084, 0.00064682086719289171, 0.00031582215688517748, 0.22542528750801771, 0.21395508858281259, 0.82967791772212351, 0.0057522645056260592, 0.38616192814445255, 0.053516514321304366, 0.055043042497719359, 0.16796429986682571, 0.94425740690008575, 0.32649446762362072, 0.20693446016852982, 0.031619050916719814, 0.01223136721391499, 0.517404307100779, 9.1128496233488951e-05, 0.10155680416677214, 0.94639795717764397, 0.00047691764054867697, 0.11335789734636116, 0.82151882647314733, 0.10371802996073312, 0.00014971221340094099, 0.62150986799559571, 0.069277801499538202, 0.59091887860707515, 0.44269542056011846, 0.0088740689886993105, 0.51643466935510607, 0.0084322601469221745, 0.79255632410643184, 0.97743389551289095, 0.20472642770079377, 0.10171981865255224, 0.010089153375417798, 0.82291361304443611, 0.15032111597744174, 0.11049677858809401, 0.88233294744855773, 5.2915955111387465e-05, 0.41560832459729413, 0.94916586163090833, 3.0897201951155193e-05, 0.17068012183200248, 0.12571062744924405, 0.0012823284182802051, 0.013004162849482326, 0.54119283505815308, 0.063332060986352912, 0.015431120015740834, 0.38793570342795097, 0.50334483344260028, 0.49005325016827983, 0.00040852605738370856, 0.91520512811475963, 0.61263112054678071, 0.93788682816019864, 0.13421889092791556, 0.066494266527992951, 0.97667923277039703, 0.25924983984362732, 0.00089586587759897594, 0.096541574068221891, 0.0039717441809320811, 0.83967015660514099, 0.14107818814359088, 0.89825044953765487, 0.99999999988330046, 0.44181277500714827, 0.11213713373674353, 0.080711350822793571, 0.0018072934049807761, 0.02301499999819934, 0.34880820092591919, 0.0059349494584774792, 0.33395622867712055, 0.0019347873373969891, 2.6980498014415515e-06, 0.10737154831456198, 0.00093030972181765061, 0.27420353951459342, 0.19592089019776499, 0.0026988106148837852, 0.12879493625944868, 0.62742010584392383, 0.91571343914173076, 0.92747582318831912, 0.99954983852569479, 0.010718577234891476, 0.61812259330265695, 0.27184694074945842, 0.00013011078766912609, 0.070453508175324836, 0.012813077820598841, 0.00040321518378241762, 0.973326435650546, 0.00088281156176662687, 0.61719873032489292, 0.37180803126707157, 0.089775223399364557, 0.78117985927465372, 0.69527894071134466, 0.00071283587147630734, 0.011468502803337329, 4.3471381808898772e-05, 0.0060926870387911771, 0.48446468403995691, 0.939283364427968, 0.0022970814023230055, 0.70336498277795345, 0.38622823990666738, 0.0069388119349658725, 0.97884702302421323, 0.95884867715410249, 0.0046181600877938855, 0.00061027222986335136, 0.33836326917554987, 0.00079444418941251968, 0.93889839209908188, 0.00051929868967068272, 4.4351832380069272e-05, 0.9016673835042659, 0.89082508857805698, 0.047629909252592001, 0.00062649540755861936, 0.003780844530807972, 0.29467568248012344, 0.98991265547542207, 0.0072961893159546451, 0.031513740277462912, 0.28678242281120697, 0.16536353133542053, 0.87335593778493348, 2.2194480561499331e-05, 0.00020680370306708234, 0.029743467433487041, 0.0090084551139626642, 0.4239846881666246, 0.39680821175174502, 0.38616673348667058, 0.04372163702244275, 0.94912417250227843, 0.95713963016204917, 0.13537094074840578, 0.23354692291515178, 0.95239354784004904, 0.98511083568277147, 0.0026564529861543458, 0.040333746414575759, 0.013795529914989078, 0.86931459319753313, 0.029130042603630821, 0.93389750167168262, 0.00046354888208904004, 0.76142298971230249, 0.14344390319436612, 0.071886779403071269, 0.018894856487923908, 0.79013837723965441, 0.00099173460901056851, 0.12232363556104701, 0.0090927878539024936, 0.72646527286927831, 0.34154911736478083, 0.025553565991798206, 0.41367170737446929, 0.60022857576246735, 0.69238174033614397, 0.77738742337198752, 0.00076093939106943039, 0.42275211819402703, 0.9970010431778521, 0.93844460241267236, 0.0025125808923659649, 0.67789600389124127, 2.3438434998566271e-06, 0.9910865912572745, 0.99955557014579977, 0.8791638943517941, 0.0087841577881331429] \n",
      " [1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0\n",
      " 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1\n",
      " 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1\n",
      " 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
      " 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0\n",
      " 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 1\n",
      " 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "clasificador=Clasificador2()\n",
    "predict, proba, humor_prob=clasificador.predict_median(\"corpus_filtro5_devset_c2.csv\")\n",
    "print(predict, \"\\n\", proba, \"\\n\", humor_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador3()\n",
    "print(clasificador.predict_clasiffier_1(\"corpus_filtro5_devset_c3.csv\", \"category\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas para el clasificador 1\n",
      "Precision:  0.7427745664739884\n",
      "Recall:  0.803125\n",
      "Accuracy  0.5492063492063493\n",
      "E-measure  0.7717717717717717\n",
      "Medidas para el clasificador 2\n",
      "Precision:  0.7610619469026548\n",
      "Recall:  0.7794561933534743\n",
      "Accuracy  0.5467741935483871\n",
      "E-measure  0.7701492537313434\n",
      "Medidas para el clasificador 3\n",
      "Precision:  0.7028301886792453\n",
      "Recall:  0.7989276139410187\n",
      "Accuracy  0.6719492868462758\n",
      "E-measure  0.7478042659974905\n",
      "Predicter Median 1\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 11 \t|\t 33 \t|\n",
      "system negative|\t 91 \t|\t 485 \t|\n",
      "Presicion  0.25\n",
      "Recall  0.10784313725490197\n",
      "Accuracy  0.07096774193548387\n",
      "E-measure  0.1506849315068493\n",
      "Predicter Median 2\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 7 \t|\t 23 \t|\n",
      "system negative|\t 88 \t|\t 502 \t|\n",
      "Presicion  0.23333333333333334\n",
      "Recall  0.07368421052631578\n",
      "Accuracy  0.04838709677419355\n",
      "E-measure  0.11199999999999999\n",
      "Predicter Median 3\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 23 \t|\t 82 \t|\n",
      "system negative|\t 87 \t|\t 428 \t|\n",
      "Presicion  0.21904761904761905\n",
      "Recall  0.20909090909090908\n",
      "Accuracy  0.1693548387096774\n",
      "E-measure  0.21395348837209302\n",
      "Predicter Median 4\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 3 \t|\t 12 \t|\n",
      "system negative|\t 54 \t|\t 551 \t|\n",
      "Presicion  0.2\n",
      "Recall  0.05263157894736842\n",
      "Accuracy  0.024193548387096774\n",
      "E-measure  0.08333333333333333\n",
      "Predicter Median 5\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 11 \t|\t 609 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 0\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 220 \t|\t 206 \t|\n",
      "system negative|\t 25 \t|\t 169 \t|\n",
      "Presicion  0.5164319248826291\n",
      "Recall  0.8979591836734694\n",
      "Accuracy  0.6870967741935484\n",
      "E-measure  0.6557377049180328\n",
      "Confusion matrix\n",
      "\t 0 \t 1 \t 2 \t 3 \t 4 \t 5 \n",
      "0 \t 220 \t 64 \t 50 \t 59 \t 27 \t 6\n",
      "1 \t 7 \t 11 \t 9 \t 13 \t 4 \t 0\n",
      "2 \t 2 \t 4 \t 7 \t 11 \t 4 \t 2\n",
      "3 \t 16 \t 18 \t 26 \t 23 \t 19 \t 3\n",
      "4 \t 0 \t 5 \t 3 \t 4 \t 3 \t 0\n",
      "5 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "Macro averaging\n",
      "Precision  0.4036850921273032  Recall 0.4036850921273032  F 0.4036850921273032\n",
      "Micro averaging\n",
      "Precision  0.06980214621059692  Recall 0.15994696011702073  F 0.0971898543980253\n"
     ]
    }
   ],
   "source": [
    "corpus_filtro5_devset = pandas.read_csv(\"corpus_filtro5_devset.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c2 = pandas.read_csv(\"corpus_filtro5_devset_c2.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c3 = pandas.read_csv(\"corpus_filtro5_devset_c3.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 1\n",
    "list_cat_1 = []\n",
    "list_ecat_1 = []\n",
    "\n",
    "\n",
    "list_cat_1=corpus_filtro5_devset['category'][:]\n",
    "\n",
    "clasificador = Clasificador1(\"corpus_filtro5_trainingset.csv\")\n",
    "list_ecat_1  = clasificador.predict_clasiffier_1(\"corpus_filtro5_devset.csv\")\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 2\n",
    "list_cat_2 = []\n",
    "list_ecat_2 = []\n",
    "list_edem_2=[]\n",
    "medians = []\n",
    "\n",
    "\n",
    "list_cat_2=corpus_filtro5_devset_c2['category'][:]\n",
    "clasificador2=Clasificador2()\n",
    "list_emed_2, _, list_ecat_2=clasificador2.predict_median(\"corpus_filtro5_devset_c2.csv\")\n",
    "medians=corpus_filtro5_devset_c2['median'][:];\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 3\n",
    "list_cat_3 = []\n",
    "list_ecat_3 = []\n",
    "\n",
    "list_cat_3=corpus_filtro5_devset_c3['category'][:]\n",
    "clasificador3 = Clasificador3()\n",
    "list_ecat_3=clasificador3.predict_clasiffier_1(\"corpus_filtro5_devset_c3.csv\", \"category\")\n",
    "\n",
    "\n",
    "#Variables para clasificador 1\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_1) ):\n",
    "    if(list_cat_1[i] == 1 and list_ecat_1[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_1[i] == 1 and list_ecat_1[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_1[i] == 0 and list_ecat_1[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 1\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 2\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_2) ):\n",
    "    if(list_cat_2[i] == 1 and list_ecat_2[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_2[i] == 1 and list_ecat_2[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_2[i] == 0 and list_ecat_2[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "\n",
    "print(\"Medidas para el clasificador 2\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 3\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_3) ):\n",
    "    if(list_cat_3[i] == 1 and list_ecat_3[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_3[i] == 1 and list_ecat_3[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_3[i] == 0 and list_ecat_3[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 3\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para las medianas\n",
    "tp_m1=0\n",
    "fp_m1=0\n",
    "tn_m1=0\n",
    "fn_m1=0\n",
    "\n",
    "tp_m2=0\n",
    "fp_m2=0\n",
    "tn_m2=0\n",
    "fn_m2=0\n",
    "\n",
    "tp_m3=0\n",
    "fp_m3=0\n",
    "tn_m3=0\n",
    "fn_m3=0\n",
    "\n",
    "tp_m4=0\n",
    "fp_m4=0\n",
    "tn_m4=0\n",
    "fn_m4=0\n",
    "\n",
    "tp_m5=0\n",
    "fp_m5=0\n",
    "tn_m5=0\n",
    "fn_m5=0\n",
    "\n",
    "tp_m0=0\n",
    "fp_m0=0\n",
    "tn_m0=0\n",
    "fn_m0=0\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c1) ):\n",
    "    if(clasificador2.m1[i] == 1 and medians[i]==1):\n",
    "        tp_m1+=1\n",
    "    elif(clasificador2.m1[i] == 0 and medians[i]==1):\n",
    "        fn_m1+=1\n",
    "    elif(clasificador2.m1[i] == 1 and medians[i]!=1):\n",
    "        fp_m1+=1\n",
    "    else:\n",
    "        tn_m1+=1\n",
    "\n",
    "p_m1=-1\n",
    "r_m1=-1\n",
    "if(tp_m1 + fp_m1 > 0):\n",
    "    p_m1 = tp_m1/(tp_m1 + fp_m1)\n",
    "if(tp_m1 + fn_m1):\n",
    "    r_m1 = tp_m1 / (tp_m1 + fn_m1)\n",
    "\n",
    "print(\"Predicter Median 1\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m1,\"\\t|\\t\", fp_m1, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m1, \"\\t|\\t\", tn_m1, \"\\t|\")\n",
    "if p_m1 > 0:\n",
    "    print(\"Presicion \", p_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m1 > 0:\n",
    "    print(\"Recall \", r_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m1 > 0 and r_m1 > 0):\n",
    "    print(\"Accuracy \", (tp_m1 + fp_m1) / (tp_m1 + fp_m1 + tn_m1 + fn_m1))\n",
    "    print(\"E-measure \", 2*p_m1*r_m1/(p_m1 + r_m1))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c2) ):\n",
    "    if(clasificador2.m2[i] == 1 and medians[i]==2):\n",
    "        tp_m2+=1\n",
    "    elif(clasificador2.m2[i] == 0 and medians[i]==2):\n",
    "        fn_m2+=1\n",
    "    elif(clasificador2.m2[i] == 1 and medians[i]!=2):\n",
    "        fp_m2+=1\n",
    "    else:\n",
    "        tn_m2+=1\n",
    "\n",
    "p_m2=-1\n",
    "r_m2=-1\n",
    "if(tp_m2 + fp_m2 > 0):\n",
    "    p_m2 = tp_m2/(tp_m2 + fp_m2)\n",
    "if(tp_m2 + fn_m2):\n",
    "    r_m2 = tp_m2 / (tp_m2 + fn_m2)\n",
    "\n",
    "print(\"Predicter Median 2\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m2,\"\\t|\\t\", fp_m2, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m2, \"\\t|\\t\", tn_m2, \"\\t|\")\n",
    "if p_m2 > 0:\n",
    "    print(\"Presicion \", p_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m2 > 0:\n",
    "    print(\"Recall \", r_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m2 > 0 and r_m2 > 0):\n",
    "    print(\"Accuracy \", (tp_m2 + fp_m2) / (tp_m2 + fp_m2 + tn_m2 + fn_m2))\n",
    "    print(\"E-measure \", 2*p_m2*r_m2/(p_m2 + r_m2))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c3) ):\n",
    "    if(clasificador2.m3[i] == 1 and medians[i]==3):\n",
    "        tp_m3+=1\n",
    "    elif(clasificador2.m3[i] == 0 and medians[i]==3):\n",
    "        fn_m3+=1\n",
    "    elif(clasificador2.m3[i] == 1 and medians[i]!=3):\n",
    "        fp_m3+=1\n",
    "    else:\n",
    "        tn_m3+=1\n",
    "\n",
    "p_m3=-1\n",
    "r_m3=-1\n",
    "if(tp_m3 + fp_m3 > 0):\n",
    "    p_m3 = tp_m3/(tp_m3 + fp_m3)\n",
    "if(tp_m3 + fn_m3):\n",
    "    r_m3 = tp_m3 / (tp_m3 + fn_m3)\n",
    "\n",
    "print(\"Predicter Median 3\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m3,\"\\t|\\t\", fp_m3, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m3, \"\\t|\\t\", tn_m3, \"\\t|\")\n",
    "if p_m3 > 0:\n",
    "    print(\"Presicion \", p_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m3 > 0:\n",
    "    print(\"Recall \", r_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m3 > 0 and r_m3 > 0):\n",
    "    print(\"Accuracy \", (tp_m3 + fp_m3) / (tp_m3 + fp_m3 + tn_m3 + fn_m3))\n",
    "    print(\"E-measure \", 2*p_m3*r_m3/(p_m3 + r_m3))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c4) ):\n",
    "    if(clasificador2.m4[i] == 1 and medians[i]==4):\n",
    "        tp_m4+=1\n",
    "    elif(clasificador2.m4[i] == 0 and medians[i]==4):\n",
    "        fn_m4+=1\n",
    "    elif(clasificador2.m4[i] == 1 and medians[i]!=4):\n",
    "        fp_m4+=1\n",
    "    else:\n",
    "        tn_m4+=1\n",
    "\n",
    "p_m4=-1\n",
    "r_m4=-1\n",
    "if(tp_m4 + fp_m4 > 0):\n",
    "    p_m4 = tp_m4/(tp_m4 + fp_m4)\n",
    "if(tp_m4 + fn_m4):\n",
    "    r_m4 = tp_m4 / (tp_m4 + fn_m4)\n",
    "\n",
    "print(\"Predicter Median 4\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m4,\"\\t|\\t\", fp_m4, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m4, \"\\t|\\t\", tn_m4, \"\\t|\")\n",
    "if p_m4 > 0:\n",
    "    print(\"Presicion \", p_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m4 > 0:\n",
    "    print(\"Recall \", r_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m4 > 0 and r_m4 > 0):\n",
    "    print(\"Accuracy \", (tp_m4 + fp_m4) / (tp_m4 + fp_m4 + tn_m4 + fn_m4))\n",
    "    print(\"E-measure \", 2*p_m4*r_m4/(p_m4 + r_m4))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c5) ):\n",
    "    if(clasificador2.m5[i] == 1 and medians[i]==5):\n",
    "        tp_m5+=1\n",
    "    elif(clasificador2.m5[i] == 0 and medians[i]==5):\n",
    "        fn_m5+=1\n",
    "    elif(clasificador2.m5[i] == 1 and medians[i]!=5):\n",
    "        fp_m5+=1\n",
    "    else:\n",
    "        tn_m5+=1\n",
    "\n",
    "p_m5=-1\n",
    "r_m5=-1\n",
    "if(tp_m5 + fp_m5 > 0):\n",
    "    p_m5 = tp_m5/(tp_m5 + fp_m5)\n",
    "if(tp_m5 + fn_m5):\n",
    "    r_m5 = tp_m5 / (tp_m5 + fn_m5)\n",
    "\n",
    "print(\"Predicter Median 5\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m5,\"\\t|\\t\", fp_m5, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m5, \"\\t|\\t\", tn_m5, \"\\t|\")\n",
    "if p_m5 > 0:\n",
    "    print(\"Presicion \", p_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m5 > 0:\n",
    "    print(\"Recall \", r_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m5 > 0 and r_m5 > 0):\n",
    "    print(\"Accuracy \", (tp_m5 + fp_m5) / (tp_m5 + fp_m5 + tn_m5 + fn_m5))\n",
    "    print(\"E-measure \", 2*p_m5*r_m5/(p_m5 + r_m5))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c0) ):\n",
    "    if(clasificador2.m0[i] == 1 and medians[i]==0):\n",
    "        tp_m0+=1\n",
    "    elif(clasificador2.m0[i] == 0 and medians[i]==0):\n",
    "        fn_m0+=1\n",
    "    elif(clasificador2.m0[i] == 1 and medians[i]!=0):\n",
    "        fp_m0+=1\n",
    "    else:\n",
    "        tn_m0+=1\n",
    "\n",
    "p_m0=-1\n",
    "r_m0=-1\n",
    "if(tp_m0 + fp_m0 > 0):\n",
    "    p_m0 = tp_m0/(tp_m0 + fp_m0)\n",
    "if(tp_m0 + fn_m0):\n",
    "    r_m0 = tp_m0 / (tp_m0 + fn_m0)\n",
    "\n",
    "print(\"Predicter Median 0\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m0,\"\\t|\\t\", fp_m0, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m0, \"\\t|\\t\", tn_m0, \"\\t|\")\n",
    "if p_m0 > 0:\n",
    "    print(\"Presicion \", p_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m0 > 0:\n",
    "    print(\"Recall \", r_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m0 > 0 and r_m0 > 0):\n",
    "    print(\"Accuracy \", (tp_m0 + fp_m0) / (tp_m0 + fp_m0 + tn_m0 + fn_m0))\n",
    "    print(\"E-measure \", 2*p_m0*r_m0/(p_m0 + r_m0))\n",
    "    \n",
    "print(\"Confusion matrix\")\n",
    "print(\"\\t 0 \\t 1 \\t 2 \\t 3 \\t 4 \\t 5 \")\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c0_predict)):\n",
    "    if(medians[pos] != 0 and clasificador2.predicts[pos] == 0):\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"0 \\t\", tp_m0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c1_predict)):\n",
    "    if(medians[pos] != 1 and clasificador2.predicts[pos] == 1):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"1 \\t\", conf0, \"\\t\", tp_m1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c2_predict)):\n",
    "    if(medians[pos] != 2 and clasificador2.predicts[pos] == 2):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"2 \\t\", conf0, \"\\t\", conf1, \"\\t\", tp_m2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c3_predict)):\n",
    "    if(medians[pos] != 3 and clasificador2.predicts[pos] == 3):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"3 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", tp_m3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c4_predict)):\n",
    "    if(medians[pos] != 4 and clasificador2.predicts[pos] == 4):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"4 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", tp_m4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c5_predict)):\n",
    "    if(medians[pos] != 5 and clasificador2.predicts[pos] == 5):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "print(\"5 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", tp_m5);\n",
    "\n",
    "print(\"Macro averaging\")\n",
    "macropresicion=(tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) / ( (tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) + (fp_m0 + fp_m1 + fp_m2 + fp_m3 + fp_m4 + fp_m5))\n",
    "macrorecall=(tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) / ( (tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) + (fn_m0 + fn_m1 + fn_m2 + fn_m3 + fn_m4 + fn_m5))\n",
    "macrof=2*macropresicion*macrorecall/(macrorecall + macropresicion)\n",
    "print(\"Precision \", macropresicion, \" Recall\", macrorecall, \" F\", macrof)\n",
    "\n",
    "print(\"Micro averaging\")\n",
    "micropresicion=(p_m0 + p_m1 + p_m2 + p_m3 + p_m4 + p_m5)/6\n",
    "microrecall=(p_m0 + r_m1 + r_m2 + r_m3 + r_m4 + r_m5)/6\n",
    "microf=2*micropresicion*microrecall/(micropresicion + microrecall)\n",
    "print(\"Precision \", micropresicion, \" Recall\", microrecall, \" F\", microf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de medidas para las medianas hecho de forma independiente, se presentan las tablas de contingencia de las predicciones de los clasificadores binarios sin tener en cuenta las probabilidades de los otros clasificadores binarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicter Median 1\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 3 \t|\t 4 \t|\n",
      "system negative|\t 99 \t|\t 514 \t|\n",
      "Presicion  0.42857142857142855\n",
      "Recall  0.029411764705882353\n",
      "Accuracy  0.01129032258064516\n",
      "E-measure  0.055045871559633024\n",
      "Predicter Median 2\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 3 \t|\n",
      "system negative|\t 95 \t|\t 522 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 3\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 4 \t|\t 4 \t|\n",
      "system negative|\t 106 \t|\t 506 \t|\n",
      "Presicion  0.5\n",
      "Recall  0.03636363636363636\n",
      "Accuracy  0.012903225806451613\n",
      "E-measure  0.06779661016949153\n",
      "Predicter Median 4\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 3 \t|\n",
      "system negative|\t 57 \t|\t 560 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 5\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 11 \t|\t 609 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 0\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 135 \t|\t 67 \t|\n",
      "system negative|\t 110 \t|\t 308 \t|\n",
      "Presicion  0.6683168316831684\n",
      "Recall  0.5510204081632653\n",
      "Accuracy  0.3258064516129032\n",
      "E-measure  0.6040268456375838\n"
     ]
    }
   ],
   "source": [
    "#Variables para las medianas\n",
    "tp_m1=0\n",
    "fp_m1=0\n",
    "tn_m1=0\n",
    "fn_m1=0\n",
    "\n",
    "tp_m2=0\n",
    "fp_m2=0\n",
    "tn_m2=0\n",
    "fn_m2=0\n",
    "\n",
    "tp_m3=0\n",
    "fp_m3=0\n",
    "tn_m3=0\n",
    "fn_m3=0\n",
    "\n",
    "tp_m4=0\n",
    "fp_m4=0\n",
    "tn_m4=0\n",
    "fn_m4=0\n",
    "\n",
    "tp_m5=0\n",
    "fp_m5=0\n",
    "tn_m5=0\n",
    "fn_m5=0\n",
    "\n",
    "tp_m0=0\n",
    "fp_m0=0\n",
    "tn_m0=0\n",
    "fn_m0=0\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c1) ):\n",
    "    if(clasificador2.median_list_c1[i] == 1 and clasificador2.c1_predict[i]==1):\n",
    "        tp_m1+=1\n",
    "    elif(clasificador2.median_list_c1[i] == 1 and clasificador2.c1_predict[i]==0):\n",
    "        fn_m1+=1\n",
    "    elif(clasificador2.median_list_c1[i] == 0 and clasificador2.c1_predict[i]==1):\n",
    "        fp_m1+=1\n",
    "    else:\n",
    "        tn_m1+=1\n",
    "\n",
    "p_m1=-1\n",
    "r_m1=-1\n",
    "if(tp_m1 + fp_m1 > 0):\n",
    "    p_m1 = tp_m1/(tp_m1 + fp_m1)\n",
    "if(tp_m1 + fn_m1):\n",
    "    r_m1 = tp_m1 / (tp_m1 + fn_m1)\n",
    "\n",
    "print(\"Predicter Median 1\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m1,\"\\t|\\t\", fp_m1, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m1, \"\\t|\\t\", tn_m1, \"\\t|\")\n",
    "if p_m1 > 0:\n",
    "    print(\"Presicion \", p_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m1 > 0:\n",
    "    print(\"Recall \", r_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m1 > 0 and r_m1 > 0):\n",
    "    print(\"Accuracy \", (tp_m1 + fp_m1) / (tp_m1 + fp_m1 + tn_m1 + fn_m1))\n",
    "    print(\"E-measure \", 2*p_m1*r_m1/(p_m1 + r_m1))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c2) ):\n",
    "    if(clasificador2.median_list_c2[i] == 1 and clasificador2.c2_predict[i]==1):\n",
    "        tp_m2+=1\n",
    "    elif(clasificador2.median_list_c2[i] == 1 and clasificador2.c2_predict[i]==0):\n",
    "        fn_m2+=1\n",
    "    elif(clasificador2.median_list_c2[i] == 0 and clasificador2.c2_predict[i]==1):\n",
    "        fp_m2+=1\n",
    "    else:\n",
    "        tn_m2+=1\n",
    "\n",
    "p_m2=-1\n",
    "r_m2=-1\n",
    "if(tp_m2 + fp_m2 > 0):\n",
    "    p_m2 = tp_m2/(tp_m2 + fp_m2)\n",
    "if(tp_m2 + fn_m2):\n",
    "    r_m2 = tp_m2 / (tp_m2 + fn_m2)\n",
    "\n",
    "print(\"Predicter Median 2\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m2,\"\\t|\\t\", fp_m2, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m2, \"\\t|\\t\", tn_m2, \"\\t|\")\n",
    "if p_m2 > 0:\n",
    "    print(\"Presicion \", p_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m2 > 0:\n",
    "    print(\"Recall \", r_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m2 > 0 and r_m2 > 0):\n",
    "    print(\"Accuracy \", (tp_m2 + fp_m2) / (tp_m2 + fp_m2 + tn_m2 + fn_m2))\n",
    "    print(\"E-measure \", 2*p_m2*r_m2/(p_m2 + r_m2))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c3) ):\n",
    "    if(clasificador2.median_list_c3[i] == 1 and clasificador2.c3_predict[i]==1):\n",
    "        tp_m3+=1\n",
    "    elif(clasificador2.median_list_c3[i] == 1 and clasificador2.c3_predict[i]==0):\n",
    "        fn_m3+=1\n",
    "    elif(clasificador2.median_list_c3[i] == 0 and clasificador2.c3_predict[i]==1):\n",
    "        fp_m3+=1\n",
    "    else:\n",
    "        tn_m3+=1\n",
    "\n",
    "p_m3=-1\n",
    "r_m3=-1\n",
    "if(tp_m3 + fp_m3 > 0):\n",
    "    p_m3 = tp_m3/(tp_m3 + fp_m3)\n",
    "if(tp_m3 + fn_m3):\n",
    "    r_m3 = tp_m3 / (tp_m3 + fn_m3)\n",
    "\n",
    "print(\"Predicter Median 3\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m3,\"\\t|\\t\", fp_m3, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m3, \"\\t|\\t\", tn_m3, \"\\t|\")\n",
    "if p_m3 > 0:\n",
    "    print(\"Presicion \", p_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m3 > 0:\n",
    "    print(\"Recall \", r_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m3 > 0 and r_m3 > 0):\n",
    "    print(\"Accuracy \", (tp_m3 + fp_m3) / (tp_m3 + fp_m3 + tn_m3 + fn_m3))\n",
    "    print(\"E-measure \", 2*p_m3*r_m3/(p_m3 + r_m3))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c4) ):\n",
    "    if(clasificador2.median_list_c4[i] == 1 and clasificador2.c4_predict[i]==1):\n",
    "        tp_m4+=1\n",
    "    elif(clasificador2.median_list_c4[i] == 1 and clasificador2.c4_predict[i]==0):\n",
    "        fn_m4+=1\n",
    "    elif(clasificador2.median_list_c4[i] == 0 and clasificador2.c4_predict[i]==1):\n",
    "        fp_m4+=1\n",
    "    else:\n",
    "        tn_m4+=1\n",
    "\n",
    "p_m4=-1\n",
    "r_m4=-1\n",
    "if(tp_m4 + fp_m4 > 0):\n",
    "    p_m4 = tp_m4/(tp_m4 + fp_m4)\n",
    "if(tp_m4 + fn_m4):\n",
    "    r_m4 = tp_m4 / (tp_m4 + fn_m4)\n",
    "\n",
    "print(\"Predicter Median 4\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m4,\"\\t|\\t\", fp_m4, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m4, \"\\t|\\t\", tn_m4, \"\\t|\")\n",
    "if p_m4 > 0:\n",
    "    print(\"Presicion \", p_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m4 > 0:\n",
    "    print(\"Recall \", r_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m4 > 0 and r_m4 > 0):\n",
    "    print(\"Accuracy \", (tp_m4 + fp_m4) / (tp_m4 + fp_m4 + tn_m4 + fn_m4))\n",
    "    print(\"E-measure \", 2*p_m4*r_m4/(p_m4 + r_m4))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c5) ):\n",
    "    if(clasificador2.median_list_c5[i] == 1 and clasificador2.c5_predict[i]==1):\n",
    "        tp_m5+=1\n",
    "    elif(clasificador2.median_list_c5[i] == 1 and clasificador2.c5_predict[i]==0):\n",
    "        fn_m5+=1\n",
    "    elif(clasificador2.median_list_c5[i] == 0 and clasificador2.c5_predict[i]==1):\n",
    "        fp_m5+=1\n",
    "    else:\n",
    "        tn_m5+=1\n",
    "\n",
    "p_m5=-1\n",
    "r_m5=-1\n",
    "if(tp_m5 + fp_m5 > 0):\n",
    "    p_m5 = tp_m5/(tp_m5 + fp_m5)\n",
    "if(tp_m5 + fn_m5):\n",
    "    r_m5 = tp_m5 / (tp_m5 + fn_m5)\n",
    "\n",
    "print(\"Predicter Median 5\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m5,\"\\t|\\t\", fp_m5, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m5, \"\\t|\\t\", tn_m5, \"\\t|\")\n",
    "if p_m5 > 0:\n",
    "    print(\"Presicion \", p_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m5 > 0:\n",
    "    print(\"Recall \", r_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m5 > 0 and r_m5 > 0):\n",
    "    print(\"Accuracy \", (tp_m5 + fp_m5) / (tp_m5 + fp_m5 + tn_m5 + fn_m5))\n",
    "    print(\"E-measure \", 2*p_m5*r_m5/(p_m5 + r_m5))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c0) ):\n",
    "    if(clasificador2.median_list_c0[i] == 1 and clasificador2.c0_predict[i]==1):\n",
    "        tp_m0+=1\n",
    "    elif(clasificador2.median_list_c0[i] == 1 and clasificador2.c0_predict[i]==0):\n",
    "        fn_m0+=1\n",
    "    elif(clasificador2.median_list_c0[i] == 0 and clasificador2.c0_predict[i]==1):\n",
    "        fp_m0+=1\n",
    "    else:\n",
    "        tn_m0+=1\n",
    "\n",
    "p_m0=-1\n",
    "r_m0=-1\n",
    "if(tp_m0 + fp_m0 > 0):\n",
    "    p_m0 = tp_m0/(tp_m0 + fp_m0)\n",
    "if(tp_m0 + fn_m0):\n",
    "    r_m0 = tp_m0 / (tp_m0 + fn_m0)\n",
    "\n",
    "print(\"Predicter Median 0\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m0,\"\\t|\\t\", fp_m0, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m0, \"\\t|\\t\", tn_m0, \"\\t|\")\n",
    "if p_m0 > 0:\n",
    "    print(\"Presicion \", p_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m0 > 0:\n",
    "    print(\"Recall \", r_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m0 > 0 and r_m0 > 0):\n",
    "    print(\"Accuracy \", (tp_m0 + fp_m0) / (tp_m0 + fp_m0 + tn_m0 + fn_m0))\n",
    "    print(\"E-measure \", 2*p_m0*r_m0/(p_m0 + r_m0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador 1 sin información de Pos-tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro3.csv\",encoding='utf-8')\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4)*20/100)\n",
    "#Se generan posiciones en el arreglo tweets al azar que representen el 20% del corpus actual\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4['text'][:]\n",
    "vec_category=corpus_filtro4['category'][:]\n",
    "\n",
    "#Se separa el 20% de corpus para desarrollo del 80% para entrenamiento\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "\n",
    "#Se guardan las instancias corpus de desarrollo en corpus_filtro5_devset.csv\n",
    "#y corpus de entrenamiento en corpus_filtro5_trainingset.csv\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_no_postag.csv')\n",
    "\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_no_postag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas para el clasificador 1\n",
      "Precision:  0.7463126843657817\n",
      "Recall:  0.7737003058103975\n",
      "Accuracy  0.5441412520064205\n",
      "E-measure  0.7597597597597597\n"
     ]
    }
   ],
   "source": [
    "corpus_filtro5_devset = pandas.read_csv(\"corpus_filtro5_devset_no_postag.csv\",encoding='utf-8')\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 1\n",
    "list_cat_1 = []\n",
    "list_ecat_1 = []\n",
    "\n",
    "\n",
    "list_cat_1=corpus_filtro5_devset['category'][:]\n",
    "\n",
    "clasificador = Clasificador1(\"corpus_filtro5_trainingset_no_postag.csv\")\n",
    "list_ecat_1  = clasificador.predict_clasiffier_1(\"corpus_filtro5_devset_no_postag.csv\")\n",
    "\n",
    "#Variables para clasificador 1\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_1) ):\n",
    "    if(list_cat_1[i] == 1 and list_ecat_1[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_1[i] == 1 and list_ecat_1[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_1[i] == 0 and list_ecat_1[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 1 sin post-tag\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La medida de Acuracy nos dice que el clasificador 1 tiene un 55% de los tweets etiquetados correctamente, esta medida puede ser tenida en cuenta como valedera debido a que los tweets chistosos y no chistosos están balanceados en el conjunto de entrenamiento para el clasificador 1.\n",
    "La medida F para el clasificador 1 marca 0.77.\n",
    "\n",
    "El clasificador 2 es el mismo que el clasificador 1, la variación se explica debido a que el conjunto de desarrollo fue elegido al azar y es distinto al conjunto de desarrollo del clasificador 1. De todas maneras las diferencias en las medidas no son notorias, salvo el Recall que para el clasificador 1 arrojó 0.80 y para el clasificador 2 bajó 0.04 puntos para medir un 0.76. Esto se puede explicar debido a un aumento de falsos negativos en las predicciones para el clasificador 2.\n",
    "\n",
    "El clasificador 3 por su parte arroja una alta Acurracy, pero el conjunto de desarrollo está desbalanceado, 149 tweets son considerados no humoristicos en comparación con los restantes 459 tweets considerados como humorísticos. La F-measure marcó un 0.88. Las medidas que componen la F-measure son Presicion y Recall, la primera marcó 0.81 y la segunda marcó una elevada puntuación de 0.96. Esto quiere decir que los errores mayormente cometidos por el clasificador están en la generación de falsos positivos, es decir tweets clasificados como humorísticos pero que en realidad no lo son. Parece aceptable la disminución de falsos negativos, y la consiguiente disminución del recall, en favor de una disminución de los falsos positivos y por consiguiente un aumento de la Presicion. Habrá que estudiar los resultados para determinar de que forma hacer esto.\n",
    "\n",
    "Los resutados del clasificador 1 y 2 no pueden ser comparables con los resultados del clasificador 3 debido a que la definición de tweets humorístico para el clasificador 1 y 2 difiere de la definición empleada en la clasificación del clasificador 3.\n",
    "\n",
    "Para el clasificador 3 una primera mejora puede venir del análisis de los casos clasificados como falsos positivos y agregar alguna regla pos-clasificación en caso de encontrar un patròn en dichos casos. Hay que tener cuidado con el sobre entrenamiento ya que las reglas podrían estar ajustando demasiado el clasificador al conjunto de desarrollo.\n",
    "\n",
    "Para el clasificador dado en 1 y 2 se deberían analizar los casos para los cuales se clasfició mal y tratar de inferir patrones comunes para estos casos, una solución es agregar reglas de pos-procesamiento, pero se puede caer en el problema de sobre entrenamiento. Otra posibilidad es estudiar los patrones sintácticos en los casos de error, lemas, cantidad de palabras desconocidas, estructuras de los árboles sintácticos y agregar como features información lèxica y sintáctica inferida de estudiar los resultados en estos casos.\n",
    "\n",
    "En cuanto a la predicción de las medianas, en la matriz de confusión lo primero que se puede apreciar es la baja taza de verdaderos positivos y falsos positivos para los valores de mediana 1 y 5. También se nota que las predicciones actuales funcionan mejor para detectar verdaderos negativos que para detectar verdaderos positivos. Los clasificadores binarios para las medianas con valores 0 y 3 fueron los que con mayor éxito pudieron detectar verdaderos positivos. Para cada fila en la matriz de confusión se puede observar que la distribución de los falsos positivos en las columnas es bastante uniforme. Mientras que observando las columnas se puede apreciar que la distribución de falsos negativos está más que nada concentrada en las medianas 0 y 3. Este comportamiento puede deberse a la predominacia de tweets con medianas 0 y 3 en el training set y development set.\n",
    "Se realizó el cálculo de microaveraging y macroaveraging para la predicción de medianas, arrojando valores muy bajos para la Presicion y Recall. Posibles mejoras a cada clasificador binario sería estudiar porque los clasificadores binarios para medianas 1,2,4,5 arrojaron medidas bajas y tratar de mejorar su funcionamiento. También cualquier modificación al clasificador 2, pos-procesamiento o incorporación de features pueden incidir positiva o negativamente en la predicción de las medianas.\n",
    "\n",
    "La conclusión más importante es que hay mucho por trabajar en los clasificadores diseñados, antes de realizar la comparación entre ellos a través de correr el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_f = []\n",
    "\n",
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro1 = pandas.read_csv(\"corpus_humor_testing.csv\",encoding='utf-8')\n",
    "\n",
    "#Generacion de patron de Hashtag\n",
    "pattern_hashtag = re.compile(r'#.+?\\b')\n",
    "\n",
    "\n",
    "#Se sustituye el Hashtag por el string vacio, los tweets que\n",
    "#van pasando por este procesamiento se van guardando en el arreglo\n",
    "#text_f\n",
    "for i in range(len(corpus_filtro1)):\n",
    "    text_f.append(re.sub(pattern_hashtag, \"\", corpus_filtro1['text'][i]))\n",
    "#El segundo filtro aplicado es guardado en el archivo corpus_filtro2.csv\n",
    "d = {'id' : corpus_filtro1['id'][:],\n",
    "    'text' : text_f,\n",
    "    'account_id': corpus_filtro1['account_id'][:],\n",
    "    'n':corpus_filtro1['n'][:], \n",
    "    '1':corpus_filtro1['1'][:],\n",
    "    '2':corpus_filtro1['2'][:],\n",
    "    '3':corpus_filtro1['3'][:],\n",
    "    '4':corpus_filtro1['4'][:],\n",
    "    '5':corpus_filtro1['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_humor_testing_no_hashtags.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar Category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro2 = pandas.read_csv(\"corpus_humor_testing_no_hashtags.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "text = []\n",
    "category=[]\n",
    "h1=[]\n",
    "h2=[]\n",
    "h3=[]\n",
    "h4=[]\n",
    "h5=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_text=corpus_filtro2['text'][:]\n",
    "vec_no_humor =corpus_filtro2['n'][:]\n",
    "vec_e1 =corpus_filtro2['1'][:]\n",
    "vec_e2 =corpus_filtro2['2'][:]\n",
    "vec_e3 =corpus_filtro2['3'][:]\n",
    "vec_e4 =corpus_filtro2['4'][:]\n",
    "vec_e5 =corpus_filtro2['5'][:]\n",
    "\n",
    "#Si hay igual o mas votos de humor que de no humor la categoria tiene el valor 1\n",
    "#en caso contrario tiene el valor 0\n",
    "for i in range(len(corpus_filtro2)):\n",
    "    if  vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= vec_no_humor[i]:\n",
    "        category.append(1)\n",
    "    else:\n",
    "        category.append(0)\n",
    "    text.append(vec_text[i])\n",
    "    h1.append(vec_e1[i])\n",
    "    h2.append(vec_e2[i])\n",
    "    h3.append(vec_e3[i])\n",
    "    h4.append(vec_e4[i])\n",
    "    h5.append(vec_e5[i])\n",
    "#El tercer procesamiento aplicado sobre los tweets es guardado en el archivo corpus_filtro.3\n",
    "d = {'text' : text,\n",
    "    'category': category,\n",
    "     'n': vec_no_humor,\n",
    "     '1':h1,\n",
    "     '2':h2,\n",
    "     '3':h3,\n",
    "     '4':h4,\n",
    "     '5':h5\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category', 'n', '1','2','3','4','5'])\n",
    "df.to_csv('corpus_humor_testing_no_hashtags_with_category.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar Medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia salvada del corpus que se encuentra en el archivo\n",
    "#corpus_filtro4.csv\n",
    "corpus_filtro4 = pandas.read_csv(\"corpus_humor_testing_no_hashtags_with_category.csv\",encoding='utf-8')\n",
    "\n",
    "text_list=corpus_filtro4['text'][:]\n",
    "category_list=corpus_filtro4['category'][:]\n",
    "\n",
    "n_list=corpus_filtro4['n'][:]\n",
    "h1_list=corpus_filtro4['1'][:]\n",
    "h2_list=corpus_filtro4['2'][:]\n",
    "h3_list=corpus_filtro4['3'][:]\n",
    "h4_list=corpus_filtro4['4'][:]\n",
    "h5_list=corpus_filtro4['5'][:]\n",
    "\n",
    "medians=[]\n",
    "pos=0\n",
    "\n",
    "#Caclulo de la mediana, en values se expanden los votos de cada estrella\n",
    "#de la siguiente manera si #cant_3Estrellas_en_tweet = 4, entonces se guardan\n",
    "#en values 4 treses 3,3,3,3 para permitir el calculo de la mediana\n",
    "#Por ultimo en la estructura medians se guarda el valor discreto (0,1,2,3,4 o 5) de la mediana\n",
    "#si la cantidad de votos es par se toma el voto del medio con valor mas grande\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    values = []\n",
    "    for j in range( h1_list[i]):\n",
    "        values.append(1)\n",
    "    for j in range( h2_list[i] ):\n",
    "        values.append(2)\n",
    "    for j in range( h3_list[i] ):\n",
    "        values.append(3)\n",
    "    for j in range( h4_list[i] ):\n",
    "        values.append(4)\n",
    "    for j in range( h5_list[i] ):\n",
    "        values.append(5)\n",
    "    for j in range( n_list[i] ):\n",
    "        values.append(0)\n",
    "    mediana=np.median(values)\n",
    "    if( len(values) % 2 == 1 ):\n",
    "        medians.append(math.floor(mediana))\n",
    "    else:\n",
    "        for i in values:\n",
    "            if( i >= mediana):\n",
    "                medians.append(i)\n",
    "                break\n",
    "    pos+=1\n",
    "\n",
    "    \n",
    "#El nuevo procesamiento que suma la informacion de la mediana se guarda\n",
    "#en el archivo corpus_filtro4median.csv\n",
    "d = {'text' : corpus_filtro4['text'][:],\n",
    "    'category' : corpus_filtro4['category'][:],\n",
    "    'median': medians,\n",
    "     'n':corpus_filtro4['n'][:],\n",
    "    '1':corpus_filtro4['1'][:],\n",
    "    '2':corpus_filtro4['2'][:],\n",
    "    '3':corpus_filtro4['3'][:],\n",
    "    '4':corpus_filtro4['4'][:],\n",
    "    '5':corpus_filtro4['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', 'median', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_humor_testing_no_hashtags_with_category_and_median.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar category_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4median = pandas.read_csv(\"corpus_humor_testing_no_hashtags_with_category_and_median.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro4median['text'][:]\n",
    "category_list=corpus_filtro4median['category'][:]\n",
    "category_2_list=[]\n",
    "median_list=corpus_filtro4median['median'][:]\n",
    "category_list=corpus_filtro4median['category'][:]\n",
    "n_list=corpus_filtro4median['n'][:]\n",
    "h1_list=corpus_filtro4median['1'][:]\n",
    "h2_list=corpus_filtro4median['2'][:]\n",
    "h3_list=corpus_filtro4median['3'][:]\n",
    "h4_list=corpus_filtro4median['4'][:]\n",
    "h5_list=corpus_filtro4median['5'][:]\n",
    "pos=0\n",
    "for m in median_list:\n",
    "    if(m<1):\n",
    "        category_2_list.append(0)\n",
    "    else:\n",
    "        category_2_list.append(1)\n",
    "    pos+=1\n",
    "d = {'text' : text_list,\n",
    "    'category': category_list,\n",
    "     'median': median_list,\n",
    "     'category_2': category_2_list,\n",
    "     'n': n_list,\n",
    "     '1': h1_list,\n",
    "     '2': h2_list,\n",
    "     '3': h3_list,\n",
    "     '4':h4_list,\n",
    "     '5':h5_list\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category','median', 'category_2', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_humor_testing_no_hashtags_with_category_and_median_and_category_2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar información de post-tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   0 %\r"
     ]
    }
   ],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro3 = pandas.read_csv(\"corpus_humor_testing_no_hashtags_with_category_and_median_and_category_2.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro3['text'][:5]\n",
    "\n",
    "#Se genera el patron para identificar las POS de las palabras\n",
    "pattern_pos = re.compile(r'pos=\"(.*?)\"')\n",
    "\n",
    "#Variables para datos estadisticos\n",
    "num_sentences=len(corpus_filtro3)\n",
    "numsentence=1\n",
    "\n",
    "#Variable auxiliar para adherir las POS a los tweets\n",
    "pos=0\n",
    "\n",
    "#Para cada documento en el corpus de tweets que va siendo procesado\n",
    "#utilizando la herramienta freeling se analizan las categorias gramaticales\n",
    "#de todas las palabras que aparecen en cada tweet y esta informacion es\n",
    "#adherida al texto del tweet\n",
    "for d in text_list:\n",
    "    if(type(d) == str):\n",
    "        xml = analyzer.run(d.encode(), 'flush')\n",
    "        print(numsentence, \" \", math.floor( numsentence/num_sentences*100),\"%\", end=\"\\r\")\n",
    "        for sentence in xml:        \n",
    "            for token in sentence:\n",
    "                token_byte=etree.tostring(token)\n",
    "                m = re.search(pattern_pos, token_byte.decode())\n",
    "                if m is not None:\n",
    "                    text_list[ pos] = text_list[pos] + \" \" + m.group(1)\n",
    "    pos+=1\n",
    "    numsentence+=1\n",
    "\n",
    "#El procesamiento actual del corpus es guardado en el documento corpus_filtro4.csv\n",
    "d = {'text' : text_list[:5],\n",
    "    'category': corpus_filtro3['category'][:5],   \n",
    "     'median':corpus_filtro3['median'][:5],\n",
    "     'category_2':corpus_filtro3['category_2'][:5],\n",
    "     'n':corpus_filtro3['n'][:5], \n",
    "     '1':corpus_filtro3['1'][:5],\n",
    "     '2':corpus_filtro3['2'][:5],\n",
    "     '3':corpus_filtro3['3'][:5],\n",
    "     '4':corpus_filtro3['4'][:5],\n",
    "     '5':corpus_filtro3['5'][:5]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', 'median', 'category_2', 'n', '1','2','3','4','5'])\n",
    "df.to_csv('corpus_humor_testing_no_hashtags_with_category_and_median_and_category_2_and_postag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas para el clasificador 1 sin pos tag\n",
      "Precision:  0.5\n",
      "Recall:  1.0\n",
      "Accuracy  0.4\n",
      "E-measure  0.6666666666666666\n",
      "Medidas para el clasificador 1\n",
      "Precision:  0.5\n",
      "Recall:  0.5\n",
      "Accuracy  0.4\n",
      "E-measure  0.5\n",
      "Medidas para el clasificador 2\n",
      "Precision:  1.0\n",
      "Recall:  0.6666666666666666\n",
      "Accuracy  0.4\n",
      "E-measure  0.8\n",
      "Medidas para el clasificador 3\n",
      "Precision:  0.3333333333333333\n",
      "Recall:  1.0\n",
      "Accuracy  0.6\n",
      "E-measure  0.5\n",
      "Predicter Median 1\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 0 \t|\t 5 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 2\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 2 \t|\t 3 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 3\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 0 \t|\t 5 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 4\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 1 \t|\t 4 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 5\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 0 \t|\t 5 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 0\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 3 \t|\n",
      "system negative|\t 0 \t|\t 0 \t|\n",
      "Presicion  0.4\n",
      "Recall  1.0\n",
      "Accuracy  1.0\n",
      "E-measure  0.5714285714285715\n",
      "Confusion matrix\n",
      "\t 0 \t 1 \t 2 \t 3 \t 4 \t 5 \n",
      "0 \t 2 \t 0 \t 2 \t 0 \t 1 \t 0\n",
      "1 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "2 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "3 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "4 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "5 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "Macro averaging\n",
      "Precision  0.4  Recall 0.4  F 0.4000000000000001\n",
      "Micro averaging\n",
      "Precision  0.06666666666666667  Recall 0.16666666666666666  F 0.09523809523809522\n"
     ]
    }
   ],
   "source": [
    "corpus_filtro5_devset_no_postag = pandas.read_csv(\"corpus_filtro5_devset_no_postag.csv\",encoding='utf-8')\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 1\n",
    "list_cat_1 = []\n",
    "list_ecat_1 = []\n",
    "\n",
    "\n",
    "list_cat_1=corpus_filtro5_devset_no_postag['category'][:5]\n",
    "\n",
    "clasificador = Clasificador1(\"corpus_filtro5_trainingset_no_postag.csv\")\n",
    "list_ecat_1  = clasificador.predict_clasiffier_1(\"corpus_filtro5_devset_no_postag.csv\")\n",
    "\n",
    "#Variables para clasificador 1\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_1) ):\n",
    "    if(list_cat_1[i] == 1 and list_ecat_1[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_1[i] == 1 and list_ecat_1[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_1[i] == 0 and list_ecat_1[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 1 sin pos tag\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "corpus_filtro5_devset = pandas.read_csv(\"corpus_filtro5_devset.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c2 = pandas.read_csv(\"corpus_filtro5_devset_c2.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c3 = pandas.read_csv(\"corpus_filtro5_devset_c3.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 1\n",
    "list_cat_1 = []\n",
    "list_ecat_1 = []\n",
    "\n",
    "\n",
    "list_cat_1=corpus_filtro5_devset['category'][:5]\n",
    "\n",
    "clasificador = Clasificador1(\"corpus_filtro5_trainingset.csv\")\n",
    "list_ecat_1  = clasificador.predict_clasiffier_1(\"corpus_humor_testing_no_hashtags_with_category_and_median_and_category_2_and_postag.csv\")\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 2\n",
    "list_cat_2 = []\n",
    "list_ecat_2 = []\n",
    "list_edem_2=[]\n",
    "medians = []\n",
    "\n",
    "\n",
    "list_cat_2=corpus_filtro5_devset_c2['category'][:5]\n",
    "clasificador2=Clasificador2()\n",
    "list_emed_2, _, list_ecat_2=clasificador2.predict_median(\"corpus_humor_testing_no_hashtags_with_category_and_median_and_category_2_and_postag.csv\")\n",
    "medians=corpus_filtro5_devset_c2['median'][:5];\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 3\n",
    "list_cat_3 = []\n",
    "list_ecat_3 = []\n",
    "\n",
    "list_cat_3=corpus_filtro5_devset_c3['category'][:5]\n",
    "clasificador3 = Clasificador3()\n",
    "list_ecat_3=clasificador3.predict_clasiffier_1(\"corpus_humor_testing_no_hashtags_with_category_and_median_and_category_2_and_postag.csv\", \"category_2\")\n",
    "\n",
    "\n",
    "#Variables para clasificador 1\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_1) ):\n",
    "    if(list_cat_1[i] == 1 and list_ecat_1[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_1[i] == 1 and list_ecat_1[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_1[i] == 0 and list_ecat_1[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 1\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 2\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_2) ):\n",
    "    if(list_cat_2[i] == 1 and list_ecat_2[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_2[i] == 1 and list_ecat_2[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_2[i] == 0 and list_ecat_2[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "\n",
    "print(\"Medidas para el clasificador 2\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 3\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_3) ):\n",
    "    if(list_cat_3[i] == 1 and list_ecat_3[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_3[i] == 1 and list_ecat_3[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_3[i] == 0 and list_ecat_3[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 3\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para las medianas\n",
    "tp_m1=0\n",
    "fp_m1=0\n",
    "tn_m1=0\n",
    "fn_m1=0\n",
    "\n",
    "tp_m2=0\n",
    "fp_m2=0\n",
    "tn_m2=0\n",
    "fn_m2=0\n",
    "\n",
    "tp_m3=0\n",
    "fp_m3=0\n",
    "tn_m3=0\n",
    "fn_m3=0\n",
    "\n",
    "tp_m4=0\n",
    "fp_m4=0\n",
    "tn_m4=0\n",
    "fn_m4=0\n",
    "\n",
    "tp_m5=0\n",
    "fp_m5=0\n",
    "tn_m5=0\n",
    "fn_m5=0\n",
    "\n",
    "tp_m0=0\n",
    "fp_m0=0\n",
    "tn_m0=0\n",
    "fn_m0=0\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c1) ):\n",
    "    if(clasificador2.m1[i] == 1 and medians[i]==1):\n",
    "        tp_m1+=1\n",
    "    elif(clasificador2.m1[i] == 0 and medians[i]==1):\n",
    "        fn_m1+=1\n",
    "    elif(clasificador2.m1[i] == 1 and medians[i]!=1):\n",
    "        fp_m1+=1\n",
    "    else:\n",
    "        tn_m1+=1\n",
    "\n",
    "p_m1=-1\n",
    "r_m1=-1\n",
    "if(tp_m1 + fp_m1 > 0):\n",
    "    p_m1 = tp_m1/(tp_m1 + fp_m1)\n",
    "if(tp_m1 + fn_m1):\n",
    "    r_m1 = tp_m1 / (tp_m1 + fn_m1)\n",
    "\n",
    "print(\"Predicter Median 1\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m1,\"\\t|\\t\", fp_m1, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m1, \"\\t|\\t\", tn_m1, \"\\t|\")\n",
    "if p_m1 > 0:\n",
    "    print(\"Presicion \", p_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m1 > 0:\n",
    "    print(\"Recall \", r_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m1 > 0 and r_m1 > 0):\n",
    "    print(\"Accuracy \", (tp_m1 + fp_m1) / (tp_m1 + fp_m1 + tn_m1 + fn_m1))\n",
    "    print(\"E-measure \", 2*p_m1*r_m1/(p_m1 + r_m1))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c2) ):\n",
    "    if(clasificador2.m2[i] == 1 and medians[i]==2):\n",
    "        tp_m2+=1\n",
    "    elif(clasificador2.m2[i] == 0 and medians[i]==2):\n",
    "        fn_m2+=1\n",
    "    elif(clasificador2.m2[i] == 1 and medians[i]!=2):\n",
    "        fp_m2+=1\n",
    "    else:\n",
    "        tn_m2+=1\n",
    "\n",
    "p_m2=-1\n",
    "r_m2=-1\n",
    "if(tp_m2 + fp_m2 > 0):\n",
    "    p_m2 = tp_m2/(tp_m2 + fp_m2)\n",
    "if(tp_m2 + fn_m2):\n",
    "    r_m2 = tp_m2 / (tp_m2 + fn_m2)\n",
    "\n",
    "print(\"Predicter Median 2\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m2,\"\\t|\\t\", fp_m2, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m2, \"\\t|\\t\", tn_m2, \"\\t|\")\n",
    "if p_m2 > 0:\n",
    "    print(\"Presicion \", p_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m2 > 0:\n",
    "    print(\"Recall \", r_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m2 > 0 and r_m2 > 0):\n",
    "    print(\"Accuracy \", (tp_m2 + fp_m2) / (tp_m2 + fp_m2 + tn_m2 + fn_m2))\n",
    "    print(\"E-measure \", 2*p_m2*r_m2/(p_m2 + r_m2))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c3) ):\n",
    "    if(clasificador2.m3[i] == 1 and medians[i]==3):\n",
    "        tp_m3+=1\n",
    "    elif(clasificador2.m3[i] == 0 and medians[i]==3):\n",
    "        fn_m3+=1\n",
    "    elif(clasificador2.m3[i] == 1 and medians[i]!=3):\n",
    "        fp_m3+=1\n",
    "    else:\n",
    "        tn_m3+=1\n",
    "\n",
    "p_m3=-1\n",
    "r_m3=-1\n",
    "if(tp_m3 + fp_m3 > 0):\n",
    "    p_m3 = tp_m3/(tp_m3 + fp_m3)\n",
    "if(tp_m3 + fn_m3):\n",
    "    r_m3 = tp_m3 / (tp_m3 + fn_m3)\n",
    "\n",
    "print(\"Predicter Median 3\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m3,\"\\t|\\t\", fp_m3, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m3, \"\\t|\\t\", tn_m3, \"\\t|\")\n",
    "if p_m3 > 0:\n",
    "    print(\"Presicion \", p_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m3 > 0:\n",
    "    print(\"Recall \", r_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m3 > 0 and r_m3 > 0):\n",
    "    print(\"Accuracy \", (tp_m3 + fp_m3) / (tp_m3 + fp_m3 + tn_m3 + fn_m3))\n",
    "    print(\"E-measure \", 2*p_m3*r_m3/(p_m3 + r_m3))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c4) ):\n",
    "    if(clasificador2.m4[i] == 1 and medians[i]==4):\n",
    "        tp_m4+=1\n",
    "    elif(clasificador2.m4[i] == 0 and medians[i]==4):\n",
    "        fn_m4+=1\n",
    "    elif(clasificador2.m4[i] == 1 and medians[i]!=4):\n",
    "        fp_m4+=1\n",
    "    else:\n",
    "        tn_m4+=1\n",
    "\n",
    "p_m4=-1\n",
    "r_m4=-1\n",
    "if(tp_m4 + fp_m4 > 0):\n",
    "    p_m4 = tp_m4/(tp_m4 + fp_m4)\n",
    "if(tp_m4 + fn_m4):\n",
    "    r_m4 = tp_m4 / (tp_m4 + fn_m4)\n",
    "\n",
    "print(\"Predicter Median 4\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m4,\"\\t|\\t\", fp_m4, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m4, \"\\t|\\t\", tn_m4, \"\\t|\")\n",
    "if p_m4 > 0:\n",
    "    print(\"Presicion \", p_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m4 > 0:\n",
    "    print(\"Recall \", r_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m4 > 0 and r_m4 > 0):\n",
    "    print(\"Accuracy \", (tp_m4 + fp_m4) / (tp_m4 + fp_m4 + tn_m4 + fn_m4))\n",
    "    print(\"E-measure \", 2*p_m4*r_m4/(p_m4 + r_m4))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c5) ):\n",
    "    if(clasificador2.m5[i] == 1 and medians[i]==5):\n",
    "        tp_m5+=1\n",
    "    elif(clasificador2.m5[i] == 0 and medians[i]==5):\n",
    "        fn_m5+=1\n",
    "    elif(clasificador2.m5[i] == 1 and medians[i]!=5):\n",
    "        fp_m5+=1\n",
    "    else:\n",
    "        tn_m5+=1\n",
    "\n",
    "p_m5=-1\n",
    "r_m5=-1\n",
    "if(tp_m5 + fp_m5 > 0):\n",
    "    p_m5 = tp_m5/(tp_m5 + fp_m5)\n",
    "if(tp_m5 + fn_m5):\n",
    "    r_m5 = tp_m5 / (tp_m5 + fn_m5)\n",
    "\n",
    "print(\"Predicter Median 5\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m5,\"\\t|\\t\", fp_m5, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m5, \"\\t|\\t\", tn_m5, \"\\t|\")\n",
    "if p_m5 > 0:\n",
    "    print(\"Presicion \", p_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m5 > 0:\n",
    "    print(\"Recall \", r_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m5 > 0 and r_m5 > 0):\n",
    "    print(\"Accuracy \", (tp_m5 + fp_m5) / (tp_m5 + fp_m5 + tn_m5 + fn_m5))\n",
    "    print(\"E-measure \", 2*p_m5*r_m5/(p_m5 + r_m5))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c0) ):\n",
    "    if(clasificador2.m0[i] == 1 and medians[i]==0):\n",
    "        tp_m0+=1\n",
    "    elif(clasificador2.m0[i] == 0 and medians[i]==0):\n",
    "        fn_m0+=1\n",
    "    elif(clasificador2.m0[i] == 1 and medians[i]!=0):\n",
    "        fp_m0+=1\n",
    "    else:\n",
    "        tn_m0+=1\n",
    "\n",
    "p_m0=-1\n",
    "r_m0=-1\n",
    "if(tp_m0 + fp_m0 > 0):\n",
    "    p_m0 = tp_m0/(tp_m0 + fp_m0)\n",
    "if(tp_m0 + fn_m0):\n",
    "    r_m0 = tp_m0 / (tp_m0 + fn_m0)\n",
    "\n",
    "print(\"Predicter Median 0\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m0,\"\\t|\\t\", fp_m0, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m0, \"\\t|\\t\", tn_m0, \"\\t|\")\n",
    "if p_m0 > 0:\n",
    "    print(\"Presicion \", p_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m0 > 0:\n",
    "    print(\"Recall \", r_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m0 > 0 and r_m0 > 0):\n",
    "    print(\"Accuracy \", (tp_m0 + fp_m0) / (tp_m0 + fp_m0 + tn_m0 + fn_m0))\n",
    "    print(\"E-measure \", 2*p_m0*r_m0/(p_m0 + r_m0))\n",
    "    \n",
    "print(\"Confusion matrix\")\n",
    "print(\"\\t 0 \\t 1 \\t 2 \\t 3 \\t 4 \\t 5 \")\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c0_predict)):\n",
    "    if(medians[pos] != 0 and clasificador2.predicts[pos] == 0):\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"0 \\t\", tp_m0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c1_predict)):\n",
    "    if(medians[pos] != 1 and clasificador2.predicts[pos] == 1):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"1 \\t\", conf0, \"\\t\", tp_m1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c2_predict)):\n",
    "    if(medians[pos] != 2 and clasificador2.predicts[pos] == 2):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"2 \\t\", conf0, \"\\t\", conf1, \"\\t\", tp_m2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c3_predict)):\n",
    "    if(medians[pos] != 3 and clasificador2.predicts[pos] == 3):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"3 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", tp_m3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c4_predict)):\n",
    "    if(medians[pos] != 4 and clasificador2.predicts[pos] == 4):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"4 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", tp_m4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c5_predict)):\n",
    "    if(medians[pos] != 5 and clasificador2.predicts[pos] == 5):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "print(\"5 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", tp_m5);\n",
    "\n",
    "print(\"Macro averaging\")\n",
    "macropresicion=(tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) / ( (tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) + (fp_m0 + fp_m1 + fp_m2 + fp_m3 + fp_m4 + fp_m5))\n",
    "macrorecall=(tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) / ( (tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) + (fn_m0 + fn_m1 + fn_m2 + fn_m3 + fn_m4 + fn_m5))\n",
    "macrof=2*macropresicion*macrorecall/(macrorecall + macropresicion)\n",
    "print(\"Precision \", macropresicion, \" Recall\", macrorecall, \" F\", macrof)\n",
    "\n",
    "if(p_m0 < 0):\n",
    "    p_m0=0\n",
    "if(p_m1 < 0):\n",
    "    p_m1=0\n",
    "if(p_m2 < 0):\n",
    "    p_m2=0\n",
    "if(p_m3 < 0):\n",
    "    p_m3=0\n",
    "if(p_m3 < 0):\n",
    "    p_m3=0\n",
    "if(p_m4 < 0):\n",
    "    p_m4=0\n",
    "if(p_m4 < 0):\n",
    "    p_m4=0\n",
    "if(p_m5 < 0):\n",
    "    p_m5=0\n",
    "\n",
    "if(r_m0 < 0):\n",
    "    r_m0=0\n",
    "if(r_m1 < 0):\n",
    "    r_m1=0\n",
    "if(r_m2 < 0):\n",
    "    r_m2=0\n",
    "if(r_m3 < 0):\n",
    "    r_m3=0\n",
    "if(r_m3 < 0):\n",
    "    r_m3=0\n",
    "if(r_m4 < 0):\n",
    "    r_m4=0\n",
    "if(r_m4 < 0):\n",
    "    r_m4=0\n",
    "if(r_m5 < 0):\n",
    "    r_m5=0\n",
    "\n",
    "print(\"Micro averaging\")\n",
    "micropresicion=(p_m0 + p_m1 + p_m2 + p_m3 + p_m4 + p_m5)/6\n",
    "microrecall=(r_m0 + r_m1 + r_m2 + r_m3 + r_m4 + r_m5)/6\n",
    "microf=2*micropresicion*microrecall/(micropresicion + microrecall)\n",
    "print(\"Precision \", micropresicion, \" Recall\", microrecall, \" F\", microf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
