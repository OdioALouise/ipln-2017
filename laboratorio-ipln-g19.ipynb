{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pln1.png)\n",
    "![title](imagenes/pdf/pln2.png)\n",
    "![title](imagenes/pdf/pln3.png)\n",
    "![title](imagenes/pdf/pln4.png)\n",
    "![title](imagenes/pdf/pln5.png)\n",
    "![title](imagenes/pdf/pln6.png)\n",
    "![title](imagenes/pdf/pln7.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de votos 26943\n",
      "No humor, votos 14131  porcentaje  52.4477600861\n",
      "Humor 1 estrella, votos  2960  porcentaje  10.9861559589\n",
      "Humor 2 estrellas, votos  2421  porcentaje  8.98563634339\n",
      "Humor 3 estrellas, votos  3274  porcentaje  12.1515792599\n",
      "Humor 4 estrellas, votos  2541  porcentaje  9.43102104443\n",
      "Humor 5 estrellas, votos  1616  porcentaje  5.99784730728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sebastiandaloia/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTACION Cantidad de votos por calificacion, promedio de estrellas, fraccion de votos de humor\n",
    "\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "fraccion_votos_humor = (total - no_humor)/total\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total de votos\", total)\n",
    "print(\"No humor, votos\", no_humor,\" porcentaje \", no_humor/total*100)\n",
    "print(\"Humor 1 estrella, votos \", humor_e1, \" porcentaje \", humor_e1/total*100)\n",
    "print(\"Humor 2 estrellas, votos \", humor_e2, \" porcentaje \", humor_e2/total*100)\n",
    "print(\"Humor 3 estrellas, votos \", humor_e3, \" porcentaje \", humor_e3/total*100)\n",
    "print(\"Humor 4 estrellas, votos \", humor_e4, \" porcentaje \", humor_e4/total*100)\n",
    "print(\"Humor 5 estrellas, votos \", humor_e5, \" porcentaje \", humor_e5/total*100)\n",
    "print(\"Promedio de estrellas PV \", promedio_estrellas_pv) \n",
    "print(\"Promedio de estrellas PVP \", promedio_estrellas_pvp)\n",
    "print(\"Fracción votos de humor\", fraccion_votos_humor)\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sebastiandaloia', api_key='cMoSSDnwQHyafA8prIEv')\n",
    "\n",
    "\n",
    "\n",
    "#Impresion de valores usando ploly\n",
    "labels = ['No humor','1 Estrella','2 Estrellas','3 Estrellas', '4 Estrellas', '5 Estrellas']\n",
    "values = [no_humor, humor_e1, humor_e2, humor_e3, humor_e4, humor_e5]\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "plotly.plotly.iplot([trace], filename='basic_pie_chart')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pln8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets  12106\n",
      "Los tweets mas votados tienen  21 votos\n",
      "Los tweets con dos o menos votos forman un total de  8668\n",
      "Los chistes mas graciosos son\n",
      "1 \n",
      " —¿A dónde vas tan maquillada? —A una fiesta, mamá. —¿Eres el payaso? —¡MAMÁAAA! :( —JAJAJÁ, cállate y hazme reír o no vas. —Ok. :(\n",
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~sebastiandaloia/0 or inside your plot.ly account where it is named 'mpl-basic-histogram'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~sebastiandaloia/0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTACION Cantidad de votos por tweet\n",
    "#Vectores\n",
    "vec_ids=corpus['id'][:]\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "#Variables\n",
    "cant_tweets=len(corpus)\n",
    "\n",
    "print(\"Cantidad de tweets \", cant_tweets)\n",
    "\n",
    "tweet_id_vot=np.zeros((cant_tweets, 2), np.int64)\n",
    "\n",
    "contador=0\n",
    "for i in range(0, cant_tweets):\n",
    "    tweet_id_vot[i, 0]=vec_ids[i]\n",
    "    tweet_id_vot[i,1]=vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i]\n",
    "\n",
    "\n",
    "array=tweet_id_vot[:,1]\n",
    "array=np.sort(array, axis=None)\n",
    "last=array[len(array) - 1]\n",
    "\n",
    "lesseq_3=0\n",
    "for i in range(0, cant_tweets):\n",
    "    if( array[i] > 2 ):\n",
    "        break;\n",
    "    lesseq_3+=1\n",
    "\n",
    "print(\"Los tweets mas votados tienen \", last, \"votos\")\n",
    "print(\"Los tweets con dos o menos votos forman un total de \", lesseq_3)\n",
    "\n",
    "contador=1\n",
    "print(\"Los chistes mas graciosos son\")\n",
    "for i in range(0, cant_tweets):\n",
    "    if( vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] == 21 ):\n",
    "        print(contador, \"\\n\", corpus['text'][i])\n",
    "\n",
    "plotly.tools.set_credentials_file(username='sebastiandaloia', api_key='cMoSSDnwQHyafA8prIEv')\n",
    "\n",
    "votos_nums = tweet_id_vot[:,1]\n",
    "\n",
    "plt.hist(votos_nums)\n",
    "plt.title(\"Histograma de votos por tweet\")\n",
    "plt.xlabel(\"Votos\")\n",
    "plt.ylabel(\"Tweets\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "plotly.plotly.plot_mpl(fig, filename='mpl-basic-histogram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fracción votos de humor 0.475522399139\n"
     ]
    }
   ],
   "source": [
    "#iMPLEMENTACION Fraccion de votos de humor\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "fraccion_votos_humor = (total - no_humor)/total\n",
    "\n",
    "print(\"Fracción votos de humor\", fraccion_votos_humor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pln9.png)\n",
    "![title](imagenes/pdf/pln10.png)\n",
    "![title](imagenes/pdf/pln11.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de estrellas PV  1.3312548714\n",
      "Promedio de estrellas PVP  2.79956290977\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION Promedio de estrellas\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "print(\"Promedio de estrellas PV \", promedio_estrellas_pv) \n",
    "print(\"Promedio de estrellas PVP \", promedio_estrellas_pvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los chistes mas graciosos son: \n",
      "1  - PV : 4.75 votos:  4\n",
      "   -Mamá tuvimos un examen sorpresa en la escuela - ¿Y que pasó hijo? -Estuve muy sorprendido mamá.\n",
      "2  - PV : 4.5 votos:  4\n",
      "   ¿Cómo se llama la secretaria de Batman? Bati la fea... #chistes #fb\n",
      "3  - PV : 4.5 votos:  4\n",
      "   Quedarse atrapado en la esquina de la ducha porque el agua sale muy fría.\n",
      "4  - PV : 4.4 votos:  5\n",
      "   —Amor, ¿Ya está dentro? —Sí ¿Te lastima? —Sí amor, mételo despacito, duele cuando entra. —Ok, vamos a intentar otro número de zapato :)\n",
      "5  - PV : 4.25 votos:  4\n",
      "   —Violarte es mi sueño —¿QUÉ? —Que estudio diseño —No, ¡ahora me violas!\n",
      "6  - PV : 4.25 votos:  4\n",
      "   — ¡Profe! ¿Puedo ir al baño?. *Regresa con comida*.\n",
      "7  - PV : 4.25 votos:  4\n",
      "   Las mujeres de hoy en día con tal de no hacer limpieza en la casa, se inventan que les gusta el fútbol.\n",
      "8  - PV : 4.25 votos:  4\n",
      "   Siempre será mejor hablar en clases que en el recreo.\n",
      "9  - PV : 4.25 votos:  4\n",
      "   Lunes Martes Miércoles Jueves Casi Sábado Sábado Casi Lunes.\n",
      "10  - PV : 4.25 votos:  4\n",
      "   Todo es comestible hasta que la diarrea demuestre lo contrario...\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTACION Mejores chistes:\n",
    "# 1: Para ser considerados deben tener al menos 3 votos en total 1 de ellos debe ser de humor.\n",
    "# 2: Entre los candidatos los mas graciosos seran los que tengan mejor promedio de estrellas y entre estos los de mas votos.\n",
    "# 3: Se listan los mejores 10 chistes, esto puede cambiarse cambiando el valor de cantidad_mejores_chistes.\n",
    "mejores_chistes = np.array([])\n",
    "cant_votos = []\n",
    "prom_estrellas_pv = []\n",
    "votos_humor = []\n",
    "minimo_votos = 3\n",
    "cantidad_mejores_chistes = 10\n",
    "#Variables\n",
    "cant_tweets=len(corpus)\n",
    "for i in range(0, cant_tweets):\n",
    "    votos_humor.append(vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i])\n",
    "    cant_votos.append(vec_no_humor[i] + votos_humor[i])\n",
    "    prom_estrellas_pv.append((vec_e1[i] + 2*vec_e2[i] + 3*vec_e3[i] + 4*vec_e4[i] + 5*vec_e5[i])/cant_votos[i])\n",
    "    \n",
    "    #debe tener la cantidad de votos necesaria y almenos un voto de humor para ser considerado\n",
    "    if( cant_votos[i] > minimo_votos and votos_humor[i] > 0 ): \n",
    "        #solo se mostraran los 5 mejores chistes.\n",
    "        chiste = np.array([corpus['text'][i], prom_estrellas_pv[i], cant_votos[i]])\n",
    "        if (len(mejores_chistes) > 0):\n",
    "            mejores_chistes = np.vstack((mejores_chistes, chiste))\n",
    "        else :\n",
    "            mejores_chistes = np.append(mejores_chistes, chiste)\n",
    "   \n",
    "print(\"\")\n",
    "print(\"Los chistes mas graciosos son: \")\n",
    "\n",
    "ind = np.lexsort((mejores_chistes[:,2],mejores_chistes[:,1]))\n",
    "for i in range(0, cantidad_mejores_chistes):\n",
    "    j = len(mejores_chistes) - i - 1\n",
    "    print(i+1, \" - PV :\",mejores_chistes[ind][j][1], \"votos: \", mejores_chistes[ind][j][2])\n",
    "    print(\"  \", mejores_chistes[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negación general:  2.440800988551316\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION Negatividad\n",
    "pattern_tag = re.compile(r'lemma=\"(no?)\"')\n",
    "\n",
    "tam=len(corpus)\n",
    "total_no=0;\n",
    "total_token=0\n",
    "pos=0\n",
    "for i in np.random.randint(0, tam, 1000):\n",
    "    text = corpus['text'][i]\n",
    "    tweet_token=0\n",
    "    token_no=0\n",
    "    xml = analyzer.run(text.encode(), 'flush')\n",
    "    for sentence in xml:\n",
    "        for token in sentence: \n",
    "            tweet_token+=1\n",
    "            m = re.search(pattern_tag, etree.tostring(token).decode())\n",
    "            if m :\n",
    "                token_no+=1\n",
    "    pos+=1\n",
    "    print(\"Tweet numero \", pos,  end=\"\\r\")\n",
    "    time.sleep(1)\n",
    "             \n",
    "        \n",
    "    total_no+=token_no    \n",
    "    total_token+=tweet_token\n",
    "        \n",
    "print(\"Negación general: \", total_no/math.sqrt(total_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de links encontrados  3280\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION cantidad de links\n",
    "\n",
    "pattern_http = re.compile(r'http://')\n",
    "\n",
    "num_links=0\n",
    "\n",
    "for text in corpus['text'][:]:\n",
    "    result = pattern_http.findall(text) \n",
    "    num_links+=len(result)\n",
    "\n",
    "print(\"Cantidad de links encontrados \", num_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana primera persona  0.0\n",
      "Mediana segunda persona  0.0\n",
      "Media primera persona  0.183470578311\n",
      "Media segunda persona  0.16683360628\n",
      "[0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 0.48507125007266594, 0.45883146774112349, 0.23570226039551587, 0.0, 0.0, 1.0606601717798212, 0.0, 0.15075567228888181, 0.75, 0.45883146774112349, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.17677669529663687, 0.0, 0.0, 0.24253562503633297, 0.2581988897471611, 1.1470786693528088, 0.0, 0.0, 0.0, 0.3481553119113957, 0.0, 0.0, 0.0, 0.0, 0.87287156094396956, 0.18257418583505536, 0.3481553119113957, 0.0, 0.17677669529663687, 0.18257418583505536, 0.0, 0.48507125007266594, 1.2060453783110545, 0.40000000000000002, 0.41702882811414954, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.0, 1.0, 0.55470019622522915, 0.0, 1.0206207261596576, 0.40824829046386307, 0.60302268915552726, 0.16666666666666666, 0.54772255750516607, 0.0, 0.39223227027636809, 0.30151134457776363, 0.59999999999999998, 0.2581988897471611, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.47140452079103173, 0.0, 0.25, 0.0, 0.0, 0.2581988897471611, 0.34299717028501764, 0.5, 0.0, 0.43643578047198478, 0.31622776601683794, 0.20851441405707477, 0.0, 0.5388159060803247, 0.0, 0.0, 0.0, 0.0, 0.6546536707079772, 0.0, 1.0776318121606494, 0.0, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.36514837167011072, 0.63245553203367588, 1.0206207261596576, 0.0, 0.0, 0.1889822365046136, 0.32879797461071458, 0.0, 0.0, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.81649658092772615, 0.0, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38490017945975052, 0.17960530202677491, 0.70710678118654746, 0.0, 0.17149858514250882, 0.58834840541455213, 0.17407765595569785, 0.1690308509457033, 0.0, 0.0, 0.15430334996209191, 0.24253562503633297, 0.48507125007266594, 0.25, 0.0, 0.1690308509457033, 0.57735026918962584, 0.0, 0.20851441405707477, 0.0, 0.17407765595569785, 0.28867513459481292, 0.0, 0.0, 0.0, 0.60302268915552726, 0.5303300858899106, 0.0, 0.19611613513818404, 0.19611613513818404, 0.47140452079103173, 0.0, 0.0, 0.0, 0.42640143271122083, 0.0, 0.21821789023599239, 0.37139067635410372, 0.0, 0.0, 0.46852128566581819, 0.0, 0.0, 0.0, 0.35355339059327373, 0.0, 0.18569533817705186, 0.45883146774112349, 0.76980035891950105, 0.63960214906683133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.0, 0.51449575542752646, 0.0, 0.0, 0.0, 0.31234752377721214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.19245008972987526, 0.0, 0.0, 0.68599434057003528, 1.212678125181665, 0.47140452079103173, 0.0, 0.0, 0.37139067635410372, 0.0, 0.42640143271122083, 0.24253562503633297, 0.70710678118654757, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.0, 0.0, 0.67082039324993692, 0.0, 0.0, 0.0, 0.0, 0.7559289460184544, 0.0, 0.34299717028501764, 0.0, 0.0, 0.0, 0.55708601453115558, 0.0, 0.0, 0.1889822365046136, 0.0, 0.48507125007266594, 0.31622776601683794, 0.49319696191607187, 0.0, 0.0, 0.68599434057003528, 0.0, 0.0, 0.17407765595569785, 0.38490017945975052, 0.17677669529663687, 0.0, 0.0, 0.21821789023599239, 0.0, 0.73029674334022143, 0.17149858514250882, 0.0, 0.5, 0.21821789023599239, 0.0, 0.20851441405707477, 0.0, 0.25, 0.67082039324993692, 0.0, 0.36514837167011072, 0.54772255750516607, 0.0, 0.66666666666666663, 0.0, 0.0, 0.53452248382484879, 0.0, 0.44721359549995793, 0.0, 0.21821789023599239, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 1.0660035817780522, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.94491118252306805, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.21320071635561041, 0.23570226039551587, 0.0, 0.6546536707079772, 0.0, 0.73029674334022143, 0.17960530202677491, 0.0, 0.20412414523193154, 1.0, 0.0, 0.0, 1.1094003924504583, 0.0, 0.83205029433784372, 0.0, 0.23570226039551587, 0.0, 0.72760687510899891, 0.76980035891950105, 0.0, 0.0, 0.0, 0.75, 0.0, 0.34299717028501764, 0.20000000000000001, 0.30151134457776363, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.39223227027636809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.0, 0.73029674334022143, 0.0, 0.0, 0.17960530202677491, 0.28867513459481292, 0.0, 0.0, 0.5, 0.0, 0.47140452079103173, 0.0, 0.15617376188860607, 0.35355339059327373, 0.0, 0.21320071635561041, 0.0, 0.2672612419124244, 0.0, 0.57735026918962584, 0.0, 0.21821789023599239, 0.41702882811414954, 0.0, 0.35921060405354982, 0.2581988897471611, 0.0, 0.42640143271122083, 0.0, 0.18257418583505536, 0.48507125007266594, 0.0, 0.39223227027636809, 0.0, 0.35921060405354982, 0.0, 0.44721359549995793, 0.0, 0.20000000000000001, 0.0, 0.22941573387056174, 0.44721359549995793, 0.0, 0.20000000000000001, 0.0, 0.22941573387056174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.24253562503633297, 0.40824829046386307, 0.0, 0.28867513459481292, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 0.17960530202677491, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.17960530202677491, 0.0, 0.0, 0.21821789023599239, 0.72760687510899891, 0.0, 0.59999999999999998, 0.0, 0.24253562503633297, 0.40000000000000002, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.21821789023599239, 0.56694670951384085, 0.0, 0.0, 1.1094003924504583, 0.0, 0.5222329678670935, 0.37139067635410372, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.21821789023599239, 0.0, 0.14744195615489714, 0.0, 0.82199493652678646, 0.0, 0.0, 0.0, 0.98058067569092022, 0.0, 0.16439898730535729, 0.20412414523193154, 0.0, 0.1889822365046136, 0.0, 0.19611613513818404, 0.35921060405354982, 0.50709255283710997, 0.20851441405707477, 0.17149858514250882, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.19245008972987526, 0.0, 0.59999999999999998, 0.32444284226152509, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.70710678118654746, 0.0, 0.0, 0.0, 0.88388347648318433, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.0, 0.51449575542752646, 0.0, 0.27735009811261457, 0.22941573387056174, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 1.150792911137501, 0.43643578047198478, 1.1094003924504583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 0.0, 0.76980035891950105, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.47140452079103173, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.31622776601683794, 0.5388159060803247, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19245008972987526, 0.1889822365046136, 0.0, 0.17960530202677491, 1.0776318121606494, 0.0, 0.21320071635561041, 0.33333333333333331, 0.0, 0.67082039324993692, 0.20412414523193154, 0.0, 0.0, 0.0, 0.7745966692414834, 0.0, 0.0, 1.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.17149858514250882, 0.0, 0.48038446141526137, 0.0, 0.0, 0.2581988897471611, 0.17407765595569785, 0.20000000000000001, 0.42640143271122083, 0.72760687510899891, 0.0, 0.0, 0.0, 0.75, 0.17960530202677491, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.63960214906683133, 0.0, 0.0, 0.36514837167011072, 0.0, 0.72760687510899891, 0.0, 0.0, 0.0, 0.40000000000000002, 0.5303300858899106, 0.0, 0.47140452079103173, 0.5303300858899106, 0.49319696191607187, 0.27735009811261457, 0.0, 0.0, 0.0, 0.43643578047198478, 0.18257418583505536, 0.0, 0.44721359549995793, 0.0, 0.17677669529663687, 0.35921060405354982, 0.28867513459481292, 0.2672612419124244, 0.0, 0.6546536707079772, 0.0, 0.16666666666666666, 0.0, 0.0, 0.28867513459481292, 0.48507125007266594, 0.68599434057003528, 0.17407765595569785, 0.0, 0.2581988897471611, 0.41702882811414954, 0.0, 0.0, 0.0, 0.98058067569092022, 0.73029674334022143, 0.30151134457776363, 0.0, 0.0, 0.21821789023599239, 0.1889822365046136, 0.2672612419124244, 0.0, 0.0, 1.0606601717798212, 0.53452248382484879, 0.0, 0.18569533817705186, 0.68824720161168518, 0.2672612419124244, 0.0, 0.16666666666666666, 0.22360679774997896, 1.044465935734187, 0.20851441405707477, 0.0, 0.0, 0.37139067635410372, 0.0, 0.44721359549995793, 0.0, 0.37139067635410372, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 0.0, 1.386750490563073, 0.0, 0.0, 0.0, 0.64888568452305018, 0.35355339059327373, 0.0, 0.0, 0.13867504905630729, 0.0, 0.0, 0.0, 0.40824829046386307, 0.18569533817705186, 0.0, 0.0, 0.0, 0.16222142113076254, 0.0, 0.68824720161168518, 0.0, 0.0, 1.0327955589886444, 0.0, 0.0, 0.0, 0.20851441405707477, 0.0, 0.21320071635561041, 0.0, 0.0, 0.8703882797784892, 0.0, 0.27735009811261457, 0.0, 0.18569533817705186, 0.0, 0.0, 0.19611613513818404, 0.5388159060803247, 0.88388347648318433, 0.0, 0.50709255283710997, 0.16666666666666666, 0.80000000000000004, 0.0, 0.46291004988627571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22941573387056174, 0.35355339059327373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.76980035891950105, 0.0, 0.58834840541455213, 0.3481553119113957, 0.2672612419124244, 0.34299717028501764, 0.35921060405354982, 0.0, 0.42640143271122083, 0.0, 0.0, 0.0, 0.55708601453115558, 0.41702882811414954, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55708601453115558, 0.19245008972987526, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.94491118252306805, 0.0, 0.0, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 1.044465935734187, 0.0, 0.0, 0.0, 0.5303300858899106, 0.0, 0.0, 0.0, 0.2581988897471611, 0.0, 0.55708601453115558, 0.36514837167011072, 0.0, 0.0, 0.38490017945975052, 0.0, 0.0, 0.22941573387056174, 0.58834840541455213, 0.23570226039551587, 0.63245553203367588, 0.0, 0.16439898730535729, 0.0, 0.0, 0.3779644730092272, 0.76980035891950105, 0.0, 0.44721359549995793, 0.0, 0.0, 0.50709255283710997, 0.0, 0.68824720161168518, 0.2581988897471611, 0.32444284226152509, 0.0, 0.28867513459481292, 0.0, 0.17407765595569785, 0.17960530202677491, 0.0, 0.51449575542752646, 0.21821789023599239, 0.78446454055273618, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.18257418583505536, 0.17407765595569785, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.40824829046386307, 0.0, 0.0, 0.0, 0.34299717028501764, 0.0, 0.60302268915552726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48507125007266594, 0.19245008972987526, 0.20000000000000001, 0.18257418583505536, 0.0, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.30499714066520933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.21821789023599239, 0.39223227027636809, 0.40824829046386307, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.31622776601683794, 0.0, 0.0, 0.24253562503633297, 0.5, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.0, 0.0, 0.0, 0.7745966692414834, 0.31622776601683794, 0.37139067635410372, 0.0, 0.57735026918962584, 0.0, 0.0, 0.0, 0.6546536707079772, 0.0, 0.97014250014533188, 0.29814239699997197, 0.81649658092772615, 0.44721359549995793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68824720161168518, 0.18257418583505536, 0.40824829046386307, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.40824829046386307, 0.19611613513818404, 0.0, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.28867513459481292, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.40000000000000002, 0.2672612419124244, 0.91766293548224698, 0.94491118252306805, 0.0, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.54772255750516607, 0.0, 0.0, 0.0, 0.48666426339228763, 0.20000000000000001, 0.0, 0.0, 0.24253562503633297, 0.0, 0.0, 0.22360679774997896, 0.2581988897471611, 0.38490017945975052, 0.48507125007266594, 0.5, 0.22941573387056174, 0.0, 0.49319696191607187, 0.22941573387056174, 0.37139067635410372, 0.0, 0.0, 0.21320071635561041, 0.2672612419124244, 0.0, 0.0, 0.0, 0.0, 0.28867513459481292, 0.40000000000000002, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.55470019622522915, 0.40824829046386307, 0.75, 0.0, 0.24253562503633297, 0.45883146774112349, 0.0, 0.19245008972987526, 0.33806170189140661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.53452248382484879, 0.94280904158206347, 0.0, 0.0, 0.24253562503633297, 0.3481553119113957, 0.72760687510899891, 0.45883146774112349, 0.23570226039551587, 0.0, 0.0, 0.0, 0.0, 0.90453403373329089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61237243569579458, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.25, 0.0, 0.3481553119113957, 0.20412414523193154, 0.31622776601683794, 0.80178372573727319, 0.0, 0.0, 0.36514837167011072, 0.0, 0.0, 0.17677669529663687, 0.18257418583505536, 0.50709255283710997, 0.0, 0.0, 0.40000000000000002, 0.0, 0.23570226039551587, 0.57735026918962573, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 1.1666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.73029674334022143, 0.0, 0.39223227027636809, 0.0, 0.80000000000000004, 0.2581988897471611, 1.2374368670764582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.0, 0.2581988897471611, 0.17149858514250882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 0.0, 0.45883146774112349, 0.35921060405354982, 0.2581988897471611, 0.0, 0.20851441405707477, 0.39223227027636809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.23570226039551587, 0.0, 0.54772255750516607, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.0, 0.75, 0.48507125007266594, 0.0, 0.91766293548224698, 0.0, 0.0, 0.24253562503633297, 0.0, 0.83205029433784372, 0.0, 0.30151134457776363, 0.0, 0.0, 0.24253562503633297, 0.0, 0.47140452079103173, 0.0, 0.0, 0.0, 0.19245008972987526, 0.35921060405354982, 0.17677669529663687, 0.60302268915552726, 0.0, 0.78446454055273618, 0.17407765595569785, 0.1690308509457033, 0.0, 0.45883146774112349, 0.61721339984836765, 0.24253562503633297, 0.0, 0.0, 0.0, 0.50709255283710997, 0.0, 0.0, 0.0, 0.0, 0.3481553119113957, 0.0, 0.54772255750516607, 0.72760687510899891, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.19611613513818404, 0.23570226039551587, 0.0, 0.0, 0.47140452079103173, 0.0, 0.47140452079103173, 0.21821789023599239, 0.37139067635410372, 0.0, 0.0, 0.62469504755442429, 0.0, 0.0, 0.0, 0.0, 0.33333333333333331, 0.18569533817705186, 0.22941573387056174, 0.0, 0.21320071635561041, 0.20851441405707477, 0.0, 0.19245008972987526, 0.0, 0.0, 0.53452248382484879, 0.20000000000000001, 0.0, 0.0, 0.0, 0.68599434057003528, 0.0, 0.0, 0.0, 0.46852128566581819, 0.0, 0.0, 0.17149858514250882, 0.36514837167011072, 0.0, 0.0, 0.38490017945975052, 0.0, 0.42640143271122083, 0.34299717028501764, 0.0, 0.47140452079103173, 0.0, 0.18257418583505536, 0.18569533817705186, 0.23570226039551587, 0.0, 0.0, 0.47140452079103173, 0.38490017945975052, 0.0, 0.0, 0.16439898730535729, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.89442719099991586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.51449575542752646, 0.43643578047198478, 0.57735026918962584, 1.1180339887498949, 0.74278135270820744, 0.0, 0.0, 0.56694670951384085, 0.0, 0.0, 0.0, 0.32879797461071458, 0.0, 0.0, 0.0, 0.68824720161168518, 0.0, 0.0, 0.57735026918962573, 0.35355339059327373, 0.27735009811261457, 0.0, 0.0, 0.0, 0.0, 0.17149858514250882, 0.0, 0.25, 0.0, 0.43643578047198478, 0.0, 0.72760687510899891, 0.0, 0.0, 0.76980035891950105, 0.36514837167011072, 0.36514837167011072, 0.0, 0.0, 1.2510864843424487, 0.0, 0.80178372573727319, 1.0425720702853738, 0.0, 0.0, 0.43643578047198478, 0.17407765595569785, 0.5, 0.60302268915552726, 0.0, 0.0, 0.17407765595569785, 0.0, 0.1889822365046136, 0.78446454055273618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.5388159060803247, 0.0, 0.20412414523193154, 0.0, 0.5163977794943222, 0.0, 0.0, 0.83405765622829908, 0.0, 0.0, 0.0, 0.22360679774997896, 0.48507125007266594, 0.38490017945975052, 0.63960214906683133, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.60302268915552726, 0.18569533817705186, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.1889822365046136, 0.0, 0.0, 0.80178372573727319, 0.44721359549995793, 0.81649658092772615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17960530202677491, 0.0, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.31234752377721214, 0.0, 0.0, 0.0, 0.0, 0.80178372573727319, 0.0, 0.57735026918962584, 0.0, 0.43643578047198478, 0.0, 0.0, 0.35921060405354982, 0.5163977794943222, 0.28867513459481292, 0.63960214906683133, 0.0, 0.0, 0.24253562503633297, 0.44721359549995793, 0.0, 0.31622776601683794, 0.0, 0.48507125007266594, 0.0, 0.0, 0.40000000000000002, 0.0, 0.22941573387056174, 0.0, 0.97014250014533188, 0.0, 0.19245008972987526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.20412414523193154, 0.20412414523193154, 0.57735026918962584, 0.45883146774112349, 0.18569533817705186, 0.28867513459481292, 0.5222329678670935, 0.0, 0.5388159060803247, 0.0, 0.7745966692414834, 0.0, 0.68824720161168518, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.0, 0.24253562503633297, 0.40000000000000002, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74278135270820744, 0.0, 0.0, 0.0, 0.57735026918962584, 0.0, 0.0, 0.45883146774112349, 0.88465173692938281, 0.0, 1.150792911137501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 0.20851441405707477, 0.34299717028501764, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.39223227027636809, 0.48507125007266594, 0.5303300858899106, 0.0, 0.38490017945975052, 0.63960214906683133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.44721359549995793, 0.0, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.53452248382484879, 0.35921060405354982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.21821789023599239, 0.0, 0.0, 0.0, 0.33806170189140661, 0.98639392383214375, 0.21821789023599239, 0.0, 0.0, 0.0, 0.2581988897471611, 0.0, 0.86602540378443871, 0.33806170189140661, 0.0, 0.38490017945975052, 0.72760687510899891, 0.21821789023599239, 0.53452248382484879, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.0, 0.18257418583505536, 0.31622776601683794, 0.0, 0.0, 0.38490017945975052, 0.0, 0.3481553119113957, 0.0, 0.2581988897471611, 0.1690308509457033, 0.0, 0.0, 0.19245008972987526, 0.0, 0.36514837167011072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61237243569579458, 0.0, 0.0, 0.42640143271122083, 0.0, 0.20000000000000001, 0.22360679774997896, 0.40000000000000002, 0.60302268915552726, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.16012815380508713, 0.48507125007266594, 0.0, 0.0, 0.3481553119113957, 0.0, 0.42640143271122083, 0.0, 0.0, 0.20000000000000001, 0.78446454055273618, 0.0, 0.71842120810709964, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.2672612419124244, 0.63960214906683133, 0.17677669529663687, 0.0, 0.0, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.386750490563073, 0.0, 0.75, 0.34299717028501764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5388159060803247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.27735009811261457, 0.19611613513818404, 0.86602540378443871, 0.0, 0.34299717028501764, 0.17407765595569785, 0.0, 0.0, 0.20851441405707477, 0.0, 0.0, 0.48507125007266594, 0.0, 0.54772255750516607, 0.0, 0.0, 0.0, 0.43643578047198478, 0.0, 0.2672612419124244, 0.0, 0.0, 0.70710678118654746, 0.0, 0.97014250014533188, 0.18569533817705186, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.20851441405707477, 0.48507125007266594, 0.0, 0.37139067635410372, 0.0, 0.44721359549995793, 0.0, 0.37139067635410372, 0.0, 0.20851441405707477, 0.0, 0.40824829046386307, 0.23570226039551587, 0.0, 0.0, 0.27735009811261457, 0.39223227027636809, 0.53452248382484879, 0.0, 0.0, 0.0, 0.80178372573727319, 0.42640143271122083, 0.0, 0.40824829046386307, 0.0, 0.0, 0.0, 0.0, 0.40824829046386307, 0.16222142113076254, 0.0, 0.0, 0.0, 0.13867504905630729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20851441405707477, 0.0, 0.21320071635561041, 0.72760687510899891, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.18569533817705186, 0.0, 0.0, 0.0, 0.71842120810709964, 0.0, 0.0, 0.0, 0.66666666666666663, 0.20000000000000001, 0.0, 0.61721339984836765, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19245008972987526, 0.28867513459481292, 0.0, 0.30151134457776363, 0.79056941504209477, 0.0, 0.0, 0.0, 0.0, 0.39223227027636809, 0.17407765595569785, 0.0, 0.0, 0.5388159060803247, 0.0, 0.42640143271122083, 0.2672612419124244, 0.0, 0.0, 0.18569533817705186, 0.41702882811414954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.5222329678670935, 0.24253562503633297, 0.27735009811261457, 0.20000000000000001, 0.20412414523193154, 0.0, 0.69631062382279141, 0.0, 0.3481553119113957, 0.0, 0.60302268915552726, 0.0, 0.35355339059327373, 0.0, 0.0, 0.0, 0.2581988897471611, 0.21320071635561041, 0.0, 0.54772255750516607, 0.0, 0.0, 0.38490017945975052, 0.0, 0.0, 0.0, 0.0, 0.47140452079103173, 0.0, 0.39223227027636809, 0.16439898730535729, 0.53452248382484879, 0.5, 0.0, 0.19245008972987526, 0.0, 0.44721359549995793, 0.0, 0.0, 0.50709255283710997, 0.0, 0.0, 0.5163977794943222, 0.16222142113076254, 0.0, 0.0, 0.0, 0.3481553119113957, 0.17960530202677491, 0.2581988897471611, 0.68599434057003528, 0.21821789023599239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70710678118654757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21821789023599239, 0.0, 0.0, 1.0, 0.20412414523193154, 0.89442719099991586, 0.0, 1.4596008983995234, 0.17149858514250882, 0.0, 0.15075567228888181, 0.0, 0.0, 0.22360679774997896, 0.45883146774112349, 0.1690308509457033, 0.24253562503633297, 0.19245008972987526, 0.20000000000000001, 0.18257418583505536, 0.0, 0.0, 0.36514837167011072, 0.0, 0.21320071635561041, 0.2581988897471611, 0.0, 0.0, 0.55470019622522915, 0.0, 0.0, 0.0, 0.48507125007266594, 0.19245008972987526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.89442719099991586, 0.31622776601683794, 0.27735009811261457, 0.0, 0.0, 0.0, 0.22941573387056174, 0.40824829046386307, 0.0, 0.0, 0.0, 0.33333333333333331, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45883146774112349, 0.0, 0.25, 0.0, 0.14907119849998599, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.1889822365046136, 0.48038446141526137, 0.22941573387056174, 0.36514837167011072, 0.20412414523193154, 0.0, 0.19245008972987526, 0.35355339059327373, 0.16439898730535729, 0.41702882811414954, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.71842120810709964, 0.3779644730092272, 0.39223227027636809, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.67082039324993692, 0.0, 0.0, 0.5, 0.0, 0.40000000000000002, 0.53452248382484879, 0.0, 0.0, 0.28867513459481292, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.24253562503633297, 0.85280286542244166, 0.0, 0.0, 0.0, 0.19245008972987526, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.91766293548224698, 0.0, 0.41702882811414954, 0.33333333333333331, 0.0, 0.0, 0.0, 0.20000000000000001, 0.55470019622522915, 0.0, 0.0, 0.40000000000000002, 0.57735026918962573, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 1.0, 0.18569533817705186, 0.0, 0.0, 0.63245553203367588, 0.38490017945975052, 0.33806170189140661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3779644730092272]\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION primera y segunda persona\n",
    "\n",
    "pattern_tag = re.compile(r'tag=\"(.*?)\"')\n",
    "\n",
    "first_second_person=np.zeros((len(corpus), 2))\n",
    "contador=0\n",
    "\n",
    "tam=len(corpus)\n",
    "\n",
    "for i in np.random.randint(0, tam, 1000):\n",
    "    text = corpus['text'][i]\n",
    "    total_token=0\n",
    "    token_1=0\n",
    "    token_2=0\n",
    "    xml = analyzer.run(text.encode(), 'flush')\n",
    "    for sentence in xml:\n",
    "        for token in sentence:\n",
    "            m = re.search(pattern_tag, etree.tostring(token).decode())\n",
    "            tag=m.group(1)\n",
    "            if (tag[0] == 'V'):\n",
    "                if(tag[4] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[4]=='2'):\n",
    "                    token_2+=1\n",
    "            elif(tag[0] == 'P'):\n",
    "                if(tag[2] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[2]=='2'):\n",
    "                    token_2+=1\n",
    "            elif(tag[0] == 'D'):\n",
    "                if(tag[2] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[2]=='2'):\n",
    "                    token_2+=1\n",
    "            total_token+=1\n",
    "    first_second_person[contador,0]=token_1/math.sqrt(total_token)\n",
    "    first_second_person[contador,1]=token_2/math.sqrt(total_token)    \n",
    "    contador+=1\n",
    "    print (\"Dato numero \",contador, \"Porcentaje \", contador/len(corpus),  end=\"\\r\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "pp=[]   \n",
    "sp=[]\n",
    "cont=0\n",
    "for t in first_second_person:\n",
    "    if(cont<1000):\n",
    "        pp.append(t[0])\n",
    "        sp.append(t[1])    \n",
    "    cont+=1    \n",
    "#first_second_person    \n",
    "print(\"Mediana primera persona \", np.median(pp))\n",
    "print(\"Mediana segunda persona \", np.median(sp))\n",
    "\n",
    "print(\"Media primera persona \", np.mean(pp))\n",
    "print(\"Media segunda persona \", np.mean(sp))\n",
    "\n",
    "print(pp)\n",
    "\n",
    "print(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importacion de librerias utiles\n",
    "\n",
    "#Libreria para analisis de datos \n",
    "#en este proyecto para leer y grabar\n",
    "#archivos en csv\n",
    "import pandas\n",
    "\n",
    "#Librerias cientificas scipy, numpy, matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Librerias de incluidas en python time, math\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Lectura de archivos xml\n",
    "from lxml import etree\n",
    "\n",
    "#Expresiones regulares\n",
    "import re\n",
    "\n",
    "#Pyfreeling\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Para implementar modelos de aprendizajes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar comentarios con menos de tres votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga el corpus de humor\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "id_f = []\n",
    "text_f = []\n",
    "account_id_f=[]\n",
    "nh_f=[]\n",
    "sh1_f=[]\n",
    "sh2_f=[]\n",
    "sh3_f=[]\n",
    "sh4_f=[]\n",
    "sh5_f=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_id=corpus['id'][:]\n",
    "vec_text=corpus['text'][:]\n",
    "vec_account_id=corpus['account_id'][:]\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "#Para cada tweet se calcula si tiene al menos tres votos, \n",
    "#en caso afirmativo se guarda su informacion, en caso\n",
    "#negativo se descarta el tweet\n",
    "for i in range(len(corpus)):\n",
    "    if vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= 3:\n",
    "        id_f.append(vec_id[i])\n",
    "        text_f.append(vec_text[i])\n",
    "        account_id_f.append(vec_account_id[i])\n",
    "        nh_f.append(vec_no_humor[i])\n",
    "        sh1_f.append(vec_e1[i])\n",
    "        sh2_f.append(vec_e2[i])\n",
    "        sh3_f.append(vec_e3[i])\n",
    "        sh4_f.append(vec_e4[i])\n",
    "        sh5_f.append(vec_e5[i])\n",
    "        \n",
    "#El primer filtro aplicado es guardado en el archivo corpus_filtro1.csv\n",
    "d = {'id' : id_f,\n",
    "    'text' : text_f,\n",
    "    'account_id': account_id_f,\n",
    "    'n':nh_f, \n",
    "    '1':sh1_f,\n",
    "    '2':sh2_f,\n",
    "    '3':sh3_f,\n",
    "    '4':sh4_f,\n",
    "    '5':sh5_f\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_f = []\n",
    "\n",
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro1 = pandas.read_csv(\"corpus_filtro1.csv\",encoding='utf-8')\n",
    "\n",
    "#Generacion de patron de Hashtag\n",
    "pattern_hashtag = re.compile(r'#.+?\\b')\n",
    "\n",
    "\n",
    "#Se sustituye el Hashtag por el string vacio, los tweets que\n",
    "#van pasando por este procesamiento se van guardando en el arreglo\n",
    "#text_f\n",
    "for i in range(len(corpus_filtro1)):\n",
    "    text_f.append(re.sub(pattern_hashtag, \"\", corpus_filtro1['text'][i]))\n",
    "#El segundo filtro aplicado es guardado en el archivo corpus_filtro2.csv\n",
    "d = {'id' : corpus_filtro1['id'][:],\n",
    "    'text' : text_f,\n",
    "    'account_id': corpus_filtro1['account_id'][:],\n",
    "    'n':corpus_filtro1['n'][:], \n",
    "    '1':corpus_filtro1['1'][:],\n",
    "    '2':corpus_filtro1['2'][:],\n",
    "    '3':corpus_filtro1['3'][:],\n",
    "    '4':corpus_filtro1['4'][:],\n",
    "    '5':corpus_filtro1['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregar la categoria humor o no humor a los documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El criterio de humor o no humor esta basado en el criterio presentado en la letra del laboratorio, en donde se considerará humorístico si la mitad o más de los anotadores lo calificaron con una o más estrellas y no humorístico en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro2 = pandas.read_csv(\"corpus_filtro2.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "text = []\n",
    "category=[]\n",
    "h1=[]\n",
    "h2=[]\n",
    "h3=[]\n",
    "h4=[]\n",
    "h5=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_text=corpus_filtro2['text'][:]\n",
    "vec_no_humor =corpus_filtro2['n'][:]\n",
    "vec_e1 =corpus_filtro2['1'][:]\n",
    "vec_e2 =corpus_filtro2['2'][:]\n",
    "vec_e3 =corpus_filtro2['3'][:]\n",
    "vec_e4 =corpus_filtro2['4'][:]\n",
    "vec_e5 =corpus_filtro2['5'][:]\n",
    "\n",
    "#Si hay igual o mas votos de humor que de no humor la categoria tiene el valor 1\n",
    "#en caso contrario tiene el valor 0\n",
    "for i in range(len(corpus_filtro2)):\n",
    "    if  vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= vec_no_humor[i]:\n",
    "        category.append(1)\n",
    "    else:\n",
    "        category.append(0)\n",
    "    text.append(vec_text[i])\n",
    "    h1.append(vec_e1[i])\n",
    "    h2.append(vec_e2[i])\n",
    "    h3.append(vec_e3[i])\n",
    "    h4.append(vec_e4[i])\n",
    "    h5.append(vec_e5[i])\n",
    "#El tercer procesamiento aplicado sobre los tweets es guardado en el archivo corpus_filtro.3\n",
    "d = {'text' : text,\n",
    "    'category': category,\n",
    "     '1':h1,\n",
    "     '2':h2,\n",
    "     '3':h3,\n",
    "     '4':h4,\n",
    "     '5':h5\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category','1','2','3','4','5'])\n",
    "df.to_csv('corpus_filtro3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar información de POS-tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro3 = pandas.read_csv(\"corpus_filtro3.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro3['text'][:]\n",
    "\n",
    "#Se genera el patron para identificar las POS de las palabras\n",
    "pattern_pos = re.compile(r'pos=\"(.*?)\"')\n",
    "\n",
    "#Variables para datos estadisticos\n",
    "num_sentences=len(corpus_filtro3)\n",
    "numsentence=1\n",
    "\n",
    "#Variable auxiliar para adherir las POS a los tweets\n",
    "pos=0\n",
    "\n",
    "#Para cada documento en el corpus de tweets que va siendo procesado\n",
    "#utilizando la herramienta freeling se analizan las categorias gramaticales\n",
    "#de todas las palabras que aparecen en cada tweet y esta informacion es\n",
    "#adherida al texto del tweet\n",
    "for d in text_list:\n",
    "    if(type(d) == str):\n",
    "        xml = analyzer.run(d.encode(), 'flush')\n",
    "        print(numsentence, \" \", math.floor( numsentence/num_sentences*100),\"%\", end=\"\\r\")\n",
    "        for sentence in xml:        \n",
    "            for token in sentence:\n",
    "                token_byte=etree.tostring(token)\n",
    "                m = re.search(pattern_pos, token_byte.decode())\n",
    "                if m is not None:\n",
    "                    text_list[ pos] = text_list[pos] + \" \" + m.group(1)\n",
    "    pos+=1\n",
    "    numsentence+=1\n",
    "\n",
    "#El procesamiento actual del corpus es guardado en el documento corpus_filtro4.csv\n",
    "d = {'text' : text_list,\n",
    "    'category': corpus_filtro3['category'][:],\n",
    "     '1':corpus_filtro3['1'][:],\n",
    "     '2':corpus_filtro3['2'][:],\n",
    "     '3':corpus_filtro3['3'][:],\n",
    "     '4':corpus_filtro3['4'][:],\n",
    "     '5':corpus_filtro3['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', '1','2','3','4','5'])\n",
    "df.to_csv('corpus_filtro4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de datos de entrenamiento y de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro4.csv\",encoding='utf-8')\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4)*20/100)\n",
    "#Se generan posiciones en el arreglo tweets al azar que representen el 20% del corpus actual\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4['text'][:]\n",
    "vec_category=corpus_filtro4['category'][:]\n",
    "\n",
    "#Se separa el 20% de corpus para desarrollo del 80% para entrenamiento\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "\n",
    "#Se guardan las instancias corpus de desarrollo en corpus_filtro5_devset.csv\n",
    "#y corpus de entrenamiento en corpus_filtro5_trainingset.csv\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset.csv')\n",
    "\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de mediana, para segundo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia salvada del corpus que se encuentra en el archivo\n",
    "#corpus_filtro4.csv\n",
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro4.csv\",encoding='utf-8')\n",
    "\n",
    "text_list=corpus_filtro4['text'][:]\n",
    "category_list=corpus_filtro4['category'][:]\n",
    "\n",
    "h1_list=corpus_filtro4['1'][:]\n",
    "h2_list=corpus_filtro4['2'][:]\n",
    "h3_list=corpus_filtro4['3'][:]\n",
    "h4_list=corpus_filtro4['4'][:]\n",
    "h5_list=corpus_filtro4['5'][:]\n",
    "\n",
    "medians=[]\n",
    "pos=0\n",
    "\n",
    "#Caclulo de la mediana, en values se expanden los votos de cada estrella\n",
    "#de la siguiente manera si #cant_3Estrellas_en_tweet = 4, entonces se guardan\n",
    "#en values 4 treses 3,3,3,3 para permitir el calculo de la mediana\n",
    "#Por ultimo en la estructura medians se guarda el valor discreto (0,1,2,3,4 o 5) de la mediana\n",
    "#si la cantidad de votos es par se toma el voto del medio con valor mas grande\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    values = []\n",
    "    for j in range( h1_list[i]):\n",
    "        values.append(1)\n",
    "    for j in range( h2_list[i] ):\n",
    "        values.append(2)\n",
    "    for j in range( h3_list[i] ):\n",
    "        values.append(3)\n",
    "    for j in range( h4_list[i] ):\n",
    "        values.append(4)\n",
    "    for j in range( h5_list[i] ):\n",
    "        values.append(5)\n",
    "    if len(values) == 0:\n",
    "        values.append(0)  \n",
    "    mediana=np.median(values)\n",
    "    if( len(values) % 2 == 1 ):\n",
    "        medians.append(math.floor(mediana))\n",
    "    else:\n",
    "        for i in values:\n",
    "            if( i >= mediana):\n",
    "                medians.append(i)\n",
    "                break\n",
    "    pos+=1\n",
    "\n",
    "#El nuevo procesamiento que suma la informacion de la mediana se guarda\n",
    "#en el archivo corpus_filtro4median.csv\n",
    "d = {'text' : corpus_filtro4['text'][:],\n",
    "    'category' : corpus_filtro4['category'][:],\n",
    "    'median': medians,\n",
    "    '1':corpus_filtro4['1'][:],\n",
    "    '2':corpus_filtro4['2'][:],\n",
    "    '3':corpus_filtro4['3'][:],\n",
    "    '4':corpus_filtro4['4'][:],\n",
    "    '5':corpus_filtro4['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', 'median', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro4median.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos de entrenamiento y desarrollo, para segundo clasificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#Se carga la instancia salvada en el bloque de codigo anterior\n",
    "corpus_filtro4median = pandas.read_csv(\"corpus_filtro4median.csv\",encoding='utf-8')\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4median)*20/100)\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4median) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "median_train=[]\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "median_dev=[]\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4median['text'][:]\n",
    "vec_median=corpus_filtro4median['median'][:]\n",
    "vec_category=corpus_filtro4median['category'][:]\n",
    "\n",
    "\n",
    "for i in range( len(corpus_filtro4median)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        median_dev.append(vec_median[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "        \n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        median_train.append(vec_median[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "d = {'text' : text_train,\n",
    "     'median' : median_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'median','category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_c2.csv')\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "     'median': median_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'median', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_c2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento, clasificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4median = pandas.read_csv(\"corpus_filtro4median.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro4median['text'][:]\n",
    "category_list=[]\n",
    "median_list=corpus_filtro4median['median'][:]\n",
    "h1_list=corpus_filtro4median['1'][:]\n",
    "h2_list=corpus_filtro4median['2'][:]\n",
    "h3_list=corpus_filtro4median['3'][:]\n",
    "h4_list=corpus_filtro4median['4'][:]\n",
    "h5_list=corpus_filtro4median['5'][:]\n",
    "pos=0\n",
    "for m in median_list:\n",
    "    if(m<1):\n",
    "        category_list.append(0)\n",
    "    else:\n",
    "        category_list.append(1)\n",
    "    pos+=1\n",
    "d = {'text' : text_list,\n",
    "    'category': category_list,\n",
    "     'median': median_list\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category','median'])\n",
    "df.to_csv('corpus_filtro4median_category.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación datos de entrenamiento y desarrollo, clasificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4median_category = pandas.read_csv(\"corpus_filtro4median_category.csv\",encoding='utf-8')\n",
    "text=corpus_filtro4median_category['text'][:]\n",
    "category=corpus_filtro4median_category['category'][:]\n",
    "median=corpus_filtro4median_category['median'][:]\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4median_category)*20/100)\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4median_category) - 1, size=num_dev_tweets)\n",
    "\n",
    "print(num_dev_tweets)\n",
    "print(random_samples)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4median_category['text'][:]\n",
    "vec_category=corpus_filtro4median_category['category'][:]\n",
    "\n",
    "for i in range( len(corpus_filtro4median_category)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_c3.csv')\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_c3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases para los clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "class Clasificador1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_1_train()\n",
    "    \n",
    "    def __clasiffier_1_train(self):\n",
    "        corpus_filtro5_trainingset = pandas.read_csv(\"corpus_filtro5_trainingset.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5_trainingset['text'][:]\n",
    "        category_list=corpus_filtro5_trainingset['category'][:]\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.train_features = self.vectorizer.fit_transform(text_list)\n",
    "\n",
    "        self.nb_1 = MultinomialNB()\n",
    "        self.nb_1.fit(self.train_features , category_list)\n",
    "    def predict_clasiffier_1(self, path):       \n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text'][:]\n",
    "        category_devlist=corpus_filtro5_devset['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features = self.vectorizer.transform(text_devlist)\n",
    "        return self.nb_1.predict(self.test_features)\n",
    "\n",
    "class Clasificador2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_2_train()\n",
    "        self.__median_predictor_train()\n",
    "\n",
    "    \n",
    "    def __median_predictor_train(self):\n",
    "        corpus_filtro5 = pandas.read_csv(\"corpus_filtro5_trainingset_c2.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5['text'][:]\n",
    "        median_list=corpus_filtro5['median'][:]\n",
    "        self.category_list_c1=[]\n",
    "\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.train_features_c1 = vectorizer.fit_transform(text_list)\n",
    "\n",
    "        for i in median_list:\n",
    "            if(i == 1):\n",
    "                self.category_list_c1.append(1)\n",
    "            else:\n",
    "                self.category_list_c1.append(0)\n",
    "        \n",
    "        self.nb_median1 = MultinomialNB()\n",
    "        self.nb_median1.fit(self.train_features_c1 , self.category_list_c1[:])\n",
    "\n",
    "        self.category_list_c2=[]\n",
    "        for i in median_list:\n",
    "            if(i == 2):\n",
    "                self.category_list_c2.append(1)\n",
    "            else:\n",
    "                self.category_list_c2.append(0)\n",
    "        self.nb_median2 = MultinomialNB()\n",
    "        self.nb_median2.fit(self.train_features_c1 , self.category_list_c2)\n",
    "\n",
    "        self.category_list_c3=[]\n",
    "        for i in median_list:\n",
    "            if(i == 3):\n",
    "                self.category_list_c3.append(1)\n",
    "            else:\n",
    "                self.category_list_c3.append(0)\n",
    "\n",
    "        self.nb_median3 = MultinomialNB()\n",
    "        self.nb_median3.fit(self.train_features_c1 , self.category_list_c3)       \n",
    "\n",
    "        self.category_list_c4=[]\n",
    "        for i in median_list:\n",
    "            if(i == 4):\n",
    "                self.category_list_c4.append(1)\n",
    "            else:\n",
    "                self.category_list_c4.append(0)\n",
    "\n",
    "        self.nb_median4 = MultinomialNB()\n",
    "        self.nb_median4.fit(self.train_features_c1 , self.category_list_c4[:])\n",
    "        \n",
    "        self.category_list_c5=[]\n",
    "        for i in median_list:\n",
    "            if(i == 5):\n",
    "                self.category_list_c5.append(1)\n",
    "            else:\n",
    "                self.category_list_c5.append(0)\n",
    "        self.nb_median5 = MultinomialNB()\n",
    "        self.nb_median5.fit(self.train_features_c1 , self.category_list_c5)\n",
    "\n",
    "        self.category_list_c0=[]\n",
    "        for i in median_list:\n",
    "            if(i == 0):\n",
    "                self.category_list_c0.append(1)\n",
    "            else:\n",
    "                self.category_list_c0.append(0)\n",
    "                \n",
    "        self.nb_median0 = MultinomialNB()\n",
    "        self.nb_median0.fit(self.train_features_c1 , self.category_list_c0)\n",
    "        \n",
    "    def __predict_median1_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c1=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 1:\n",
    "                self.median_list_c1.append(1)\n",
    "            else:\n",
    "                self.median_list_c1.append(0)\n",
    "            \n",
    "\n",
    "        self.test_features_c1 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median1.predict_proba(self.test_features_c1), self.nb_median1.predict(self.test_features_c1)\n",
    "    def __predict_median2_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        \n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c2=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 2:\n",
    "                self.median_list_c2.append(1)\n",
    "            else:\n",
    "                self.median_list_c2.append(0)\n",
    "\n",
    "        \n",
    "        self.test_features_c2 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median2.predict_proba(self.test_features_c2), self.nb_median2.predict(self.test_features_c2)\n",
    "    def __predict_median3_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c3=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 3:\n",
    "                self.median_list_c3.append(1)\n",
    "            else:\n",
    "                self.median_list_c3.append(0)\n",
    "\n",
    "        self.test_features_c3 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median3.predict_proba(self.test_features_c3), self.nb_median3.predict(self.test_features_c3)\n",
    "    def __predict_median4_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c4=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 4:\n",
    "                self.median_list_c4.append(1)\n",
    "            else:\n",
    "                self.median_list_c4.append(0)\n",
    "\n",
    "        self.test_features_c4 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median4.predict_proba(self.test_features_c4), self.nb_median4.predict(self.test_features_c4)\n",
    "    def __predict_median5_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c5=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 5:\n",
    "                self.median_list_c5.append(1)\n",
    "            else:\n",
    "                self.median_list_c5.append(0)\n",
    "\n",
    "        self.test_features_c5 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median5.predict_proba(self.test_features_c5), self.nb_median5.predict(self.test_features_c5)\n",
    "    def __predict_median0_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c0=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 0:\n",
    "                self.median_list_c0.append(1)\n",
    "            else:\n",
    "                self.median_list_c0.append(0)\n",
    "\n",
    "        self.test_features_c0 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median0.predict_proba(self.test_features_c0), self.nb_median0.predict(self.test_features_c0)\n",
    "    def __clasiffier_2_train(self):\n",
    "        corpus_filtro5_trainingset_c2 = pandas.read_csv(\"corpus_filtro5_trainingset_c2.csv\",encoding='utf-8')\n",
    "        text_list_c2=corpus_filtro5_trainingset_c2['text'][:]\n",
    "        category_list_c2=corpus_filtro5_trainingset_c2['category'][:]\n",
    "        pos_c2=0\n",
    "        for t in text_list_c2:\n",
    "            if type(t) != str:\n",
    "                text_list_c2[pos_c2]=\"NaN\"\n",
    "            pos_c2+=1\n",
    "        self.train_features_class2 = self.vectorizer.fit_transform(text_list_c2)\n",
    "\n",
    "        self.nb_2 = MultinomialNB()\n",
    "        self.nb_2.fit(self.train_features_class2, category_list_c2)\n",
    "\n",
    "    \n",
    "    def predict_median(self, path):\n",
    "        self.c1_pred, self.c1_predict=self.__predict_median1_c2(path)\n",
    "        self.c2_pred, self.c2_predict=self.__predict_median2_c2(path)\n",
    "        self.c3_pred, self.c3_predict=self.__predict_median3_c2(path)\n",
    "        self.c4_pred, self.c4_predict=self.__predict_median4_c2(path)\n",
    "        self.c5_pred, self.c5_predict=self.__predict_median5_c2(path)\n",
    "        self.c0_pred, self.c0_predict=self.__predict_median0_c2(path)        \n",
    "        self.predicts=[]\n",
    "        proba=[]\n",
    "        for i in range( len(self.c1_pred) ):\n",
    "            maximum=np.max([self.c1_pred[i][1],self.c2_pred[i][1],self.c3_pred[i][1],self.c4_pred[i][1],self.c5_pred[i][1],self.c0_pred[i][1]])\n",
    "            if(maximum == self.c1_pred[i][1]):\n",
    "                self.predicts.append(1)\n",
    "            elif(maximum == self.c2_pred[i][1]):\n",
    "                self.predicts.append(2)\n",
    "            elif(maximum == self.c3_pred[i][1]):\n",
    "                self.predicts.append(3)\n",
    "            elif(maximum == self.c4_pred[i][1]):\n",
    "                self.predicts.append(4)\n",
    "            elif(maximum == self.c5_pred[i][1]):\n",
    "                self.predicts.append(5)\n",
    "            elif(maximum == self.c0_pred[i][1]):\n",
    "                self.predicts.append(0)\n",
    "            proba.append(maximum)\n",
    "        self.m0 = []\n",
    "        self.m1 = []\n",
    "        self.m2 = []\n",
    "        self.m3 = []\n",
    "        self.m4 = []\n",
    "        self.m5 = []\n",
    "\n",
    "        for pred in self.predicts:\n",
    "            if pred == 0:\n",
    "                self.m0.append(1)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 1:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(1)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 2:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(1)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 3:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(1)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 4:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(1)\n",
    "                self.m5.append(0)\n",
    "            elif pred == 5:\n",
    "                self.m0.append(0)\n",
    "                self.m1.append(0)\n",
    "                self.m2.append(0)\n",
    "                self.m3.append(0)\n",
    "                self.m4.append(0)\n",
    "                self.m5.append(1)\n",
    "\n",
    "        \n",
    "        \n",
    "        corpus_filtro5_devset_c2 = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist_c2=corpus_filtro5_devset_c2['text'][:]\n",
    "        category_devlist_c2=corpus_filtro5_devset_c2['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist_c2:\n",
    "            if type(t) != str:\n",
    "                text_devlist_c2[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features_class2 = self.vectorizer.transform(text_devlist_c2)\n",
    "                    \n",
    "        return self.predicts, proba, self.nb_2.predict(self.test_features_class2)\n",
    "\n",
    "class Clasificador3:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_3_train()\n",
    "    def __clasiffier_3_train(self):\n",
    "        corpus_filtro5_trainingset_c3 = pandas.read_csv(\"corpus_filtro5_trainingset_c3.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5_trainingset_c3['text'][:]\n",
    "        category_list=corpus_filtro5_trainingset_c3['category'][:]\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.train_features = self.vectorizer.fit_transform(text_list)\n",
    "        self.nb = MultinomialNB()\n",
    "        self.nb.fit(self.train_features , category_list)\n",
    "    def predict_clasiffier_1(self, path):\n",
    "        corpus_filtro5_devset_c3 = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset_c3['text'][:]\n",
    "        category_devlist=corpus_filtro5_devset_c3['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features = self.vectorizer.transform(text_devlist)\n",
    "        return self.nb.predict(self.test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1\n",
      " 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1\n",
      " 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1\n",
      " 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador1()\n",
    "print(clasificador.predict_clasiffier_1(\"corpus_filtro5_devset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clasificador=Clasificador2()\n",
    "predict, proba, humor_prob=clasificador.predict_median(\"corpus_filtro5_devset_c2.csv\")\n",
    "print(predict, \"\\n\", proba, \"\\n\", humor_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador3()\n",
    "print(clasificador.predict_clasiffier_1(\"corpus_filtro5_devset_c3.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas para el clasificador 1\n",
      "Precision:  0.7427745664739884\n",
      "Recall:  0.803125\n",
      "Accuracy  0.5492063492063493\n",
      "E-measure  0.7717717717717717\n",
      "Medidas para el clasificador 2\n",
      "Precision:  0.7680722891566265\n",
      "Recall:  0.7634730538922155\n",
      "Accuracy  0.5363489499192245\n",
      "E-measure  0.7657657657657657\n",
      "Medidas para el clasificador 3\n",
      "Precision:  0.8198970840480274\n",
      "Recall:  0.9676113360323887\n",
      "Accuracy  0.9313099041533547\n",
      "E-measure  0.8876508820798514\n",
      "Predicter Median 1\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 1 \t|\n",
      "system negative|\t 68 \t|\t 550 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 2\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 4 \t|\t 22 \t|\n",
      "system negative|\t 76 \t|\t 517 \t|\n",
      "Presicion  0.15384615384615385\n",
      "Recall  0.05\n",
      "Accuracy  0.0420032310177706\n",
      "E-measure  0.07547169811320756\n",
      "Predicter Median 3\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 93 \t|\t 223 \t|\n",
      "system negative|\t 54 \t|\t 249 \t|\n",
      "Presicion  0.29430379746835444\n",
      "Recall  0.6326530612244898\n",
      "Accuracy  0.5105008077544426\n",
      "E-measure  0.4017278617710583\n",
      "Predicter Median 4\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 17 \t|\t 72 \t|\n",
      "system negative|\t 93 \t|\t 437 \t|\n",
      "Presicion  0.19101123595505617\n",
      "Recall  0.15454545454545454\n",
      "Accuracy  0.14378029079159935\n",
      "E-measure  0.1708542713567839\n",
      "Predicter Median 5\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 1 \t|\t 1 \t|\n",
      "system negative|\t 75 \t|\t 542 \t|\n",
      "Presicion  0.5\n",
      "Recall  0.013157894736842105\n",
      "Accuracy  0.0032310177705977385\n",
      "E-measure  0.025641025641025637\n",
      "Predicter Median 0\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 88 \t|\t 97 \t|\n",
      "system negative|\t 50 \t|\t 384 \t|\n",
      "Presicion  0.4756756756756757\n",
      "Recall  0.6376811594202898\n",
      "Accuracy  0.2988691437802908\n",
      "E-measure  0.544891640866873\n",
      "Confusion matrix\n",
      "\t 0 \t 1 \t 2 \t 3 \t 4 \t 5 \n",
      "0 \t 88 \t 13 \t 22 \t 25 \t 17 \t 20\n",
      "1 \t 1 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "2 \t 4 \t 3 \t 4 \t 4 \t 9 \t 2\n",
      "3 \t 34 \t 41 \t 42 \t 93 \t 66 \t 40\n",
      "4 \t 11 \t 11 \t 12 \t 25 \t 17 \t 13\n",
      "5 \t 0 \t 0 \t 0 \t 0 \t 1 \t 1\n",
      "Macro averaging\n",
      "Precision  0.20912547528517111  Recall 0.20912547528517111  F 0.20912547528517111\n",
      "Micro averaging\n",
      "Precision  0.26913947715754  Recall 0.22100534769707703  F 0.24270893300099425\n"
     ]
    }
   ],
   "source": [
    "corpus_filtro5_devset = pandas.read_csv(\"corpus_filtro5_devset.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c2 = pandas.read_csv(\"corpus_filtro5_devset_c2.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c3 = pandas.read_csv(\"corpus_filtro5_devset_c3.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 1\n",
    "list_cat_1 = []\n",
    "list_ecat_1 = []\n",
    "\n",
    "\n",
    "list_cat_1=corpus_filtro5_devset['category'][:]\n",
    "\n",
    "clasificador = Clasificador1()\n",
    "list_ecat_1  = clasificador.predict_clasiffier_1(\"corpus_filtro5_devset.csv\")\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 2\n",
    "list_cat_2 = []\n",
    "list_ecat_2 = []\n",
    "list_edem_2=[]\n",
    "medians = []\n",
    "\n",
    "\n",
    "list_cat_2=corpus_filtro5_devset_c2['category'][:]\n",
    "clasificador2=Clasificador2()\n",
    "list_emed_2, _, list_ecat_2=clasificador2.predict_median(\"corpus_filtro5_devset_c2.csv\")\n",
    "medians=corpus_filtro5_devset_c2['median'][:];\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 3\n",
    "list_cat_3 = []\n",
    "list_ecat_3 = []\n",
    "\n",
    "list_cat_3=corpus_filtro5_devset_c3['category'][:]\n",
    "clasificador3 = Clasificador3()\n",
    "list_ecat_3=clasificador3.predict_clasiffier_1(\"corpus_filtro5_devset_c3.csv\")\n",
    "\n",
    "\n",
    "#Variables para clasificador 1\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_1) ):\n",
    "    if(list_cat_1[i] == 1 and list_ecat_1[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_1[i] == 1 and list_ecat_1[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_1[i] == 0 and list_ecat_1[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 1\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 2\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_2) ):\n",
    "    if(list_cat_2[i] == 1 and list_ecat_2[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_2[i] == 1 and list_ecat_2[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_2[i] == 0 and list_ecat_2[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "\n",
    "print(\"Medidas para el clasificador 2\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 3\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_3) ):\n",
    "    if(list_cat_3[i] == 1 and list_ecat_3[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_3[i] == 1 and list_ecat_3[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_3[i] == 0 and list_ecat_3[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 3\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para las medianas\n",
    "tp_m1=0\n",
    "fp_m1=0\n",
    "tn_m1=0\n",
    "fn_m1=0\n",
    "\n",
    "tp_m2=0\n",
    "fp_m2=0\n",
    "tn_m2=0\n",
    "fn_m2=0\n",
    "\n",
    "tp_m3=0\n",
    "fp_m3=0\n",
    "tn_m3=0\n",
    "fn_m3=0\n",
    "\n",
    "tp_m4=0\n",
    "fp_m4=0\n",
    "tn_m4=0\n",
    "fn_m4=0\n",
    "\n",
    "tp_m5=0\n",
    "fp_m5=0\n",
    "tn_m5=0\n",
    "fn_m5=0\n",
    "\n",
    "tp_m0=0\n",
    "fp_m0=0\n",
    "tn_m0=0\n",
    "fn_m0=0\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c1) ):\n",
    "    if(clasificador2.m1[i] == 1 and medians[i]==1):\n",
    "        tp_m1+=1\n",
    "    elif(clasificador2.m1[i] == 0 and medians[i]==1):\n",
    "        fn_m1+=1\n",
    "    elif(clasificador2.m1[i] == 1 and medians[i]!=1):\n",
    "        fp_m1+=1\n",
    "    else:\n",
    "        tn_m1+=1\n",
    "\n",
    "p_m1=-1\n",
    "r_m1=-1\n",
    "if(tp_m1 + fp_m1 > 0):\n",
    "    p_m1 = tp_m1/(tp_m1 + fp_m1)\n",
    "if(tp_m1 + fn_m1):\n",
    "    r_m1 = tp_m1 / (tp_m1 + fn_m1)\n",
    "\n",
    "print(\"Predicter Median 1\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m1,\"\\t|\\t\", fp_m1, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m1, \"\\t|\\t\", tn_m1, \"\\t|\")\n",
    "if p_m1 > 0:\n",
    "    print(\"Presicion \", p_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m1 > 0:\n",
    "    print(\"Recall \", r_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m1 > 0 and r_m1 > 0):\n",
    "    print(\"Accuracy \", (tp_m1 + fp_m1) / (tp_m1 + fp_m1 + tn_m1 + fn_m1))\n",
    "    print(\"E-measure \", 2*p_m1*r_m1/(p_m1 + r_m1))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c2) ):\n",
    "    if(clasificador2.m2[i] == 1 and medians[i]==2):\n",
    "        tp_m2+=1\n",
    "    elif(clasificador2.m2[i] == 0 and medians[i]==2):\n",
    "        fn_m2+=1\n",
    "    elif(clasificador2.m2[i] == 1 and medians[i]!=2):\n",
    "        fp_m2+=1\n",
    "    else:\n",
    "        tn_m2+=1\n",
    "\n",
    "p_m2=-1\n",
    "r_m2=-1\n",
    "if(tp_m2 + fp_m2 > 0):\n",
    "    p_m2 = tp_m2/(tp_m2 + fp_m2)\n",
    "if(tp_m2 + fn_m2):\n",
    "    r_m2 = tp_m2 / (tp_m2 + fn_m2)\n",
    "\n",
    "print(\"Predicter Median 2\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m2,\"\\t|\\t\", fp_m2, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m2, \"\\t|\\t\", tn_m2, \"\\t|\")\n",
    "if p_m2 > 0:\n",
    "    print(\"Presicion \", p_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m2 > 0:\n",
    "    print(\"Recall \", r_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m2 > 0 and r_m2 > 0):\n",
    "    print(\"Accuracy \", (tp_m2 + fp_m2) / (tp_m2 + fp_m2 + tn_m2 + fn_m2))\n",
    "    print(\"E-measure \", 2*p_m2*r_m2/(p_m2 + r_m2))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c3) ):\n",
    "    if(clasificador2.m3[i] == 1 and medians[i]==3):\n",
    "        tp_m3+=1\n",
    "    elif(clasificador2.m3[i] == 0 and medians[i]==3):\n",
    "        fn_m3+=1\n",
    "    elif(clasificador2.m3[i] == 1 and medians[i]!=3):\n",
    "        fp_m3+=1\n",
    "    else:\n",
    "        tn_m3+=1\n",
    "\n",
    "p_m3=-1\n",
    "r_m3=-1\n",
    "if(tp_m3 + fp_m3 > 0):\n",
    "    p_m3 = tp_m3/(tp_m3 + fp_m3)\n",
    "if(tp_m3 + fn_m3):\n",
    "    r_m3 = tp_m3 / (tp_m3 + fn_m3)\n",
    "\n",
    "print(\"Predicter Median 3\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m3,\"\\t|\\t\", fp_m3, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m3, \"\\t|\\t\", tn_m3, \"\\t|\")\n",
    "if p_m3 > 0:\n",
    "    print(\"Presicion \", p_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m3 > 0:\n",
    "    print(\"Recall \", r_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m3 > 0 and r_m3 > 0):\n",
    "    print(\"Accuracy \", (tp_m3 + fp_m3) / (tp_m3 + fp_m3 + tn_m3 + fn_m3))\n",
    "    print(\"E-measure \", 2*p_m3*r_m3/(p_m3 + r_m3))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c4) ):\n",
    "    if(clasificador2.m4[i] == 1 and medians[i]==4):\n",
    "        tp_m4+=1\n",
    "    elif(clasificador2.m4[i] == 0 and medians[i]==4):\n",
    "        fn_m4+=1\n",
    "    elif(clasificador2.m4[i] == 1 and medians[i]!=4):\n",
    "        fp_m4+=1\n",
    "    else:\n",
    "        tn_m4+=1\n",
    "\n",
    "p_m4=-1\n",
    "r_m4=-1\n",
    "if(tp_m4 + fp_m4 > 0):\n",
    "    p_m4 = tp_m4/(tp_m4 + fp_m4)\n",
    "if(tp_m4 + fn_m4):\n",
    "    r_m4 = tp_m4 / (tp_m4 + fn_m4)\n",
    "\n",
    "print(\"Predicter Median 4\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m4,\"\\t|\\t\", fp_m4, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m4, \"\\t|\\t\", tn_m4, \"\\t|\")\n",
    "if p_m4 > 0:\n",
    "    print(\"Presicion \", p_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m4 > 0:\n",
    "    print(\"Recall \", r_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m4 > 0 and r_m4 > 0):\n",
    "    print(\"Accuracy \", (tp_m4 + fp_m4) / (tp_m4 + fp_m4 + tn_m4 + fn_m4))\n",
    "    print(\"E-measure \", 2*p_m4*r_m4/(p_m4 + r_m4))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c5) ):\n",
    "    if(clasificador2.m5[i] == 1 and medians[i]==5):\n",
    "        tp_m5+=1\n",
    "    elif(clasificador2.m5[i] == 0 and medians[i]==5):\n",
    "        fn_m5+=1\n",
    "    elif(clasificador2.m5[i] == 1 and medians[i]!=5):\n",
    "        fp_m5+=1\n",
    "    else:\n",
    "        tn_m5+=1\n",
    "\n",
    "p_m5=-1\n",
    "r_m5=-1\n",
    "if(tp_m5 + fp_m5 > 0):\n",
    "    p_m5 = tp_m5/(tp_m5 + fp_m5)\n",
    "if(tp_m5 + fn_m5):\n",
    "    r_m5 = tp_m5 / (tp_m5 + fn_m5)\n",
    "\n",
    "print(\"Predicter Median 5\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m5,\"\\t|\\t\", fp_m5, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m5, \"\\t|\\t\", tn_m5, \"\\t|\")\n",
    "if p_m5 > 0:\n",
    "    print(\"Presicion \", p_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m5 > 0:\n",
    "    print(\"Recall \", r_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m5 > 0 and r_m5 > 0):\n",
    "    print(\"Accuracy \", (tp_m5 + fp_m5) / (tp_m5 + fp_m5 + tn_m5 + fn_m5))\n",
    "    print(\"E-measure \", 2*p_m5*r_m5/(p_m5 + r_m5))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c0) ):\n",
    "    if(clasificador2.m0[i] == 1 and medians[i]==0):\n",
    "        tp_m0+=1\n",
    "    elif(clasificador2.m0[i] == 0 and medians[i]==0):\n",
    "        fn_m0+=1\n",
    "    elif(clasificador2.m0[i] == 1 and medians[i]!=0):\n",
    "        fp_m0+=1\n",
    "    else:\n",
    "        tn_m0+=1\n",
    "\n",
    "p_m0=-1\n",
    "r_m0=-1\n",
    "if(tp_m0 + fp_m0 > 0):\n",
    "    p_m0 = tp_m0/(tp_m0 + fp_m0)\n",
    "if(tp_m0 + fn_m0):\n",
    "    r_m0 = tp_m0 / (tp_m0 + fn_m0)\n",
    "\n",
    "print(\"Predicter Median 0\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m0,\"\\t|\\t\", fp_m0, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m0, \"\\t|\\t\", tn_m0, \"\\t|\")\n",
    "if p_m0 > 0:\n",
    "    print(\"Presicion \", p_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m0 > 0:\n",
    "    print(\"Recall \", r_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m0 > 0 and r_m0 > 0):\n",
    "    print(\"Accuracy \", (tp_m0 + fp_m0) / (tp_m0 + fp_m0 + tn_m0 + fn_m0))\n",
    "    print(\"E-measure \", 2*p_m0*r_m0/(p_m0 + r_m0))\n",
    "    \n",
    "print(\"Confusion matrix\")\n",
    "print(\"\\t 0 \\t 1 \\t 2 \\t 3 \\t 4 \\t 5 \")\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c0_predict)):\n",
    "    if(medians[pos] != 0 and clasificador2.predicts[pos] == 0):\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"0 \\t\", tp_m0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c1_predict)):\n",
    "    if(medians[pos] != 1 and clasificador2.predicts[pos] == 1):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"1 \\t\", conf0, \"\\t\", tp_m1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c2_predict)):\n",
    "    if(medians[pos] != 2 and clasificador2.predicts[pos] == 2):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"2 \\t\", conf0, \"\\t\", conf1, \"\\t\", tp_m2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c3_predict)):\n",
    "    if(medians[pos] != 3 and clasificador2.predicts[pos] == 3):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"3 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", tp_m3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c4_predict)):\n",
    "    if(medians[pos] != 4 and clasificador2.predicts[pos] == 4):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"4 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", tp_m4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c5_predict)):\n",
    "    if(medians[pos] != 5 and clasificador2.predicts[pos] == 5):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "print(\"5 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", tp_m5);\n",
    "\n",
    "print(\"Macro averaging\")\n",
    "macropresicion=(tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) / ( (tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) + (fp_m0 + fp_m1 + fp_m2 + fp_m3 + fp_m4 + fp_m5))\n",
    "macrorecall=(tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) / ( (tp_m0 + tp_m1 + tp_m2 + tp_m4 + tp_m5) + (fn_m0 + fn_m1 + fn_m2 + fn_m3 + fn_m4 + fn_m5))\n",
    "macrof=2*macropresicion*macrorecall/(macrorecall + macropresicion)\n",
    "print(\"Precision \", macropresicion, \" Recall\", macrorecall, \" F\", macrof)\n",
    "\n",
    "print(\"Micro averaging\")\n",
    "micropresicion=(p_m0 + p_m1 + p_m2 + p_m3 + p_m4 + p_m5)/6\n",
    "microrecall=(p_m0 + r_m1 + r_m2 + r_m3 + r_m4 + r_m5)/6\n",
    "microf=2*micropresicion*microrecall/(micropresicion + microrecall)\n",
    "print(\"Precision \", micropresicion, \" Recall\", microrecall, \" F\", microf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de medidas para las medianas hecho de forma independiente, se presentan las tablas de contingencia de las predicciones de los clasificadores binarios sin tener en cuenta las probabilidades de los otros clasificadores binarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicter Median 1\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 68 \t|\t 551 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 2\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 2 \t|\n",
      "system negative|\t 78 \t|\t 537 \t|\n",
      "Presicion  0.5\n",
      "Recall  0.025\n",
      "Accuracy  0.006462035541195477\n",
      "E-measure  0.047619047619047616\n",
      "Predicter Median 3\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 7 \t|\t 17 \t|\n",
      "system negative|\t 140 \t|\t 455 \t|\n",
      "Presicion  0.2916666666666667\n",
      "Recall  0.047619047619047616\n",
      "Accuracy  0.03877221324717286\n",
      "E-measure  0.08187134502923976\n",
      "Predicter Median 4\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 12 \t|\n",
      "system negative|\t 108 \t|\t 497 \t|\n",
      "Presicion  0.14285714285714285\n",
      "Recall  0.01818181818181818\n",
      "Accuracy  0.022617124394184167\n",
      "E-measure  0.032258064516129024\n",
      "Predicter Median 5\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 1 \t|\n",
      "system negative|\t 74 \t|\t 542 \t|\n",
      "Presicion  0.6666666666666666\n",
      "Recall  0.02631578947368421\n",
      "Accuracy  0.004846526655896607\n",
      "E-measure  0.05063291139240506\n",
      "Predicter Median 0\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 24 \t|\t 13 \t|\n",
      "system negative|\t 114 \t|\t 468 \t|\n",
      "Presicion  0.6486486486486487\n",
      "Recall  0.17391304347826086\n",
      "Accuracy  0.05977382875605816\n",
      "E-measure  0.2742857142857143\n"
     ]
    }
   ],
   "source": [
    "#Variables para las medianas\n",
    "tp_m1=0\n",
    "fp_m1=0\n",
    "tn_m1=0\n",
    "fn_m1=0\n",
    "\n",
    "tp_m2=0\n",
    "fp_m2=0\n",
    "tn_m2=0\n",
    "fn_m2=0\n",
    "\n",
    "tp_m3=0\n",
    "fp_m3=0\n",
    "tn_m3=0\n",
    "fn_m3=0\n",
    "\n",
    "tp_m4=0\n",
    "fp_m4=0\n",
    "tn_m4=0\n",
    "fn_m4=0\n",
    "\n",
    "tp_m5=0\n",
    "fp_m5=0\n",
    "tn_m5=0\n",
    "fn_m5=0\n",
    "\n",
    "tp_m0=0\n",
    "fp_m0=0\n",
    "tn_m0=0\n",
    "fn_m0=0\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c1) ):\n",
    "    if(clasificador2.median_list_c1[i] == 1 and clasificador2.c1_predict[i]==1):\n",
    "        tp_m1+=1\n",
    "    elif(clasificador2.median_list_c1[i] == 1 and clasificador2.c1_predict[i]==0):\n",
    "        fn_m1+=1\n",
    "    elif(clasificador2.median_list_c1[i] == 0 and clasificador2.c1_predict[i]==1):\n",
    "        fp_m1+=1\n",
    "    else:\n",
    "        tn_m1+=1\n",
    "\n",
    "p_m1=-1\n",
    "r_m1=-1\n",
    "if(tp_m1 + fp_m1 > 0):\n",
    "    p_m1 = tp_m1/(tp_m1 + fp_m1)\n",
    "if(tp_m1 + fn_m1):\n",
    "    r_m1 = tp_m1 / (tp_m1 + fn_m1)\n",
    "\n",
    "print(\"Predicter Median 1\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m1,\"\\t|\\t\", fp_m1, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m1, \"\\t|\\t\", tn_m1, \"\\t|\")\n",
    "if p_m1 > 0:\n",
    "    print(\"Presicion \", p_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m1 > 0:\n",
    "    print(\"Recall \", r_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m1 > 0 and r_m1 > 0):\n",
    "    print(\"Accuracy \", (tp_m1 + fp_m1) / (tp_m1 + fp_m1 + tn_m1 + fn_m1))\n",
    "    print(\"E-measure \", 2*p_m1*r_m1/(p_m1 + r_m1))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c2) ):\n",
    "    if(clasificador2.median_list_c2[i] == 1 and clasificador2.c2_predict[i]==1):\n",
    "        tp_m2+=1\n",
    "    elif(clasificador2.median_list_c2[i] == 1 and clasificador2.c2_predict[i]==0):\n",
    "        fn_m2+=1\n",
    "    elif(clasificador2.median_list_c2[i] == 0 and clasificador2.c2_predict[i]==1):\n",
    "        fp_m2+=1\n",
    "    else:\n",
    "        tn_m2+=1\n",
    "\n",
    "p_m2=-1\n",
    "r_m2=-1\n",
    "if(tp_m2 + fp_m2 > 0):\n",
    "    p_m2 = tp_m2/(tp_m2 + fp_m2)\n",
    "if(tp_m2 + fn_m2):\n",
    "    r_m2 = tp_m2 / (tp_m2 + fn_m2)\n",
    "\n",
    "print(\"Predicter Median 2\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m2,\"\\t|\\t\", fp_m2, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m2, \"\\t|\\t\", tn_m2, \"\\t|\")\n",
    "if p_m2 > 0:\n",
    "    print(\"Presicion \", p_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m2 > 0:\n",
    "    print(\"Recall \", r_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m2 > 0 and r_m2 > 0):\n",
    "    print(\"Accuracy \", (tp_m2 + fp_m2) / (tp_m2 + fp_m2 + tn_m2 + fn_m2))\n",
    "    print(\"E-measure \", 2*p_m2*r_m2/(p_m2 + r_m2))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c3) ):\n",
    "    if(clasificador2.median_list_c3[i] == 1 and clasificador2.c3_predict[i]==1):\n",
    "        tp_m3+=1\n",
    "    elif(clasificador2.median_list_c3[i] == 1 and clasificador2.c3_predict[i]==0):\n",
    "        fn_m3+=1\n",
    "    elif(clasificador2.median_list_c3[i] == 0 and clasificador2.c3_predict[i]==1):\n",
    "        fp_m3+=1\n",
    "    else:\n",
    "        tn_m3+=1\n",
    "\n",
    "p_m3=-1\n",
    "r_m3=-1\n",
    "if(tp_m3 + fp_m3 > 0):\n",
    "    p_m3 = tp_m3/(tp_m3 + fp_m3)\n",
    "if(tp_m3 + fn_m3):\n",
    "    r_m3 = tp_m3 / (tp_m3 + fn_m3)\n",
    "\n",
    "print(\"Predicter Median 3\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m3,\"\\t|\\t\", fp_m3, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m3, \"\\t|\\t\", tn_m3, \"\\t|\")\n",
    "if p_m3 > 0:\n",
    "    print(\"Presicion \", p_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m3 > 0:\n",
    "    print(\"Recall \", r_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m3 > 0 and r_m3 > 0):\n",
    "    print(\"Accuracy \", (tp_m3 + fp_m3) / (tp_m3 + fp_m3 + tn_m3 + fn_m3))\n",
    "    print(\"E-measure \", 2*p_m3*r_m3/(p_m3 + r_m3))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c4) ):\n",
    "    if(clasificador2.median_list_c4[i] == 1 and clasificador2.c4_predict[i]==1):\n",
    "        tp_m4+=1\n",
    "    elif(clasificador2.median_list_c4[i] == 1 and clasificador2.c4_predict[i]==0):\n",
    "        fn_m4+=1\n",
    "    elif(clasificador2.median_list_c4[i] == 0 and clasificador2.c4_predict[i]==1):\n",
    "        fp_m4+=1\n",
    "    else:\n",
    "        tn_m4+=1\n",
    "\n",
    "p_m4=-1\n",
    "r_m4=-1\n",
    "if(tp_m4 + fp_m4 > 0):\n",
    "    p_m4 = tp_m4/(tp_m4 + fp_m4)\n",
    "if(tp_m4 + fn_m4):\n",
    "    r_m4 = tp_m4 / (tp_m4 + fn_m4)\n",
    "\n",
    "print(\"Predicter Median 4\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m4,\"\\t|\\t\", fp_m4, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m4, \"\\t|\\t\", tn_m4, \"\\t|\")\n",
    "if p_m4 > 0:\n",
    "    print(\"Presicion \", p_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m4 > 0:\n",
    "    print(\"Recall \", r_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m4 > 0 and r_m4 > 0):\n",
    "    print(\"Accuracy \", (tp_m4 + fp_m4) / (tp_m4 + fp_m4 + tn_m4 + fn_m4))\n",
    "    print(\"E-measure \", 2*p_m4*r_m4/(p_m4 + r_m4))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c5) ):\n",
    "    if(clasificador2.median_list_c5[i] == 1 and clasificador2.c5_predict[i]==1):\n",
    "        tp_m5+=1\n",
    "    elif(clasificador2.median_list_c5[i] == 1 and clasificador2.c5_predict[i]==0):\n",
    "        fn_m5+=1\n",
    "    elif(clasificador2.median_list_c5[i] == 0 and clasificador2.c5_predict[i]==1):\n",
    "        fp_m5+=1\n",
    "    else:\n",
    "        tn_m5+=1\n",
    "\n",
    "p_m5=-1\n",
    "r_m5=-1\n",
    "if(tp_m5 + fp_m5 > 0):\n",
    "    p_m5 = tp_m5/(tp_m5 + fp_m5)\n",
    "if(tp_m5 + fn_m5):\n",
    "    r_m5 = tp_m5 / (tp_m5 + fn_m5)\n",
    "\n",
    "print(\"Predicter Median 5\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m5,\"\\t|\\t\", fp_m5, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m5, \"\\t|\\t\", tn_m5, \"\\t|\")\n",
    "if p_m5 > 0:\n",
    "    print(\"Presicion \", p_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m5 > 0:\n",
    "    print(\"Recall \", r_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m5 > 0 and r_m5 > 0):\n",
    "    print(\"Accuracy \", (tp_m5 + fp_m5) / (tp_m5 + fp_m5 + tn_m5 + fn_m5))\n",
    "    print(\"E-measure \", 2*p_m5*r_m5/(p_m5 + r_m5))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c0) ):\n",
    "    if(clasificador2.median_list_c0[i] == 1 and clasificador2.c0_predict[i]==1):\n",
    "        tp_m0+=1\n",
    "    elif(clasificador2.median_list_c0[i] == 1 and clasificador2.c0_predict[i]==0):\n",
    "        fn_m0+=1\n",
    "    elif(clasificador2.median_list_c0[i] == 0 and clasificador2.c0_predict[i]==1):\n",
    "        fp_m0+=1\n",
    "    else:\n",
    "        tn_m0+=1\n",
    "\n",
    "p_m0=-1\n",
    "r_m0=-1\n",
    "if(tp_m0 + fp_m0 > 0):\n",
    "    p_m0 = tp_m0/(tp_m0 + fp_m0)\n",
    "if(tp_m0 + fn_m0):\n",
    "    r_m0 = tp_m0 / (tp_m0 + fn_m0)\n",
    "\n",
    "print(\"Predicter Median 0\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m0,\"\\t|\\t\", fp_m0, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m0, \"\\t|\\t\", tn_m0, \"\\t|\")\n",
    "if p_m0 > 0:\n",
    "    print(\"Presicion \", p_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m0 > 0:\n",
    "    print(\"Recall \", r_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m0 > 0 and r_m0 > 0):\n",
    "    print(\"Accuracy \", (tp_m0 + fp_m0) / (tp_m0 + fp_m0 + tn_m0 + fn_m0))\n",
    "    print(\"E-measure \", 2*p_m0*r_m0/(p_m0 + r_m0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
