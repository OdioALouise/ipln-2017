{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pdf1.png)\n",
    "![title](imagenes/pdf/pdf2.png)\n",
    "![title](imagenes/pdf/pdf3.png)\n",
    "![title](imagenes/pdf/pdf4.png)\n",
    "![title](imagenes/pdf/pdf5.png)\n",
    "![title](imagenes/pdf/pdf6.png)\n",
    "![title](imagenes/pdf/pdf7.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de votos 26943\n",
      "No humor, votos 14131  porcentaje  52.4477600861\n",
      "Humor 1 estrella, votos  2960  porcentaje  10.9861559589\n",
      "Humor 2 estrellas, votos  2421  porcentaje  8.98563634339\n",
      "Humor 3 estrellas, votos  3274  porcentaje  12.1515792599\n",
      "Humor 4 estrellas, votos  2541  porcentaje  9.43102104443\n",
      "Humor 5 estrellas, votos  1616  porcentaje  5.99784730728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sebastiandaloia/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTACION Cantidad de votos por calificacion, promedio de estrellas, fraccion de votos de humor\n",
    "\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "fraccion_votos_humor = (total - no_humor)/total\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total de votos\", total)\n",
    "print(\"No humor, votos\", no_humor,\" porcentaje \", no_humor/total*100)\n",
    "print(\"Humor 1 estrella, votos \", humor_e1, \" porcentaje \", humor_e1/total*100)\n",
    "print(\"Humor 2 estrellas, votos \", humor_e2, \" porcentaje \", humor_e2/total*100)\n",
    "print(\"Humor 3 estrellas, votos \", humor_e3, \" porcentaje \", humor_e3/total*100)\n",
    "print(\"Humor 4 estrellas, votos \", humor_e4, \" porcentaje \", humor_e4/total*100)\n",
    "print(\"Humor 5 estrellas, votos \", humor_e5, \" porcentaje \", humor_e5/total*100)\n",
    "print(\"Promedio de estrellas PV \", promedio_estrellas_pv) \n",
    "print(\"Promedio de estrellas PVP \", promedio_estrellas_pvp)\n",
    "print(\"Fracción votos de humor\", fraccion_votos_humor)\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sebastiandaloia', api_key='cMoSSDnwQHyafA8prIEv')\n",
    "\n",
    "\n",
    "\n",
    "#Impresion de valores usando ploly\n",
    "labels = ['No humor','1 Estrella','2 Estrellas','3 Estrellas', '4 Estrellas', '5 Estrellas']\n",
    "values = [no_humor, humor_e1, humor_e2, humor_e3, humor_e4, humor_e5]\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "plotly.plotly.iplot([trace], filename='basic_pie_chart')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pdf8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets  12106\n",
      "Los tweets mas votados tienen  21 votos\n",
      "Los tweets con dos o menos votos forman un total de  8668\n",
      "Los chistes mas graciosos son\n",
      "1 \n",
      " —¿A dónde vas tan maquillada? —A una fiesta, mamá. —¿Eres el payaso? —¡MAMÁAAA! :( —JAJAJÁ, cállate y hazme reír o no vas. —Ok. :(\n",
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~sebastiandaloia/0 or inside your plot.ly account where it is named 'mpl-basic-histogram'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~sebastiandaloia/0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTACION Cantidad de votos por tweet\n",
    "#Vectores\n",
    "vec_ids=corpus['id'][:]\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "#Variables\n",
    "cant_tweets=len(corpus)\n",
    "\n",
    "print(\"Cantidad de tweets \", cant_tweets)\n",
    "\n",
    "tweet_id_vot=np.zeros((cant_tweets, 2), np.int64)\n",
    "\n",
    "contador=0\n",
    "for i in range(0, cant_tweets):\n",
    "    tweet_id_vot[i, 0]=vec_ids[i]\n",
    "    tweet_id_vot[i,1]=vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i]\n",
    "\n",
    "\n",
    "array=tweet_id_vot[:,1]\n",
    "array=np.sort(array, axis=None)\n",
    "last=array[len(array) - 1]\n",
    "\n",
    "lesseq_3=0\n",
    "for i in range(0, cant_tweets):\n",
    "    if( array[i] > 2 ):\n",
    "        break;\n",
    "    lesseq_3+=1\n",
    "\n",
    "print(\"Los tweets mas votados tienen \", last, \"votos\")\n",
    "print(\"Los tweets con dos o menos votos forman un total de \", lesseq_3)\n",
    "\n",
    "contador=1\n",
    "print(\"Los chistes mas graciosos son\")\n",
    "for i in range(0, cant_tweets):\n",
    "    if( vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] == 21 ):\n",
    "        print(contador, \"\\n\", corpus['text'][i])\n",
    "\n",
    "plotly.tools.set_credentials_file(username='sebastiandaloia', api_key='cMoSSDnwQHyafA8prIEv')\n",
    "\n",
    "votos_nums = tweet_id_vot[:,1]\n",
    "\n",
    "plt.hist(votos_nums)\n",
    "plt.title(\"Histograma de votos por tweet\")\n",
    "plt.xlabel(\"Votos\")\n",
    "plt.ylabel(\"Tweets\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "plotly.plotly.plot_mpl(fig, filename='mpl-basic-histogram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fracción votos de humor 0.475522399139\n"
     ]
    }
   ],
   "source": [
    "#iMPLEMENTACION Fraccion de votos de humor\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "fraccion_votos_humor = (total - no_humor)/total\n",
    "\n",
    "print(\"Fracción votos de humor\", fraccion_votos_humor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagenes/pdf/pdf9.png)\n",
    "![title](imagenes/pdf/pdf10.png)\n",
    "![title](imagenes/pdf/pdf11.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de estrellas PV  1.3312548714\n",
      "Promedio de estrellas PVP  2.79956290977\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION Promedio de estrellas\n",
    "import pandas\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from lxml import etree\n",
    "import re\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Calificaciones\n",
    "no_humor=0\n",
    "humor_e1=0\n",
    "humor_e2=0\n",
    "humor_e3=0\n",
    "humor_e4=0\n",
    "humor_e5=0\n",
    "total=0\n",
    "\n",
    "#Vectores tomados del corpus\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "\n",
    "#Se suman los votos por cada calificacion\n",
    "for calificacion in vec_no_humor[:]:\n",
    "    no_humor+=calificacion\n",
    "\n",
    "for calificacion in vec_e1[:]:\n",
    "    humor_e1+=calificacion\n",
    "    \n",
    "for calificacion in vec_e2[:]:\n",
    "    humor_e2+=calificacion\n",
    "    \n",
    "for calificacion in vec_e3[:]:\n",
    "    humor_e3+=calificacion\n",
    "    \n",
    "for calificacion in vec_e4[:]:\n",
    "    humor_e4+=calificacion\n",
    "\n",
    "for calificacion in vec_e5[:]:\n",
    "    humor_e5+=calificacion\n",
    "\n",
    "total=no_humor + humor_e1 + humor_e2 + humor_e3 + humor_e4 + humor_e5\n",
    "\n",
    "promedio_estrellas_pv = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/total\n",
    "promedio_estrellas_pvp = (humor_e1 + 2*humor_e2 + 3*humor_e3 + 4*humor_e4 + 5*humor_e5)/(total - no_humor)\n",
    "\n",
    "print(\"Promedio de estrellas PV \", promedio_estrellas_pv) \n",
    "print(\"Promedio de estrellas PVP \", promedio_estrellas_pvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los chistes mas graciosos son: \n",
      "1  - PV : 4.75 votos:  4\n",
      "   -Mamá tuvimos un examen sorpresa en la escuela - ¿Y que pasó hijo? -Estuve muy sorprendido mamá.\n",
      "2  - PV : 4.5 votos:  4\n",
      "   ¿Cómo se llama la secretaria de Batman? Bati la fea... #chistes #fb\n",
      "3  - PV : 4.5 votos:  4\n",
      "   Quedarse atrapado en la esquina de la ducha porque el agua sale muy fría.\n",
      "4  - PV : 4.4 votos:  5\n",
      "   —Amor, ¿Ya está dentro? —Sí ¿Te lastima? —Sí amor, mételo despacito, duele cuando entra. —Ok, vamos a intentar otro número de zapato :)\n",
      "5  - PV : 4.25 votos:  4\n",
      "   —Violarte es mi sueño —¿QUÉ? —Que estudio diseño —No, ¡ahora me violas!\n",
      "6  - PV : 4.25 votos:  4\n",
      "   — ¡Profe! ¿Puedo ir al baño?. *Regresa con comida*.\n",
      "7  - PV : 4.25 votos:  4\n",
      "   Las mujeres de hoy en día con tal de no hacer limpieza en la casa, se inventan que les gusta el fútbol.\n",
      "8  - PV : 4.25 votos:  4\n",
      "   Siempre será mejor hablar en clases que en el recreo.\n",
      "9  - PV : 4.25 votos:  4\n",
      "   Lunes Martes Miércoles Jueves Casi Sábado Sábado Casi Lunes.\n",
      "10  - PV : 4.25 votos:  4\n",
      "   Todo es comestible hasta que la diarrea demuestre lo contrario...\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTACION Mejores chistes:\n",
    "# 1: Para ser considerados deben tener al menos 3 votos en total 1 de ellos debe ser de humor.\n",
    "# 2: Entre los candidatos los mas graciosos seran los que tengan mejor promedio de estrellas y entre estos los de mas votos.\n",
    "# 3: Se listan los mejores 10 chistes, esto puede cambiarse cambiando el valor de cantidad_mejores_chistes.\n",
    "mejores_chistes = np.array([])\n",
    "cant_votos = []\n",
    "prom_estrellas_pv = []\n",
    "votos_humor = []\n",
    "minimo_votos = 3\n",
    "cantidad_mejores_chistes = 10\n",
    "#Variables\n",
    "cant_tweets=len(corpus)\n",
    "for i in range(0, cant_tweets):\n",
    "    votos_humor.append(vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i])\n",
    "    cant_votos.append(vec_no_humor[i] + votos_humor[i])\n",
    "    prom_estrellas_pv.append((vec_e1[i] + 2*vec_e2[i] + 3*vec_e3[i] + 4*vec_e4[i] + 5*vec_e5[i])/cant_votos[i])\n",
    "    \n",
    "    #debe tener la cantidad de votos necesaria y almenos un voto de humor para ser considerado\n",
    "    if( cant_votos[i] > minimo_votos and votos_humor[i] > 0 ): \n",
    "        #solo se mostraran los 5 mejores chistes.\n",
    "        chiste = np.array([corpus['text'][i], prom_estrellas_pv[i], cant_votos[i]])\n",
    "        if (len(mejores_chistes) > 0):\n",
    "            mejores_chistes = np.vstack((mejores_chistes, chiste))\n",
    "        else :\n",
    "            mejores_chistes = np.append(mejores_chistes, chiste)\n",
    "   \n",
    "print(\"\")\n",
    "print(\"Los chistes mas graciosos son: \")\n",
    "\n",
    "ind = np.lexsort((mejores_chistes[:,2],mejores_chistes[:,1]))\n",
    "for i in range(0, cantidad_mejores_chistes):\n",
    "    j = len(mejores_chistes) - i - 1\n",
    "    print(i+1, \" - PV :\",mejores_chistes[ind][j][1], \"votos: \", mejores_chistes[ind][j][2])\n",
    "    print(\"  \", mejores_chistes[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negación general:  0.0\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION Negatividad\n",
    "pattern_tag = re.compile(r'lemma=\"(no?)\"')\n",
    "\n",
    "tam=len(corpus)\n",
    "total_no=0;\n",
    "total_token=0\n",
    "\n",
    "for i in np.random.randint(0, tam, 5):\n",
    "    text = corpus['text'][i]\n",
    "    tweet_token=0\n",
    "    token_no=0\n",
    "    xml = analyzer.run(text.encode(), 'flush')\n",
    "    for sentence in xml:\n",
    "        for token in sentence: \n",
    "            tweet_token+=1\n",
    "            m = re.search(pattern_tag, etree.tostring(token).decode())\n",
    "            if m :\n",
    "                token_no+=1\n",
    "             \n",
    "        \n",
    "    total_no+=token_no    \n",
    "    total_token+=tweet_token\n",
    "        \n",
    "print(\"Negación general: \", total_no/math.sqrt(total_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de links encontrados  3280\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION cantidad de links\n",
    "\n",
    "pattern_http = re.compile(r'http://')\n",
    "\n",
    "num_links=0\n",
    "\n",
    "for text in corpus['text'][:]:\n",
    "    result = pattern_http.findall(text) \n",
    "    num_links+=len(result)\n",
    "\n",
    "print(\"Cantidad de links encontrados \", num_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana primera persona  0.0\n",
      "Mediana segunda persona  0.0\n",
      "Media primera persona  0.183470578311\n",
      "Media segunda persona  0.16683360628\n",
      "[0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 0.48507125007266594, 0.45883146774112349, 0.23570226039551587, 0.0, 0.0, 1.0606601717798212, 0.0, 0.15075567228888181, 0.75, 0.45883146774112349, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.17677669529663687, 0.0, 0.0, 0.24253562503633297, 0.2581988897471611, 1.1470786693528088, 0.0, 0.0, 0.0, 0.3481553119113957, 0.0, 0.0, 0.0, 0.0, 0.87287156094396956, 0.18257418583505536, 0.3481553119113957, 0.0, 0.17677669529663687, 0.18257418583505536, 0.0, 0.48507125007266594, 1.2060453783110545, 0.40000000000000002, 0.41702882811414954, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.0, 1.0, 0.55470019622522915, 0.0, 1.0206207261596576, 0.40824829046386307, 0.60302268915552726, 0.16666666666666666, 0.54772255750516607, 0.0, 0.39223227027636809, 0.30151134457776363, 0.59999999999999998, 0.2581988897471611, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.47140452079103173, 0.0, 0.25, 0.0, 0.0, 0.2581988897471611, 0.34299717028501764, 0.5, 0.0, 0.43643578047198478, 0.31622776601683794, 0.20851441405707477, 0.0, 0.5388159060803247, 0.0, 0.0, 0.0, 0.0, 0.6546536707079772, 0.0, 1.0776318121606494, 0.0, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.36514837167011072, 0.63245553203367588, 1.0206207261596576, 0.0, 0.0, 0.1889822365046136, 0.32879797461071458, 0.0, 0.0, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.81649658092772615, 0.0, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38490017945975052, 0.17960530202677491, 0.70710678118654746, 0.0, 0.17149858514250882, 0.58834840541455213, 0.17407765595569785, 0.1690308509457033, 0.0, 0.0, 0.15430334996209191, 0.24253562503633297, 0.48507125007266594, 0.25, 0.0, 0.1690308509457033, 0.57735026918962584, 0.0, 0.20851441405707477, 0.0, 0.17407765595569785, 0.28867513459481292, 0.0, 0.0, 0.0, 0.60302268915552726, 0.5303300858899106, 0.0, 0.19611613513818404, 0.19611613513818404, 0.47140452079103173, 0.0, 0.0, 0.0, 0.42640143271122083, 0.0, 0.21821789023599239, 0.37139067635410372, 0.0, 0.0, 0.46852128566581819, 0.0, 0.0, 0.0, 0.35355339059327373, 0.0, 0.18569533817705186, 0.45883146774112349, 0.76980035891950105, 0.63960214906683133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.0, 0.51449575542752646, 0.0, 0.0, 0.0, 0.31234752377721214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.19245008972987526, 0.0, 0.0, 0.68599434057003528, 1.212678125181665, 0.47140452079103173, 0.0, 0.0, 0.37139067635410372, 0.0, 0.42640143271122083, 0.24253562503633297, 0.70710678118654757, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.0, 0.0, 0.67082039324993692, 0.0, 0.0, 0.0, 0.0, 0.7559289460184544, 0.0, 0.34299717028501764, 0.0, 0.0, 0.0, 0.55708601453115558, 0.0, 0.0, 0.1889822365046136, 0.0, 0.48507125007266594, 0.31622776601683794, 0.49319696191607187, 0.0, 0.0, 0.68599434057003528, 0.0, 0.0, 0.17407765595569785, 0.38490017945975052, 0.17677669529663687, 0.0, 0.0, 0.21821789023599239, 0.0, 0.73029674334022143, 0.17149858514250882, 0.0, 0.5, 0.21821789023599239, 0.0, 0.20851441405707477, 0.0, 0.25, 0.67082039324993692, 0.0, 0.36514837167011072, 0.54772255750516607, 0.0, 0.66666666666666663, 0.0, 0.0, 0.53452248382484879, 0.0, 0.44721359549995793, 0.0, 0.21821789023599239, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 1.0660035817780522, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.94491118252306805, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.21320071635561041, 0.23570226039551587, 0.0, 0.6546536707079772, 0.0, 0.73029674334022143, 0.17960530202677491, 0.0, 0.20412414523193154, 1.0, 0.0, 0.0, 1.1094003924504583, 0.0, 0.83205029433784372, 0.0, 0.23570226039551587, 0.0, 0.72760687510899891, 0.76980035891950105, 0.0, 0.0, 0.0, 0.75, 0.0, 0.34299717028501764, 0.20000000000000001, 0.30151134457776363, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.39223227027636809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.0, 0.73029674334022143, 0.0, 0.0, 0.17960530202677491, 0.28867513459481292, 0.0, 0.0, 0.5, 0.0, 0.47140452079103173, 0.0, 0.15617376188860607, 0.35355339059327373, 0.0, 0.21320071635561041, 0.0, 0.2672612419124244, 0.0, 0.57735026918962584, 0.0, 0.21821789023599239, 0.41702882811414954, 0.0, 0.35921060405354982, 0.2581988897471611, 0.0, 0.42640143271122083, 0.0, 0.18257418583505536, 0.48507125007266594, 0.0, 0.39223227027636809, 0.0, 0.35921060405354982, 0.0, 0.44721359549995793, 0.0, 0.20000000000000001, 0.0, 0.22941573387056174, 0.44721359549995793, 0.0, 0.20000000000000001, 0.0, 0.22941573387056174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.24253562503633297, 0.40824829046386307, 0.0, 0.28867513459481292, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 0.17960530202677491, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.17960530202677491, 0.0, 0.0, 0.21821789023599239, 0.72760687510899891, 0.0, 0.59999999999999998, 0.0, 0.24253562503633297, 0.40000000000000002, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.21821789023599239, 0.56694670951384085, 0.0, 0.0, 1.1094003924504583, 0.0, 0.5222329678670935, 0.37139067635410372, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.21821789023599239, 0.0, 0.14744195615489714, 0.0, 0.82199493652678646, 0.0, 0.0, 0.0, 0.98058067569092022, 0.0, 0.16439898730535729, 0.20412414523193154, 0.0, 0.1889822365046136, 0.0, 0.19611613513818404, 0.35921060405354982, 0.50709255283710997, 0.20851441405707477, 0.17149858514250882, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.19245008972987526, 0.0, 0.59999999999999998, 0.32444284226152509, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.70710678118654746, 0.0, 0.0, 0.0, 0.88388347648318433, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.0, 0.51449575542752646, 0.0, 0.27735009811261457, 0.22941573387056174, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 1.150792911137501, 0.43643578047198478, 1.1094003924504583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 0.0, 0.76980035891950105, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.47140452079103173, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.31622776601683794, 0.5388159060803247, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19245008972987526, 0.1889822365046136, 0.0, 0.17960530202677491, 1.0776318121606494, 0.0, 0.21320071635561041, 0.33333333333333331, 0.0, 0.67082039324993692, 0.20412414523193154, 0.0, 0.0, 0.0, 0.7745966692414834, 0.0, 0.0, 1.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.17149858514250882, 0.0, 0.48038446141526137, 0.0, 0.0, 0.2581988897471611, 0.17407765595569785, 0.20000000000000001, 0.42640143271122083, 0.72760687510899891, 0.0, 0.0, 0.0, 0.75, 0.17960530202677491, 0.0, 0.0, 0.0, 0.40000000000000002, 0.0, 0.0, 0.63960214906683133, 0.0, 0.0, 0.36514837167011072, 0.0, 0.72760687510899891, 0.0, 0.0, 0.0, 0.40000000000000002, 0.5303300858899106, 0.0, 0.47140452079103173, 0.5303300858899106, 0.49319696191607187, 0.27735009811261457, 0.0, 0.0, 0.0, 0.43643578047198478, 0.18257418583505536, 0.0, 0.44721359549995793, 0.0, 0.17677669529663687, 0.35921060405354982, 0.28867513459481292, 0.2672612419124244, 0.0, 0.6546536707079772, 0.0, 0.16666666666666666, 0.0, 0.0, 0.28867513459481292, 0.48507125007266594, 0.68599434057003528, 0.17407765595569785, 0.0, 0.2581988897471611, 0.41702882811414954, 0.0, 0.0, 0.0, 0.98058067569092022, 0.73029674334022143, 0.30151134457776363, 0.0, 0.0, 0.21821789023599239, 0.1889822365046136, 0.2672612419124244, 0.0, 0.0, 1.0606601717798212, 0.53452248382484879, 0.0, 0.18569533817705186, 0.68824720161168518, 0.2672612419124244, 0.0, 0.16666666666666666, 0.22360679774997896, 1.044465935734187, 0.20851441405707477, 0.0, 0.0, 0.37139067635410372, 0.0, 0.44721359549995793, 0.0, 0.37139067635410372, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 0.0, 1.386750490563073, 0.0, 0.0, 0.0, 0.64888568452305018, 0.35355339059327373, 0.0, 0.0, 0.13867504905630729, 0.0, 0.0, 0.0, 0.40824829046386307, 0.18569533817705186, 0.0, 0.0, 0.0, 0.16222142113076254, 0.0, 0.68824720161168518, 0.0, 0.0, 1.0327955589886444, 0.0, 0.0, 0.0, 0.20851441405707477, 0.0, 0.21320071635561041, 0.0, 0.0, 0.8703882797784892, 0.0, 0.27735009811261457, 0.0, 0.18569533817705186, 0.0, 0.0, 0.19611613513818404, 0.5388159060803247, 0.88388347648318433, 0.0, 0.50709255283710997, 0.16666666666666666, 0.80000000000000004, 0.0, 0.46291004988627571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22941573387056174, 0.35355339059327373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.76980035891950105, 0.0, 0.58834840541455213, 0.3481553119113957, 0.2672612419124244, 0.34299717028501764, 0.35921060405354982, 0.0, 0.42640143271122083, 0.0, 0.0, 0.0, 0.55708601453115558, 0.41702882811414954, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55708601453115558, 0.19245008972987526, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.94491118252306805, 0.0, 0.0, 0.17407765595569785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5222329678670935, 0.0, 1.044465935734187, 0.0, 0.0, 0.0, 0.5303300858899106, 0.0, 0.0, 0.0, 0.2581988897471611, 0.0, 0.55708601453115558, 0.36514837167011072, 0.0, 0.0, 0.38490017945975052, 0.0, 0.0, 0.22941573387056174, 0.58834840541455213, 0.23570226039551587, 0.63245553203367588, 0.0, 0.16439898730535729, 0.0, 0.0, 0.3779644730092272, 0.76980035891950105, 0.0, 0.44721359549995793, 0.0, 0.0, 0.50709255283710997, 0.0, 0.68824720161168518, 0.2581988897471611, 0.32444284226152509, 0.0, 0.28867513459481292, 0.0, 0.17407765595569785, 0.17960530202677491, 0.0, 0.51449575542752646, 0.21821789023599239, 0.78446454055273618, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.18257418583505536, 0.17407765595569785, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.40824829046386307, 0.0, 0.0, 0.0, 0.34299717028501764, 0.0, 0.60302268915552726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48507125007266594, 0.19245008972987526, 0.20000000000000001, 0.18257418583505536, 0.0, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.30499714066520933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.21821789023599239, 0.39223227027636809, 0.40824829046386307, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.31622776601683794, 0.0, 0.0, 0.24253562503633297, 0.5, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.0, 0.0, 0.0, 0.7745966692414834, 0.31622776601683794, 0.37139067635410372, 0.0, 0.57735026918962584, 0.0, 0.0, 0.0, 0.6546536707079772, 0.0, 0.97014250014533188, 0.29814239699997197, 0.81649658092772615, 0.44721359549995793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68824720161168518, 0.18257418583505536, 0.40824829046386307, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.40824829046386307, 0.19611613513818404, 0.0, 0.0, 0.0, 0.35921060405354982, 0.0, 0.0, 0.28867513459481292, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.40000000000000002, 0.2672612419124244, 0.91766293548224698, 0.94491118252306805, 0.0, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.54772255750516607, 0.0, 0.0, 0.0, 0.48666426339228763, 0.20000000000000001, 0.0, 0.0, 0.24253562503633297, 0.0, 0.0, 0.22360679774997896, 0.2581988897471611, 0.38490017945975052, 0.48507125007266594, 0.5, 0.22941573387056174, 0.0, 0.49319696191607187, 0.22941573387056174, 0.37139067635410372, 0.0, 0.0, 0.21320071635561041, 0.2672612419124244, 0.0, 0.0, 0.0, 0.0, 0.28867513459481292, 0.40000000000000002, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.55470019622522915, 0.40824829046386307, 0.75, 0.0, 0.24253562503633297, 0.45883146774112349, 0.0, 0.19245008972987526, 0.33806170189140661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.53452248382484879, 0.94280904158206347, 0.0, 0.0, 0.24253562503633297, 0.3481553119113957, 0.72760687510899891, 0.45883146774112349, 0.23570226039551587, 0.0, 0.0, 0.0, 0.0, 0.90453403373329089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61237243569579458, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.25, 0.0, 0.3481553119113957, 0.20412414523193154, 0.31622776601683794, 0.80178372573727319, 0.0, 0.0, 0.36514837167011072, 0.0, 0.0, 0.17677669529663687, 0.18257418583505536, 0.50709255283710997, 0.0, 0.0, 0.40000000000000002, 0.0, 0.23570226039551587, 0.57735026918962573, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 1.1666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.73029674334022143, 0.0, 0.39223227027636809, 0.0, 0.80000000000000004, 0.2581988897471611, 1.2374368670764582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.0, 0.0, 0.2581988897471611, 0.17149858514250882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17407765595569785, 0.0, 0.45883146774112349, 0.35921060405354982, 0.2581988897471611, 0.0, 0.20851441405707477, 0.39223227027636809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.23570226039551587, 0.0, 0.54772255750516607, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.0, 0.75, 0.48507125007266594, 0.0, 0.91766293548224698, 0.0, 0.0, 0.24253562503633297, 0.0, 0.83205029433784372, 0.0, 0.30151134457776363, 0.0, 0.0, 0.24253562503633297, 0.0, 0.47140452079103173, 0.0, 0.0, 0.0, 0.19245008972987526, 0.35921060405354982, 0.17677669529663687, 0.60302268915552726, 0.0, 0.78446454055273618, 0.17407765595569785, 0.1690308509457033, 0.0, 0.45883146774112349, 0.61721339984836765, 0.24253562503633297, 0.0, 0.0, 0.0, 0.50709255283710997, 0.0, 0.0, 0.0, 0.0, 0.3481553119113957, 0.0, 0.54772255750516607, 0.72760687510899891, 0.0, 0.30151134457776363, 0.0, 0.0, 0.0, 0.19611613513818404, 0.23570226039551587, 0.0, 0.0, 0.47140452079103173, 0.0, 0.47140452079103173, 0.21821789023599239, 0.37139067635410372, 0.0, 0.0, 0.62469504755442429, 0.0, 0.0, 0.0, 0.0, 0.33333333333333331, 0.18569533817705186, 0.22941573387056174, 0.0, 0.21320071635561041, 0.20851441405707477, 0.0, 0.19245008972987526, 0.0, 0.0, 0.53452248382484879, 0.20000000000000001, 0.0, 0.0, 0.0, 0.68599434057003528, 0.0, 0.0, 0.0, 0.46852128566581819, 0.0, 0.0, 0.17149858514250882, 0.36514837167011072, 0.0, 0.0, 0.38490017945975052, 0.0, 0.42640143271122083, 0.34299717028501764, 0.0, 0.47140452079103173, 0.0, 0.18257418583505536, 0.18569533817705186, 0.23570226039551587, 0.0, 0.0, 0.47140452079103173, 0.38490017945975052, 0.0, 0.0, 0.16439898730535729, 0.0, 0.20412414523193154, 0.0, 0.0, 0.0, 0.89442719099991586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.51449575542752646, 0.43643578047198478, 0.57735026918962584, 1.1180339887498949, 0.74278135270820744, 0.0, 0.0, 0.56694670951384085, 0.0, 0.0, 0.0, 0.32879797461071458, 0.0, 0.0, 0.0, 0.68824720161168518, 0.0, 0.0, 0.57735026918962573, 0.35355339059327373, 0.27735009811261457, 0.0, 0.0, 0.0, 0.0, 0.17149858514250882, 0.0, 0.25, 0.0, 0.43643578047198478, 0.0, 0.72760687510899891, 0.0, 0.0, 0.76980035891950105, 0.36514837167011072, 0.36514837167011072, 0.0, 0.0, 1.2510864843424487, 0.0, 0.80178372573727319, 1.0425720702853738, 0.0, 0.0, 0.43643578047198478, 0.17407765595569785, 0.5, 0.60302268915552726, 0.0, 0.0, 0.17407765595569785, 0.0, 0.1889822365046136, 0.78446454055273618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.5388159060803247, 0.0, 0.20412414523193154, 0.0, 0.5163977794943222, 0.0, 0.0, 0.83405765622829908, 0.0, 0.0, 0.0, 0.22360679774997896, 0.48507125007266594, 0.38490017945975052, 0.63960214906683133, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.60302268915552726, 0.18569533817705186, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.1889822365046136, 0.0, 0.0, 0.80178372573727319, 0.44721359549995793, 0.81649658092772615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17960530202677491, 0.0, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.31234752377721214, 0.0, 0.0, 0.0, 0.0, 0.80178372573727319, 0.0, 0.57735026918962584, 0.0, 0.43643578047198478, 0.0, 0.0, 0.35921060405354982, 0.5163977794943222, 0.28867513459481292, 0.63960214906683133, 0.0, 0.0, 0.24253562503633297, 0.44721359549995793, 0.0, 0.31622776601683794, 0.0, 0.48507125007266594, 0.0, 0.0, 0.40000000000000002, 0.0, 0.22941573387056174, 0.0, 0.97014250014533188, 0.0, 0.19245008972987526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.20412414523193154, 0.20412414523193154, 0.57735026918962584, 0.45883146774112349, 0.18569533817705186, 0.28867513459481292, 0.5222329678670935, 0.0, 0.5388159060803247, 0.0, 0.7745966692414834, 0.0, 0.68824720161168518, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.0, 0.24253562503633297, 0.40000000000000002, 0.0, 0.0, 0.0, 0.19611613513818404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74278135270820744, 0.0, 0.0, 0.0, 0.57735026918962584, 0.0, 0.0, 0.45883146774112349, 0.88465173692938281, 0.0, 1.150792911137501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16439898730535729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33806170189140661, 0.20851441405707477, 0.34299717028501764, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.39223227027636809, 0.48507125007266594, 0.5303300858899106, 0.0, 0.38490017945975052, 0.63960214906683133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.44721359549995793, 0.0, 0.0, 0.0, 0.0, 0.17677669529663687, 0.0, 0.53452248382484879, 0.35921060405354982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.21821789023599239, 0.0, 0.0, 0.0, 0.33806170189140661, 0.98639392383214375, 0.21821789023599239, 0.0, 0.0, 0.0, 0.2581988897471611, 0.0, 0.86602540378443871, 0.33806170189140661, 0.0, 0.38490017945975052, 0.72760687510899891, 0.21821789023599239, 0.53452248382484879, 0.0, 0.0, 0.23570226039551587, 0.0, 0.0, 0.0, 0.0, 0.59999999999999998, 0.0, 0.18257418583505536, 0.31622776601683794, 0.0, 0.0, 0.38490017945975052, 0.0, 0.3481553119113957, 0.0, 0.2581988897471611, 0.1690308509457033, 0.0, 0.0, 0.19245008972987526, 0.0, 0.36514837167011072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61237243569579458, 0.0, 0.0, 0.42640143271122083, 0.0, 0.20000000000000001, 0.22360679774997896, 0.40000000000000002, 0.60302268915552726, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.16012815380508713, 0.48507125007266594, 0.0, 0.0, 0.3481553119113957, 0.0, 0.42640143271122083, 0.0, 0.0, 0.20000000000000001, 0.78446454055273618, 0.0, 0.71842120810709964, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.2672612419124244, 0.63960214906683133, 0.17677669529663687, 0.0, 0.0, 0.0, 0.24253562503633297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.386750490563073, 0.0, 0.75, 0.34299717028501764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5388159060803247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.27735009811261457, 0.19611613513818404, 0.86602540378443871, 0.0, 0.34299717028501764, 0.17407765595569785, 0.0, 0.0, 0.20851441405707477, 0.0, 0.0, 0.48507125007266594, 0.0, 0.54772255750516607, 0.0, 0.0, 0.0, 0.43643578047198478, 0.0, 0.2672612419124244, 0.0, 0.0, 0.70710678118654746, 0.0, 0.97014250014533188, 0.18569533817705186, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.20851441405707477, 0.48507125007266594, 0.0, 0.37139067635410372, 0.0, 0.44721359549995793, 0.0, 0.37139067635410372, 0.0, 0.20851441405707477, 0.0, 0.40824829046386307, 0.23570226039551587, 0.0, 0.0, 0.27735009811261457, 0.39223227027636809, 0.53452248382484879, 0.0, 0.0, 0.0, 0.80178372573727319, 0.42640143271122083, 0.0, 0.40824829046386307, 0.0, 0.0, 0.0, 0.0, 0.40824829046386307, 0.16222142113076254, 0.0, 0.0, 0.0, 0.13867504905630729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20851441405707477, 0.0, 0.21320071635561041, 0.72760687510899891, 0.0, 0.0, 0.5222329678670935, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.18569533817705186, 0.0, 0.0, 0.0, 0.71842120810709964, 0.0, 0.0, 0.0, 0.66666666666666663, 0.20000000000000001, 0.0, 0.61721339984836765, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19245008972987526, 0.28867513459481292, 0.0, 0.30151134457776363, 0.79056941504209477, 0.0, 0.0, 0.0, 0.0, 0.39223227027636809, 0.17407765595569785, 0.0, 0.0, 0.5388159060803247, 0.0, 0.42640143271122083, 0.2672612419124244, 0.0, 0.0, 0.18569533817705186, 0.41702882811414954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.5222329678670935, 0.24253562503633297, 0.27735009811261457, 0.20000000000000001, 0.20412414523193154, 0.0, 0.69631062382279141, 0.0, 0.3481553119113957, 0.0, 0.60302268915552726, 0.0, 0.35355339059327373, 0.0, 0.0, 0.0, 0.2581988897471611, 0.21320071635561041, 0.0, 0.54772255750516607, 0.0, 0.0, 0.38490017945975052, 0.0, 0.0, 0.0, 0.0, 0.47140452079103173, 0.0, 0.39223227027636809, 0.16439898730535729, 0.53452248382484879, 0.5, 0.0, 0.19245008972987526, 0.0, 0.44721359549995793, 0.0, 0.0, 0.50709255283710997, 0.0, 0.0, 0.5163977794943222, 0.16222142113076254, 0.0, 0.0, 0.0, 0.3481553119113957, 0.17960530202677491, 0.2581988897471611, 0.68599434057003528, 0.21821789023599239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70710678118654757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21821789023599239, 0.0, 0.0, 1.0, 0.20412414523193154, 0.89442719099991586, 0.0, 1.4596008983995234, 0.17149858514250882, 0.0, 0.15075567228888181, 0.0, 0.0, 0.22360679774997896, 0.45883146774112349, 0.1690308509457033, 0.24253562503633297, 0.19245008972987526, 0.20000000000000001, 0.18257418583505536, 0.0, 0.0, 0.36514837167011072, 0.0, 0.21320071635561041, 0.2581988897471611, 0.0, 0.0, 0.55470019622522915, 0.0, 0.0, 0.0, 0.48507125007266594, 0.19245008972987526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22941573387056174, 0.0, 0.89442719099991586, 0.31622776601683794, 0.27735009811261457, 0.0, 0.0, 0.0, 0.22941573387056174, 0.40824829046386307, 0.0, 0.0, 0.0, 0.33333333333333331, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45883146774112349, 0.0, 0.25, 0.0, 0.14907119849998599, 0.0, 0.0, 0.58834840541455213, 0.0, 0.0, 0.1889822365046136, 0.48038446141526137, 0.22941573387056174, 0.36514837167011072, 0.20412414523193154, 0.0, 0.19245008972987526, 0.35355339059327373, 0.16439898730535729, 0.41702882811414954, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.71842120810709964, 0.3779644730092272, 0.39223227027636809, 0.0, 0.0, 0.0, 0.21320071635561041, 0.0, 0.67082039324993692, 0.0, 0.0, 0.5, 0.0, 0.40000000000000002, 0.53452248382484879, 0.0, 0.0, 0.28867513459481292, 0.0, 0.0, 0.0, 0.18569533817705186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27735009811261457, 0.0, 0.24253562503633297, 0.85280286542244166, 0.0, 0.0, 0.0, 0.19245008972987526, 0.0, 0.0, 0.22941573387056174, 0.0, 0.0, 0.91766293548224698, 0.0, 0.41702882811414954, 0.33333333333333331, 0.0, 0.0, 0.0, 0.20000000000000001, 0.55470019622522915, 0.0, 0.0, 0.40000000000000002, 0.57735026918962573, 0.0, 0.37139067635410372, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 1.0, 0.18569533817705186, 0.0, 0.0, 0.63245553203367588, 0.38490017945975052, 0.33806170189140661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3779644730092272]\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENTACION primera y segunda persona\n",
    "\n",
    "pattern_tag = re.compile(r'tag=\"(.*?)\"')\n",
    "\n",
    "first_second_person=np.zeros((len(corpus), 2))\n",
    "contador=0\n",
    "\n",
    "tam=len(corpus)\n",
    "\n",
    "for i in np.random.randint(0, tam, 1000):\n",
    "    text = corpus['text'][i]\n",
    "    total_token=0\n",
    "    token_1=0\n",
    "    token_2=0\n",
    "    xml = analyzer.run(text.encode(), 'flush')\n",
    "    for sentence in xml:\n",
    "        for token in sentence:\n",
    "            m = re.search(pattern_tag, etree.tostring(token).decode())\n",
    "            tag=m.group(1)\n",
    "            if (tag[0] == 'V'):\n",
    "                if(tag[4] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[4]=='2'):\n",
    "                    token_2+=1\n",
    "            elif(tag[0] == 'P'):\n",
    "                if(tag[2] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[2]=='2'):\n",
    "                    token_2+=1\n",
    "            elif(tag[0] == 'D'):\n",
    "                if(tag[2] == '1'):\n",
    "                    token_1+=1\n",
    "                elif(tag[2]=='2'):\n",
    "                    token_2+=1\n",
    "            total_token+=1\n",
    "    first_second_person[contador,0]=token_1/math.sqrt(total_token)\n",
    "    first_second_person[contador,1]=token_2/math.sqrt(total_token)    \n",
    "    contador+=1\n",
    "    print (\"Dato numero \",contador, \"Porcentaje \", contador/len(corpus),  end=\"\\r\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "pp=[]   \n",
    "sp=[]\n",
    "cont=0\n",
    "for t in first_second_person:\n",
    "    if(cont<1000):\n",
    "        pp.append(t[0])\n",
    "        sp.append(t[1])    \n",
    "    cont+=1    \n",
    "#first_second_person    \n",
    "print(\"Mediana primera persona \", np.median(pp))\n",
    "print(\"Mediana segunda persona \", np.median(sp))\n",
    "\n",
    "print(\"Media primera persona \", np.mean(pp))\n",
    "print(\"Media segunda persona \", np.mean(sp))\n",
    "\n",
    "print(pp)\n",
    "\n",
    "print(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importacion de librerias utiles\n",
    "\n",
    "#Libreria para analisis de datos \n",
    "#en este proyecto para leer y grabar\n",
    "#archivos en csv\n",
    "import pandas\n",
    "\n",
    "#Librerias cientificas scipy, numpy, matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Librerias de incluidas en python time, math\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Lectura de archivos xml\n",
    "from lxml import etree\n",
    "\n",
    "#Expresiones regulares\n",
    "import re\n",
    "\n",
    "#Pyfreeling\n",
    "from pyfreeling import Analyzer\n",
    "analyzer = Analyzer(config='/usr/share/freeling/config/es.cfg', lang='es')\n",
    "\n",
    "#Para implementar modelos de aprendizajes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar comentarios con menos de tres votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga el corpus de humor\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "id_f = []\n",
    "text_f = []\n",
    "account_id_f=[]\n",
    "nh_f=[]\n",
    "sh1_f=[]\n",
    "sh2_f=[]\n",
    "sh3_f=[]\n",
    "sh4_f=[]\n",
    "sh5_f=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_id=corpus['id'][:]\n",
    "vec_text=corpus['text'][:]\n",
    "vec_account_id=corpus['account_id'][:]\n",
    "vec_no_humor =corpus['n'][:]\n",
    "vec_e1 =corpus['1'][:]\n",
    "vec_e2 =corpus['2'][:]\n",
    "vec_e3 =corpus['3'][:]\n",
    "vec_e4 =corpus['4'][:]\n",
    "vec_e5 =corpus['5'][:]\n",
    "\n",
    "#Para cada tweet se calcula si tiene al menos tres votos, \n",
    "#en caso afirmativo se guarda su informacion, en caso\n",
    "#negativo se descarta el tweet\n",
    "for i in range(len(corpus)):\n",
    "    if vec_no_humor[i] + vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= 3:\n",
    "        id_f.append(vec_id[i])\n",
    "        text_f.append(vec_text[i])\n",
    "        account_id_f.append(vec_account_id[i])\n",
    "        nh_f.append(vec_no_humor[i])\n",
    "        sh1_f.append(vec_e1[i])\n",
    "        sh2_f.append(vec_e2[i])\n",
    "        sh3_f.append(vec_e3[i])\n",
    "        sh4_f.append(vec_e4[i])\n",
    "        sh5_f.append(vec_e5[i])\n",
    "        \n",
    "#El primer filtro aplicado es guardado en el archivo corpus_filtro1.csv\n",
    "d = {'id' : id_f,\n",
    "    'text' : text_f,\n",
    "    'account_id': account_id_f,\n",
    "    'n':nh_f, \n",
    "    '1':sh1_f,\n",
    "    '2':sh2_f,\n",
    "    '3':sh3_f,\n",
    "    '4':sh4_f,\n",
    "    '5':sh5_f\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_f = []\n",
    "\n",
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro1 = pandas.read_csv(\"corpus_filtro1.csv\",encoding='utf-8')\n",
    "\n",
    "#Generacion de patron de Hashtag\n",
    "pattern_hashtag = re.compile(r'#.+?\\b')\n",
    "\n",
    "\n",
    "#Se sustituye el Hashtag por el string vacio, los tweets que\n",
    "#van pasando por este procesamiento se van guardando en el arreglo\n",
    "#text_f\n",
    "for i in range(len(corpus_filtro1)):\n",
    "    text_f.append(re.sub(pattern_hashtag, \"\", corpus_filtro1['text'][i]))\n",
    "#El segundo filtro aplicado es guardado en el archivo corpus_filtro2.csv\n",
    "d = {'id' : corpus_filtro1['id'][:],\n",
    "    'text' : text_f,\n",
    "    'account_id': corpus_filtro1['account_id'][:],\n",
    "    'n':corpus_filtro1['n'][:], \n",
    "    '1':corpus_filtro1['1'][:],\n",
    "    '2':corpus_filtro1['2'][:],\n",
    "    '3':corpus_filtro1['3'][:],\n",
    "    '4':corpus_filtro1['4'][:],\n",
    "    '5':corpus_filtro1['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregar la categoria humor o no humor a los documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El criterio de humor o no humor esta basado en el criterio presentado en la letra del laboratorio, en donde se considerará humorístico si la mitad o más de los anotadores lo calificaron con una o más estrellas y no humorístico en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro2 = pandas.read_csv(\"corpus_filtro2.csv\",encoding='utf-8')\n",
    "\n",
    "#Listas para salvar los tweets filtrados\n",
    "text = []\n",
    "category=[]\n",
    "h1=[]\n",
    "h2=[]\n",
    "h3=[]\n",
    "h4=[]\n",
    "h5=[]\n",
    "\n",
    "#Listas del corpus\n",
    "vec_text=corpus_filtro2['text'][:]\n",
    "vec_no_humor =corpus_filtro2['n'][:]\n",
    "vec_e1 =corpus_filtro2['1'][:]\n",
    "vec_e2 =corpus_filtro2['2'][:]\n",
    "vec_e3 =corpus_filtro2['3'][:]\n",
    "vec_e4 =corpus_filtro2['4'][:]\n",
    "vec_e5 =corpus_filtro2['5'][:]\n",
    "\n",
    "#Si hay igual o mas votos de humor que de no humor la categoria tiene el valor 1\n",
    "#en caso contrario tiene el valor 0\n",
    "for i in range(len(corpus_filtro2)):\n",
    "    if  vec_e1[i] + vec_e2[i] + vec_e3[i] + vec_e4[i] + vec_e5[i] >= vec_no_humor[i]:\n",
    "        category.append(1)\n",
    "    else:\n",
    "        category.append(0)\n",
    "    text.append(vec_text[i])\n",
    "    h1.append(vec_e1[i])\n",
    "    h2.append(vec_e2[i])\n",
    "    h3.append(vec_e3[i])\n",
    "    h4.append(vec_e4[i])\n",
    "    h5.append(vec_e5[i])\n",
    "#El tercer procesamiento aplicado sobre los tweets es guardado en el archivo corpus_filtro.3\n",
    "d = {'text' : text,\n",
    "    'category': category,\n",
    "     '1':h1,\n",
    "     '2':h2,\n",
    "     '3':h3,\n",
    "     '4':h4,\n",
    "     '5':h5\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category','1','2','3','4','5'])\n",
    "df.to_csv('corpus_filtro3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar información de POS-tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia de tweets salvada en el bloque de codigo anterior\n",
    "corpus_filtro3 = pandas.read_csv(\"corpus_filtro3.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro3['text'][:]\n",
    "\n",
    "#Se genera el patron para identificar las POS de las palabras\n",
    "pattern_pos = re.compile(r'pos=\"(.*?)\"')\n",
    "\n",
    "#Variables para datos estadisticos\n",
    "num_sentences=len(corpus_filtro3)\n",
    "numsentence=1\n",
    "\n",
    "#Variable auxiliar para adherir las POS a los tweets\n",
    "pos=0\n",
    "\n",
    "#Para cada documento en el corpus de tweets que va siendo procesado\n",
    "#utilizando la herramienta freeling se analizan las categorias gramaticales\n",
    "#de todas las palabras que aparecen en cada tweet y esta informacion es\n",
    "#adherida al texto del tweet\n",
    "for d in text_list:\n",
    "    if(type(d) == str):\n",
    "        xml = analyzer.run(d.encode(), 'flush')\n",
    "        print(numsentence, \" \", math.floor( numsentence/num_sentences*100),\"%\", end=\"\\r\")\n",
    "        for sentence in xml:        \n",
    "            for token in sentence:\n",
    "                token_byte=etree.tostring(token)\n",
    "                m = re.search(pattern_pos, token_byte.decode())\n",
    "                if m is not None:\n",
    "                    text_list[ pos] = text_list[pos] + \" \" + m.group(1)\n",
    "    pos+=1\n",
    "    numsentence+=1\n",
    "\n",
    "#El procesamiento actual del corpus es guardado en el documento corpus_filtro4.csv\n",
    "d = {'text' : text_list,\n",
    "    'category': corpus_filtro3['category'][:],\n",
    "     '1':corpus_filtro3['1'][:],\n",
    "     '2':corpus_filtro3['2'][:],\n",
    "     '3':corpus_filtro3['3'][:],\n",
    "     '4':corpus_filtro3['4'][:],\n",
    "     '5':corpus_filtro3['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', '1','2','3','4','5'])\n",
    "df.to_csv('corpus_filtro4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de datos de entrenamiento y de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro4.csv\",encoding='utf-8')\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4)*20/100)\n",
    "#Se generan posiciones en el arreglo tweets al azar que representen el 20% del corpus actual\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4['text'][:]\n",
    "vec_category=corpus_filtro4['category'][:]\n",
    "\n",
    "#Se separa el 20% de corpus para desarrollo del 80% para entrenamiento\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "\n",
    "#Se guardan las instancias corpus de desarrollo en corpus_filtro5_devset.csv\n",
    "#y corpus de entrenamiento en corpus_filtro5_trainingset.csv\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset.csv')\n",
    "\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de mediana, para segundo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se carga la instancia salvada del corpus que se encuentra en el archivo\n",
    "#corpus_filtro4.csv\n",
    "corpus_filtro4 = pandas.read_csv(\"corpus_filtro4.csv\",encoding='utf-8')\n",
    "\n",
    "text_list=corpus_filtro4['text'][:]\n",
    "category_list=corpus_filtro4['category'][:]\n",
    "\n",
    "h1_list=corpus_filtro4['1'][:]\n",
    "h2_list=corpus_filtro4['2'][:]\n",
    "h3_list=corpus_filtro4['3'][:]\n",
    "h4_list=corpus_filtro4['4'][:]\n",
    "h5_list=corpus_filtro4['5'][:]\n",
    "\n",
    "medians=[]\n",
    "pos=0\n",
    "\n",
    "#Caclulo de la mediana, en values se expanden los votos de cada estrella\n",
    "#de la siguiente manera si #cant_3Estrellas_en_tweet = 4, entonces se guardan\n",
    "#en values 4 treses 3,3,3,3 para permitir el calculo de la mediana\n",
    "#Por ultimo en la estructura medians se guarda el valor discreto (0,1,2,3,4 o 5) de la mediana\n",
    "#si la cantidad de votos es par se toma el voto del medio con valor mas grande\n",
    "for i in range( len(corpus_filtro4)):\n",
    "    values = []\n",
    "    for j in range( h1_list[i]):\n",
    "        values.append(1)\n",
    "    for j in range( h2_list[i] ):\n",
    "        values.append(2)\n",
    "    for j in range( h3_list[i] ):\n",
    "        values.append(3)\n",
    "    for j in range( h4_list[i] ):\n",
    "        values.append(4)\n",
    "    for j in range( h5_list[i] ):\n",
    "        values.append(5)\n",
    "    if len(values) == 0:\n",
    "        values.append(0)  \n",
    "    mediana=np.median(values)\n",
    "    if( len(values) % 2 == 1 ):\n",
    "        medians.append(math.floor(mediana))\n",
    "    else:\n",
    "        for i in values:\n",
    "            if( i >= mediana):\n",
    "                medians.append(i)\n",
    "                break\n",
    "    pos+=1\n",
    "\n",
    "#El nuevo procesamiento que suma la informacion de la mediana se guarda\n",
    "#en el archivo corpus_filtro4median.csv\n",
    "d = {'text' : corpus_filtro4['text'][:],\n",
    "    'category' : corpus_filtro4['category'][:],\n",
    "    'median': medians,\n",
    "    '1':corpus_filtro4['1'][:],\n",
    "    '2':corpus_filtro4['2'][:],\n",
    "    '3':corpus_filtro4['3'][:],\n",
    "    '4':corpus_filtro4['4'][:],\n",
    "    '5':corpus_filtro4['5'][:]\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category', 'median', '1', '2', '3', '4', '5'])\n",
    "df.to_csv('corpus_filtro4median.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos de entrenamiento y desarrollo, para segundo clasificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#Se carga la instancia salvada en el bloque de codigo anterior\n",
    "corpus_filtro4median = pandas.read_csv(\"corpus_filtro4median.csv\",encoding='utf-8')\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4median)*20/100)\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4median) - 1, size=num_dev_tweets)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "median_train=[]\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "median_dev=[]\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4median['text'][:]\n",
    "vec_median=corpus_filtro4median['median'][:]\n",
    "vec_category=corpus_filtro4median['category'][:]\n",
    "\n",
    "\n",
    "for i in range( len(corpus_filtro4median)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        median_dev.append(vec_median[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "        \n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        median_train.append(vec_median[i])\n",
    "        category_train.append(vec_category[i])\n",
    "\n",
    "d = {'text' : text_train,\n",
    "     'median' : median_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'median','category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_c2.csv')\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "     'median': median_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'median', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_c2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento, clasificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4median = pandas.read_csv(\"corpus_filtro4median.csv\",encoding='utf-8')\n",
    "text_list=corpus_filtro4median['text'][:]\n",
    "category_list=[]\n",
    "median_list=corpus_filtro4median['median'][:]\n",
    "h1_list=corpus_filtro4median['1'][:]\n",
    "h2_list=corpus_filtro4median['2'][:]\n",
    "h3_list=corpus_filtro4median['3'][:]\n",
    "h4_list=corpus_filtro4median['4'][:]\n",
    "h5_list=corpus_filtro4median['5'][:]\n",
    "pos=0\n",
    "for m in median_list:\n",
    "    if(m<1):\n",
    "        category_list.append(0)\n",
    "    else:\n",
    "        category_list.append(1)\n",
    "    pos+=1\n",
    "d = {'text' : text_list,\n",
    "    'category': category_list,\n",
    "     'median': median_list\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text','category','median'])\n",
    "df.to_csv('corpus_filtro4median_category.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación datos de entrenamiento y desarrollo, clasificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_filtro4median_category = pandas.read_csv(\"corpus_filtro4median_category.csv\",encoding='utf-8')\n",
    "text=corpus_filtro4median_category['text'][:]\n",
    "category=corpus_filtro4median_category['category'][:]\n",
    "median=corpus_filtro4median_category['median'][:]\n",
    "\n",
    "num_dev_tweets=math.floor(len(corpus_filtro4median_category)*20/100)\n",
    "random_samples=np.random.randint(0, len(corpus_filtro4median_category) - 1, size=num_dev_tweets)\n",
    "\n",
    "print(num_dev_tweets)\n",
    "print(random_samples)\n",
    "\n",
    "#Listas para entrenamiento\n",
    "text_train = []\n",
    "category_train=[]\n",
    "\n",
    "#Listas para desarrollo\n",
    "text_dev = []\n",
    "category_dev=[]\n",
    "\n",
    "#Listas con datos del corpus\n",
    "vec_text=corpus_filtro4median_category['text'][:]\n",
    "vec_category=corpus_filtro4median_category['category'][:]\n",
    "\n",
    "for i in range( len(corpus_filtro4median_category)):\n",
    "    if(np.any(random_samples[:] == i)):\n",
    "        text_dev.append(vec_text[i])\n",
    "        category_dev.append(vec_category[i])\n",
    "    else:\n",
    "        text_train.append(vec_text[i])\n",
    "        category_train.append(vec_category[i])\n",
    "d = {'text' : text_train,\n",
    "    'category': category_train\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_trainingset_c3.csv')\n",
    "\n",
    "d = {'text' : text_dev,\n",
    "    'category': category_dev\n",
    "    }\n",
    "df = pandas.DataFrame(d, columns = ['text', 'category'])\n",
    "df.to_csv('corpus_filtro5_devset_c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "class Clasificador1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_1_train()\n",
    "    \n",
    "    def __clasiffier_1_train(self):\n",
    "        corpus_filtro5_trainingset = pandas.read_csv(\"corpus_filtro5_trainingset.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5_trainingset['text'][:]\n",
    "        category_list=corpus_filtro5_trainingset['category'][:]\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.train_features = self.vectorizer.fit_transform(text_list)\n",
    "\n",
    "        self.nb_1 = MultinomialNB()\n",
    "        self.nb_1.fit(self.train_features , category_list)\n",
    "    def predict_clasiffier_1(self, path):       \n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text'][:]\n",
    "        category_devlist=corpus_filtro5_devset['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features = self.vectorizer.transform(text_devlist)\n",
    "        return self.nb_1.predict(self.test_features)\n",
    "\n",
    "class Clasificador2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_2_train()\n",
    "        self.__median_predictor_train()\n",
    "\n",
    "    \n",
    "    def __median_predictor_train(self):\n",
    "        corpus_filtro5 = pandas.read_csv(\"corpus_filtro5_trainingset_c2.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5['text'][:]\n",
    "        median_list=corpus_filtro5['median'][:]\n",
    "        self.category_list_c1=[]\n",
    "\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.train_features_c1 = vectorizer.fit_transform(text_list)\n",
    "\n",
    "        for i in median_list:\n",
    "            if(i == 1):\n",
    "                self.category_list_c1.append(1)\n",
    "            else:\n",
    "                self.category_list_c1.append(0)\n",
    "        \n",
    "        self.nb_median1 = MultinomialNB()\n",
    "        self.nb_median1.fit(self.train_features_c1 , self.category_list_c1[:])\n",
    "\n",
    "        self.category_list_c2=[]\n",
    "        for i in median_list:\n",
    "            if(i == 2):\n",
    "                self.category_list_c2.append(1)\n",
    "            else:\n",
    "                self.category_list_c2.append(0)\n",
    "        self.nb_median2 = MultinomialNB()\n",
    "        self.nb_median2.fit(self.train_features_c1 , self.category_list_c2)\n",
    "\n",
    "        self.category_list_c3=[]\n",
    "        for i in median_list:\n",
    "            if(i == 3):\n",
    "                self.category_list_c3.append(1)\n",
    "            else:\n",
    "                self.category_list_c3.append(0)\n",
    "\n",
    "        self.nb_median3 = MultinomialNB()\n",
    "        self.nb_median3.fit(self.train_features_c1 , self.category_list_c3)       \n",
    "\n",
    "        self.category_list_c4=[]\n",
    "        for i in median_list:\n",
    "            if(i == 4):\n",
    "                self.category_list_c4.append(1)\n",
    "            else:\n",
    "                self.category_list_c4.append(0)\n",
    "\n",
    "        self.nb_median4 = MultinomialNB()\n",
    "        self.nb_median4.fit(self.train_features_c1 , self.category_list_c4[:])\n",
    "        \n",
    "        self.category_list_c5=[]\n",
    "        for i in median_list:\n",
    "            if(i == 5):\n",
    "                self.category_list_c5.append(1)\n",
    "            else:\n",
    "                self.category_list_c5.append(0)\n",
    "        self.nb_median5 = MultinomialNB()\n",
    "        self.nb_median5.fit(self.train_features_c1 , self.category_list_c5)\n",
    "\n",
    "        self.category_list_c0=[]\n",
    "        for i in median_list:\n",
    "            if(i == 0):\n",
    "                self.category_list_c0.append(1)\n",
    "            else:\n",
    "                self.category_list_c0.append(0)\n",
    "                \n",
    "        self.nb_median0 = MultinomialNB()\n",
    "        self.nb_median0.fit(self.train_features_c1 , self.category_list_c0)\n",
    "        \n",
    "    def __predict_median1_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c1=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 1:\n",
    "                self.median_list_c1.append(1)\n",
    "            else:\n",
    "                self.median_list_c1.append(0)\n",
    "            \n",
    "\n",
    "        self.test_features_c1 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median1.predict_proba(self.test_features_c1), self.nb_median1.predict(self.test_features_c1)\n",
    "    def __predict_median2_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        \n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c2=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 2:\n",
    "                self.median_list_c2.append(1)\n",
    "            else:\n",
    "                self.median_list_c2.append(0)\n",
    "\n",
    "        \n",
    "        self.test_features_c2 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median2.predict_proba(self.test_features_c2), self.nb_median2.predict(self.test_features_c2)\n",
    "    def __predict_median3_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "\n",
    "        self.median_list_c3=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 3:\n",
    "                self.median_list_c3.append(1)\n",
    "            else:\n",
    "                self.median_list_c3.append(0)\n",
    "\n",
    "        self.test_features_c3 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median3.predict_proba(self.test_features_c3), self.nb_median3.predict(self.test_features_c3)\n",
    "    def __predict_median4_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c4=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 4:\n",
    "                self.median_list_c4.append(1)\n",
    "            else:\n",
    "                self.median_list_c4.append(0)\n",
    "\n",
    "        self.test_features_c4 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median4.predict_proba(self.test_features_c4), self.nb_median4.predict(self.test_features_c4)\n",
    "    def __predict_median5_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c5=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 5:\n",
    "                self.median_list_c5.append(1)\n",
    "            else:\n",
    "                self.median_list_c5.append(0)\n",
    "\n",
    "        self.test_features_c5 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median5.predict_proba(self.test_features_c5), self.nb_median5.predict(self.test_features_c5)\n",
    "    def __predict_median0_c2(self, path):\n",
    "        corpus_filtro5_devset = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset['text']\n",
    "        median_devlist=corpus_filtro5_devset['median']\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.median_list_c0=[]\n",
    "        for med in median_devlist:\n",
    "            if med == 0:\n",
    "                self.median_list_c0.append(1)\n",
    "            else:\n",
    "                self.median_list_c0.append(0)\n",
    "\n",
    "        self.test_features_c0 = vectorizer.transform(text_devlist)\n",
    "        return self.nb_median0.predict_proba(self.test_features_c0), self.nb_median0.predict(self.test_features_c0)\n",
    "    def __clasiffier_2_train(self):\n",
    "        corpus_filtro5_trainingset_c2 = pandas.read_csv(\"corpus_filtro5_trainingset_c2.csv\",encoding='utf-8')\n",
    "        text_list_c2=corpus_filtro5_trainingset_c2['text'][:]\n",
    "        category_list_c2=corpus_filtro5_trainingset_c2['category'][:]\n",
    "        pos_c2=0\n",
    "        for t in text_list_c2:\n",
    "            if type(t) != str:\n",
    "                text_list_c2[pos_c2]=\"NaN\"\n",
    "            pos_c2+=1\n",
    "        self.train_features_class2 = self.vectorizer.fit_transform(text_list_c2)\n",
    "\n",
    "        self.nb_2 = MultinomialNB()\n",
    "        self.nb_2.fit(self.train_features_class2, category_list_c2)\n",
    "\n",
    "    \n",
    "    def predict_median(self, path):\n",
    "        self.c1_pred, self.c1_predict=self.__predict_median1_c2(path)\n",
    "        self.c2_pred, self.c2_predict=self.__predict_median2_c2(path)\n",
    "        self.c3_pred, self.c3_predict=self.__predict_median3_c2(path)\n",
    "        self.c4_pred, self.c4_predict=self.__predict_median4_c2(path)\n",
    "        self.c5_pred, self.c5_predict=self.__predict_median5_c2(path)\n",
    "        self.c0_pred, self.c0_predict=self.__predict_median0_c2(path)        \n",
    "        predicts=[]\n",
    "        proba=[]\n",
    "        for i in range( len(self.c1_pred) ):\n",
    "            maximum=np.max([self.c1_pred[i][1],self.c2_pred[i][1],self.c3_pred[i][1],self.c4_pred[i][1],self.c5_pred[i][1],self.c0_pred[i][1]])\n",
    "            if(maximum == self.c1_pred[i][1]):\n",
    "                predicts.append(1)\n",
    "            elif(maximum == self.c2_pred[i][1]):\n",
    "                predicts.append(2)\n",
    "            elif(maximum == self.c3_pred[i][1]):\n",
    "                predicts.append(3)\n",
    "            elif(maximum == self.c4_pred[i][1]):\n",
    "                predicts.append(4)\n",
    "            elif(maximum == self.c5_pred[i][1]):\n",
    "                predicts.append(5)\n",
    "            elif(maximum == self.c0_pred[i][1]):\n",
    "                predicts.append(0)\n",
    "            proba.append(maximum)\n",
    "        corpus_filtro5_devset_c2 = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist_c2=corpus_filtro5_devset_c2['text'][:]\n",
    "        category_devlist_c2=corpus_filtro5_devset_c2['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist_c2:\n",
    "            if type(t) != str:\n",
    "                text_devlist_c2[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features_class2 = self.vectorizer.transform(text_devlist_c2)\n",
    "                    \n",
    "        return predicts, proba, self.nb_2.predict(self.test_features_class2)\n",
    "\n",
    "class Clasificador3:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english')\n",
    "        self.__clasiffier_3_train()\n",
    "    def __clasiffier_3_train(self):\n",
    "        corpus_filtro5_trainingset_c3 = pandas.read_csv(\"corpus_filtro5_trainingset_c3.csv\",encoding='utf-8')\n",
    "        text_list=corpus_filtro5_trainingset_c3['text'][:]\n",
    "        category_list=corpus_filtro5_trainingset_c3['category'][:]\n",
    "        pos=0\n",
    "        for t in text_list:\n",
    "            if type(t) != str:\n",
    "                text_list[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.train_features = self.vectorizer.fit_transform(text_list)\n",
    "        self.nb = MultinomialNB()\n",
    "        self.nb.fit(self.train_features , category_list)\n",
    "    def predict_clasiffier_1(self, path):\n",
    "        corpus_filtro5_devset_c3 = pandas.read_csv(path,encoding='utf-8')\n",
    "        text_devlist=corpus_filtro5_devset_c3['text'][:]\n",
    "        category_devlist=corpus_filtro5_devset_c3['category'][:]\n",
    "        pos=0\n",
    "        for t in text_devlist:\n",
    "            if type(t) != str:\n",
    "                text_devlist[pos]=\"NaN\"\n",
    "            pos+=1\n",
    "        self.test_features = self.vectorizer.transform(text_devlist)\n",
    "        return self.nb.predict(self.test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1\n",
      " 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1\n",
      " 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1\n",
      " 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador1()\n",
    "print(clasificador.predict_clasiffier_1(\"corpus_filtro5_devset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 3, 0, 0, 4, 3, 0, 0, 3, 3, 3, 0, 4, 3, 3, 3, 0, 3, 0, 3, 4, 2, 3, 3, 3, 4, 3, 4, 3, 3, 3, 0, 0, 0, 3, 0, 3, 2, 0, 0, 3, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 4, 4, 0, 3, 4, 4, 4, 4, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 4, 3, 4, 3, 3, 3, 3, 4, 0, 3, 4, 0, 0, 3, 3, 4, 0, 3, 2, 0, 0, 3, 0, 4, 3, 2, 0, 3, 3, 3, 5, 0, 4, 3, 3, 3, 0, 3, 3, 3, 0, 0, 4, 3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 4, 3, 3, 2, 4, 0, 4, 3, 2, 0, 3, 3, 3, 4, 3, 0, 3, 3, 0, 0, 0, 3, 3, 4, 3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 4, 4, 0, 3, 0, 0, 2, 3, 3, 3, 2, 3, 0, 0, 3, 3, 3, 2, 0, 3, 3, 3, 4, 4, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 4, 3, 3, 4, 0, 0, 4, 3, 3, 4, 0, 0, 4, 3, 3, 0, 3, 4, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 2, 0, 0, 3, 0, 3, 3, 0, 4, 3, 0, 3, 3, 3, 4, 4, 3, 3, 3, 3, 0, 3, 3, 3, 0, 4, 3, 3, 3, 3, 3, 4, 2, 4, 0, 0, 3, 0, 3, 3, 0, 3, 3, 4, 3, 3, 0, 4, 0, 3, 4, 0, 3, 3, 3, 2, 0, 2, 3, 3, 4, 0, 3, 3, 0, 0, 4, 3, 0, 3, 0, 3, 3, 0, 0, 3, 4, 2, 4, 3, 0, 3, 3, 3, 0, 4, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 4, 0, 3, 3, 3, 3, 0, 3, 0, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 4, 0, 3, 3, 3, 2, 0, 4, 3, 3, 0, 3, 3, 4, 3, 3, 3, 0, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 4, 3, 2, 3, 0, 0, 2, 0, 3, 3, 3, 2, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3, 4, 0, 4, 3, 3, 4, 4, 3, 3, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 4, 4, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 4, 3, 3, 3, 4, 4, 4, 3, 0, 0, 0, 0, 4, 4, 4, 3, 0, 4, 3, 3, 0, 4, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 4, 3, 4, 3, 5, 3, 2, 3, 2, 0, 3, 0, 0, 3, 0, 2, 3, 3, 3, 0, 4, 0, 0, 3, 4, 0, 3, 3, 0, 3, 0, 2, 0, 2, 0, 3, 3, 2, 3, 4, 4, 0, 4, 4, 3, 3, 3, 3, 3, 2, 3, 0, 0, 0, 0, 0, 4, 3, 3, 0, 3, 3, 4, 3, 3, 4, 1, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 4, 3, 3, 0, 0, 4, 3, 0, 0, 4, 4, 0, 2, 3, 3, 3, 0, 4, 3, 3, 3, 3, 0, 0, 3, 0, 0, 4, 0] \n",
      " [0.0015638012047151739, 0.47464306506740256, 0.020327327098329347, 0.00021253613072010381, 0.0023744859912325504, 0.021868232990965217, 0.0111639325962319, 0.30567791806395322, 0.19144938311683043, 0.10570040330607518, 0.010359413447975202, 0.052374849257947984, 0.16456974564294308, 0.10620453629716112, 0.026774518195275564, 0.026697429085100956, 0.028027994792486643, 0.0055122502447145626, 0.0010737327753021968, 0.00038077628940280368, 0.0033148763560547634, 0.17459315256369076, 0.01353267271723216, 0.61554455473226477, 0.00016550459247238739, 0.0028726005834890955, 0.0037371366750477818, 0.0094529481890847384, 0.034702125353742154, 0.037437906643820622, 0.0016366885340906073, 0.83391781896777961, 0.65170064146559092, 0.02573055513118119, 0.030643867093204359, 0.086860709881497716, 0.040199507961836023, 0.19557467263070211, 0.0089506745960339119, 0.0047770118449379255, 0.013537437782335215, 0.8523630004624444, 0.044928246802220878, 0.0055810445135917475, 1.914886896366577e-05, 0.061615042811669289, 0.052615830336065733, 0.46314699786681612, 0.77249783626003465, 0.020867966431162097, 0.010101160408656787, 0.18102641412952411, 0.97936146628149434, 0.21105004297421934, 0.0049501734709863441, 0.017374691465165862, 0.049497814377301219, 0.0047738994388141177, 0.15913465492645992, 0.0077110669586858919, 0.92869674533729796, 0.50164460095194618, 0.75116208914488769, 0.67401155011974456, 0.20005904030405119, 0.016638198522603037, 0.011909380796578311, 0.47268298081672111, 0.94348951186586028, 0.20395773653505056, 0.0025571567531608654, 0.037739534553421598, 0.016882305897082329, 0.033080000245003384, 0.0045004449500671961, 0.014380125668008364, 0.020080541020398725, 0.0032932470795165067, 0.028972366430246008, 0.023709798911686026, 0.6951360094607173, 0.0032701903843585832, 0.00045612970762784938, 0.089695627732764974, 0.90464639112978829, 0.027364395468570179, 0.10894304661003101, 0.0016844756049875992, 0.082668400371899292, 0.0020886343739964395, 0.087679249599971018, 0.040472409260432482, 0.00046175512901588516, 0.19252635506196616, 0.045550514934187367, 0.066093264979726618, 0.14527083781535119, 0.0012136391634685463, 0.0061895163656636009, 0.0092727510158922503, 0.00013113262025855711, 0.93878015844783125, 0.47859029516118984, 0.087904583337585315, 0.00094312302065508022, 0.021259470402957385, 0.0083527596324654632, 0.048764155243621821, 0.0069292121310532201, 0.015933088709493927, 0.23441606950512764, 0.039013285276506014, 0.0021473541847263052, 0.095062671668348697, 0.13766447023256412, 0.054601814127917654, 0.5281099327591473, 0.01110610018622187, 0.0096248903067773558, 0.0061487566529155385, 0.010735052908772901, 0.20287322863230897, 0.90302978404628131, 0.038003889777812903, 0.035943559465004139, 0.07420990244368604, 0.10490459165350866, 0.034363493527133374, 0.91922313002270151, 0.030754406239055124, 0.072808773094345094, 0.00074857705115896058, 0.021518939320826515, 0.42984128243313635, 0.095629634042744049, 0.15701661220350507, 0.60701451430601738, 0.0024219024969855825, 0.22069858119137942, 0.041284148241632602, 0.016736662681032594, 0.0019262802118852154, 0.016708874484718337, 0.0064030510168304952, 0.18130477093962963, 0.00082365765342902984, 0.45673547753572658, 0.043472385275503012, 0.0096248903067773558, 0.53166668760453839, 0.023262527214636359, 0.13568365071222036, 0.6260091941309911, 0.17748138589320922, 0.036123147428988034, 0.056204385292262113, 0.31302789752477916, 0.004918428488918678, 0.72892120957007556, 0.010533873596817829, 0.08496909222385797, 0.2413423587391702, 0.004382959097698467, 0.014563426363815319, 0.020007629058036488, 0.027708679998834852, 0.037818893100866502, 0.023958518493332609, 0.089746901713039562, 0.0043891540378871042, 0.30498977178408115, 0.00023751166667965285, 0.18303510751196359, 0.50646240134144183, 0.031831080267690458, 0.88763885860119995, 0.00065527170588382472, 0.01719403370420242, 0.23320677278624838, 0.0088014998859395257, 0.0015049569159634691, 0.19768025266551997, 0.095664683308451556, 0.0083888352451125109, 0.026190750547796803, 0.038241606474726679, 0.012622134320636856, 0.064480077923957754, 0.39901423048642165, 0.29507307216224182, 0.0033440406864698076, 0.28488634904364035, 0.043799195156803028, 0.0007155214119043728, 0.0011172407917616062, 0.030383997742899044, 0.75775446476705177, 0.0014534632200864483, 0.12845478289167378, 0.17182503848001737, 0.00016557485233709748, 0.66617928053022468, 0.082669448836368259, 0.0018142282264323032, 0.0004474624580155622, 0.5124256788023458, 0.0066925438004459296, 0.029239096153381425, 0.10899079027408695, 0.25707994868710543, 0.02260901335390229, 0.00982630507509814, 0.0057441660759501786, 0.0071456260389141006, 0.92885149878753837, 0.12039991696463812, 0.048533412674995613, 0.024405188956325045, 0.49524513294197037, 0.079413761072103878, 0.00096246649804085621, 0.0040349389990285856, 0.17430499521477977, 0.090447076621268857, 0.018844340440583151, 0.048455648539976588, 0.005680254593322772, 0.025990859399585734, 0.091084959520859085, 0.77981731434758761, 0.0045788971149805565, 0.017602194469402404, 0.00024028014493703028, 0.58074294224322631, 0.031434349822631512, 0.022578393570901953, 0.024590257746072711, 0.13280410529470313, 0.00042990748661891621, 0.0094196672825106811, 0.10317686371351413, 0.22629140203062892, 0.17450243913891261, 0.10418369658715816, 0.45665261574728061, 0.092654767484197875, 0.20134384995807461, 0.0024023990000156983, 0.0017520314821409448, 0.0062476811909749474, 0.00057664941380495313, 0.21143898800315683, 0.19816072344838936, 0.027473887064632635, 0.010756764422838894, 0.0073400273308593753, 0.10894207508992165, 0.078442832151721459, 0.58491413745623488, 0.30833463254180488, 0.003047653221574206, 0.043670927153342677, 0.98157038568811428, 0.0016780976387713495, 0.068916971846744224, 0.81523384234056118, 0.16482410691445493, 0.19362711779491748, 0.21201681245868953, 0.058135348822814355, 0.18633397777959151, 0.0087568769651468412, 0.02377838611081352, 0.17777375867921488, 0.46932690808239796, 0.012517575020067702, 0.075360852674800902, 0.15105630596609515, 0.02422741893970496, 0.73609747175123486, 0.029986822436301821, 0.21496099477001349, 0.024884268915862803, 0.69578375376253021, 0.020586798427116134, 0.15770035544617819, 0.0038715439949738081, 0.1106762573320976, 0.060057316591705046, 0.05181593192459806, 0.032383503097307371, 0.16228624635704292, 0.13668147349984427, 0.95808422374339475, 0.16702474816766538, 0.015665462892525951, 0.0026716474186074739, 0.97757915109952331, 0.99999984427118493, 0.25633289160462236, 0.0043614771393146101, 0.33307377542382305, 0.020438787081350874, 0.16377833520223831, 0.39906042009450593, 0.00096959454514915298, 0.59720377879936914, 0.0043357421809101133, 0.0016210255851945791, 0.00052499033541012787, 0.0079799439015511009, 0.066267050371620617, 0.16938287038373975, 0.0077798553084711987, 0.080576217662119087, 0.27072304197114661, 0.008435000352039819, 0.032177354885865553, 0.31278536435214338, 0.10157537185068204, 0.0092200417752958709, 0.034922310123493221, 0.0052869024534197779, 0.12585269627158843, 0.0032787226271257641, 0.00085114568508990547, 0.14821890570037513, 0.047502786163898601, 0.071960177723488047, 0.98899174930464628, 0.1054702132111618, 4.3884946192636668e-05, 0.90243383224610874, 0.31087395283209879, 0.099666791831481055, 0.41931910649164256, 0.01254520441015043, 0.18028610332237743, 0.012495046900144432, 0.03131815547112908, 0.0067404295591159133, 0.018924376810360504, 0.0098539872623018727, 0.1060369898962269, 0.79391823761260083, 0.25165928650678276, 0.012897001349979556, 0.00053480629357305668, 0.056569005836832956, 0.0020932417995706714, 2.0565581261625279e-05, 0.23152333958798677, 0.72908653721240069, 0.021919773428336901, 0.035966522153624454, 0.0066414198929316088, 0.072120852975992605, 0.016136649905227937, 0.3129270895309138, 0.0024703172620633121, 0.023792413555440813, 0.48865930773005101, 0.11250909944294815, 0.11043835456455167, 0.24184159381609857, 0.0041516042982156472, 0.012727104904643518, 0.17937552700217554, 0.00065084950031970722, 0.10130013772145176, 0.1971493300447768, 0.14361776110357999, 0.074599643603202356, 0.35233275793514091, 0.067762438078400503, 0.92301581711761793, 0.10876407811915645, 0.52766659628566115, 0.025448967444494801, 0.0607856138316476, 0.016655171598222312, 0.04996087403192577, 0.0014759852774419021, 0.085168048082570572, 0.044492572557574425, 0.0022968966285649758, 0.048269690467225602, 0.0082391947318903869, 0.003854192059159722, 0.13245497075418367, 0.41840425775303447, 0.89311735476174992, 0.43300262990075361, 0.017260901555624552, 0.018424767642547486, 0.22764618212692947, 0.012385592857454202, 0.96148241975144744, 0.99645504438428911, 0.18217868697064818, 0.4256374322189086, 0.0095525923633022949, 4.9408544031034867e-05, 0.041060305574053838, 0.259230843135691, 0.034768291945965514, 0.089905322956322059, 0.027513924554895465, 0.92033999025672419, 0.011413038324617375, 0.0098966697974354634, 0.0079579479130645232, 0.00075559384150500548, 0.0057346635380623543, 0.50692221223666567, 0.014996057852883552, 0.11169799537388159, 0.0024774926293089608, 0.026441434162664739, 0.67621027314709381, 0.020784841722867153, 0.0028893614852212022, 0.020583034036171871, 0.87707971124948092, 0.0021404408260706181, 0.039464343256425422, 0.011273387769472717, 0.3450993938072226, 0.013412417207062332, 0.99119492100002249, 0.021242859731838811, 0.80660849889424147, 0.12141076149040704, 0.029554839222624581, 0.0023273570438562489, 0.051440634127138, 0.008041103193056353, 0.99999244719764269, 0.026979118107498035, 0.026943517601861693, 0.020427802797627851, 0.045043743955217805, 0.10519535942506447, 0.079729479700734518, 0.22484761050621327, 0.010346082109920701, 0.9981690832056348, 0.10015976467710175, 0.032131795432066096, 0.022495862310471567, 0.033500034401756869, 0.010268538963566963, 0.03969731612630957, 0.0024039234146055479, 0.05001938777501283, 0.59471642823454141, 0.016272078427295059, 0.0064433138913899349, 0.013143334078198966, 0.023365592894914095, 0.0038118531826364442, 0.030222670692606222, 0.018459702020606223, 0.012446836119472695, 0.0078675365561387371, 0.10174756978334633, 0.98337484826799615, 0.049630565456708103, 0.018736949428497369, 0.0089037251239966527, 0.11043951740044509, 0.16115698702245179, 0.83050923475532157, 0.0046232500626165393, 0.35884331752546073, 0.055228916231300183, 0.026219820943258299, 0.052347501422618931, 0.010694751138739673, 0.13904278648577634, 0.0055494638379540362, 0.87360261302840325, 0.31837738894545509, 0.012271956011031706, 0.012743805280238132, 0.10424048529048535, 0.24059184308237672, 0.20364766410953178, 0.030340175023312359, 0.97420676435926812, 0.078262300716304176, 0.051600446816794349, 0.0015827245356934776, 0.011086718886398257, 0.016358882843180454, 0.60473219476845297, 0.017234484133515447, 0.068915508325020858, 0.00074582339984994737, 0.26096027548352901, 0.9999976303002367, 0.072901018296314943, 0.96871854743916264, 0.37201072407223706, 0.0038618411014151471, 0.0374978866265799, 0.43266264919130504, 0.034922310123493221, 0.09476634261594058, 0.20940163924623059, 0.96763216931374585, 0.013313271623050255, 0.99999999999874944, 0.9999826399761339, 0.0024304804889023045, 0.012549933119762937, 0.0048291013193277133, 0.0072371521292837878, 0.012413037142794285, 0.010146981633569901, 0.25079815537424621, 0.12929016272851418, 0.054801262388397907, 0.7988361003969674, 0.020532323980185074, 0.072971003382042779, 0.01394598921902019, 0.0059171476866105481, 0.0018321569240709302, 0.10841662353109546, 0.0039685581188235591, 0.11640037447305444, 0.0025405890979128981, 0.98318940270825939, 0.093120565233534874, 0.036236484066335506, 0.012559476484006115, 0.18375449304149907, 0.013465628628328064, 0.00010695097735150086, 0.52314351358066924, 0.074831916999617068, 0.35042590321382522, 0.12247318076727204, 0.0048921602968023011, 0.3667143857234284, 0.44193237761117371, 0.093686594693746794, 0.0016242661026093078, 0.31876213979812312, 0.29572090487783731, 0.051741561666415491, 0.15638002269939769, 0.003979921885950726, 0.0036659615095299461, 0.0034507809870747402, 0.65290915246322012, 0.023343584132510704, 0.02024681497095826, 0.00044427885450052887, 0.028435466134134897, 0.1250280962553402, 0.051075379127170153, 0.011863427170643133, 0.021380108396751585, 0.18143416229578904, 0.60492651184706425, 0.46701903121492172, 0.012393036836524164, 0.0094094679630512459, 0.19567173707774835, 0.03703759034841568, 0.97417167739681598, 0.99990941532947919, 0.013054375839857158, 0.002453403147000292, 0.29363351662765402, 0.0083236545894529064, 0.018116747083634813, 0.11121039459430947, 0.015785717103687088, 0.087923899312348605, 0.0072296823521719143, 0.50302832641713902, 0.013199656705682218, 0.0069826775167833649, 8.474887177138694e-05, 0.5216865730095398, 0.12659345739426928, 0.079620763677979253, 0.84818832314817749, 0.0027953270119319847, 0.69646000727551083, 0.044220971331781676, 0.034511076401987237, 0.85929092876778168, 0.1607486252871167, 0.0075066420337509855, 0.19283649124896302, 0.12070605505536443, 0.037674756513665052, 0.0063998949687832114, 0.051378444400772966, 0.00037459191829578454, 0.0046785539255567036, 0.13927948543045474, 0.48866357126763599, 0.0019728656558821952, 0.017376862208299447, 0.1344301771797507, 0.99897403424776987, 0.0093481274716409428, 0.016080788996160552, 0.093828242575702145, 0.75587024597975139, 0.13233831964647344, 0.051557670762246245, 0.012066755508276546, 0.041269632050749849] \n",
      " [1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0\n",
      " 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1\n",
      " 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1\n",
      " 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
      " 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1\n",
      " 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1\n",
      " 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0\n",
      " 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0\n",
      " 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1\n",
      " 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1\n",
      " 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0\n",
      " 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "clasificador=Clasificador2()\n",
    "predict, proba, humor_prob=clasificador.predict_median(\"corpus_filtro5_devset_c2.csv\")\n",
    "print(predict, \"\\n\", proba, \"\\n\", humor_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador3()\n",
    "print(clasificador.predict_clasiffier_1(\"corpus_filtro5_devset_c3.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "corpus_filtro5_devset = pandas.read_csv(\"corpus_filtro5_devset.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c2 = pandas.read_csv(\"corpus_filtro5_devset_c2.csv\",encoding='utf-8')\n",
    "corpus_filtro5_devset_c3 = pandas.read_csv(\"corpus_filtro5_devset_c3.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 1\n",
    "list_cat_1 = []\n",
    "list_ecat_1 = []\n",
    "\n",
    "\n",
    "list_cat_1=corpus_filtro5_devset['category'][:]\n",
    "\n",
    "clasificador = Clasificador1()\n",
    "list_ecat_1  = clasificador.predict_clasiffier_1(\"corpus_filtro5_devset.csv\")\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 2\n",
    "list_cat_2 = []\n",
    "list_ecat_2 = []\n",
    "list_edem_2=[]\n",
    "\n",
    "\n",
    "list_cat_2=corpus_filtro5_devset_c2['category'][:]\n",
    "clasificador2=Clasificador2()\n",
    "list_emed_2, _, list_ecat_2=clasificador2.predict_median(\"corpus_filtro5_devset_c2.csv\")\n",
    "\n",
    "\n",
    "#Lista de categorias del cuerpo de desarrollo\n",
    "#y de categorias estimadas sobre dicho cuerpo\n",
    "#para el clasificador 3\n",
    "list_cat_3 = []\n",
    "list_ecat_3 = []\n",
    "\n",
    "list_cat_3=corpus_filtro5_devset_c3['category'][:]\n",
    "clasificador3 = Clasificador3()\n",
    "list_ecat_3=clasificador3.predict_clasiffier_1(\"corpus_filtro5_devset_c3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas para el clasificador 1\n",
      "Precision:  0.7427745664739884\n",
      "Recall:  0.803125\n",
      "Accuracy  0.5492063492063493\n",
      "E-measure  0.7717717717717717\n",
      "Medidas para el clasificador 2\n",
      "Precision:  0.7680722891566265\n",
      "Recall:  0.7634730538922155\n",
      "Accuracy  0.5363489499192245\n",
      "E-measure  0.7657657657657657\n",
      "Medidas para el clasificador 3\n",
      "Precision:  0.8198970840480274\n",
      "Recall:  0.9676113360323887\n",
      "Accuracy  0.9313099041533547\n",
      "E-measure  0.8876508820798514\n",
      "Predicter Median 1\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 0 \t|\t 0 \t|\n",
      "system negative|\t 68 \t|\t 551 \t|\n",
      "Cant calculate Presicion, division by zero\n",
      "Cant calculate Recall, division by zero\n",
      "Predicter Median 2\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 2 \t|\n",
      "system negative|\t 78 \t|\t 537 \t|\n",
      "Presicion  0.5\n",
      "Recall  0.025\n",
      "Accuracy  0.006462035541195477\n",
      "E-measure  0.047619047619047616\n",
      "Predicter Median 3\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 7 \t|\t 17 \t|\n",
      "system negative|\t 140 \t|\t 455 \t|\n",
      "Presicion  0.2916666666666667\n",
      "Recall  0.047619047619047616\n",
      "Accuracy  0.03877221324717286\n",
      "E-measure  0.08187134502923976\n",
      "Predicter Median 4\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 12 \t|\n",
      "system negative|\t 108 \t|\t 497 \t|\n",
      "Presicion  0.14285714285714285\n",
      "Recall  0.01818181818181818\n",
      "Accuracy  0.022617124394184167\n",
      "E-measure  0.032258064516129024\n",
      "Predicter Median 5\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 2 \t|\t 1 \t|\n",
      "system negative|\t 74 \t|\t 542 \t|\n",
      "Presicion  0.6666666666666666\n",
      "Recall  0.02631578947368421\n",
      "Accuracy  0.004846526655896607\n",
      "E-measure  0.05063291139240506\n",
      "Predicter Median 0\n",
      "\t\t gold positive  | gold negative\n",
      "system positive|\t 24 \t|\t 13 \t|\n",
      "system negative|\t 114 \t|\t 468 \t|\n",
      "Presicion  0.6486486486486487\n",
      "Recall  0.17391304347826086\n",
      "Accuracy  0.05977382875605816\n",
      "E-measure  0.2742857142857143\n",
      "Confusion matrix\n",
      "\t 0 \t 1 \t 2 \t 3 \t 4 \t 5 \n",
      "0 \t 24 \t 2 \t 3 \t 3 \t 1 \t 4\n",
      "1 \t 0 \t 0 \t 0 \t 0 \t 0 \t 0\n",
      "2 \t 1 \t 0 \t 2 \t 0 \t 0 \t 1\n",
      "3 \t 0 \t 4 \t 2 \t 7 \t 7 \t 4\n",
      "4 \t 2 \t 0 \t 1 \t 6 \t 2 \t 3\n",
      "5 \t 0 \t 0 \t 0 \t 0 \t 1 \t 2\n"
     ]
    }
   ],
   "source": [
    "#Variables para clasificador 1\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_1) ):\n",
    "    if(list_cat_1[i] == 1 and list_ecat_1[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_1[i] == 1 and list_ecat_1[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_1[i] == 0 and list_ecat_1[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 1\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 2\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_2) ):\n",
    "    if(list_cat_2[i] == 1 and list_ecat_2[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_2[i] == 1 and list_ecat_2[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_2[i] == 0 and list_ecat_2[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "\n",
    "print(\"Medidas para el clasificador 2\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para el clasificador 3\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for i in range( len(list_cat_3) ):\n",
    "    if(list_cat_3[i] == 1 and list_ecat_3[i]==1):\n",
    "        tp+=1\n",
    "    elif(list_cat_3[i] == 1 and list_ecat_3[i]==0):\n",
    "        fn+=1\n",
    "    elif(list_cat_3[i] == 0 and list_ecat_3[i]==1):\n",
    "        fp+=1\n",
    "    else:\n",
    "        tn+=1\n",
    "\n",
    "p = tp/(tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "print(\"Medidas para el clasificador 3\")\n",
    "print(\"Precision: \", p )\n",
    "print(\"Recall: \", r)\n",
    "print(\"Accuracy \", (tp + fp) / (tp + fp + tn + fn))\n",
    "print(\"E-measure \", 2*p*r/(p + r))\n",
    "\n",
    "\n",
    "#Variables para las medianas\n",
    "tp_m1=0\n",
    "fp_m1=0\n",
    "tn_m1=0\n",
    "fn_m1=0\n",
    "\n",
    "tp_m2=0\n",
    "fp_m2=0\n",
    "tn_m2=0\n",
    "fn_m2=0\n",
    "\n",
    "tp_m3=0\n",
    "fp_m3=0\n",
    "tn_m3=0\n",
    "fn_m3=0\n",
    "\n",
    "tp_m4=0\n",
    "fp_m4=0\n",
    "tn_m4=0\n",
    "fn_m4=0\n",
    "\n",
    "tp_m5=0\n",
    "fp_m5=0\n",
    "tn_m5=0\n",
    "fn_m5=0\n",
    "\n",
    "tp_m0=0\n",
    "fp_m0=0\n",
    "tn_m0=0\n",
    "fn_m0=0\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c1) ):\n",
    "    if(clasificador2.median_list_c1[i] == 1 and clasificador2.c1_predict[i]==1):\n",
    "        tp_m1+=1\n",
    "    elif(clasificador2.median_list_c1[i] == 1 and clasificador2.c1_predict[i]==0):\n",
    "        fn_m1+=1\n",
    "    elif(clasificador2.median_list_c1[i] == 0 and clasificador2.c1_predict[i]==1):\n",
    "        fp_m1+=1\n",
    "    else:\n",
    "        tn_m1+=1\n",
    "\n",
    "p_m1=-1\n",
    "r_m1=-1\n",
    "if(tp_m1 + fp_m1 > 0):\n",
    "    p_m1 = tp_m1/(tp_m1 + fp_m1)\n",
    "if(tp_m1 + fn_m1):\n",
    "    r_m1 = tp_m1 / (tp_m1 + fn_m1)\n",
    "\n",
    "print(\"Predicter Median 1\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m1,\"\\t|\\t\", fp_m1, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m1, \"\\t|\\t\", tn_m1, \"\\t|\")\n",
    "if p_m1 > 0:\n",
    "    print(\"Presicion \", p_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m1 > 0:\n",
    "    print(\"Recall \", r_m1)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m1 > 0 and r_m1 > 0):\n",
    "    print(\"Accuracy \", (tp_m1 + fp_m1) / (tp_m1 + fp_m1 + tn_m1 + fn_m1))\n",
    "    print(\"E-measure \", 2*p_m1*r_m1/(p_m1 + r_m1))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c2) ):\n",
    "    if(clasificador2.median_list_c2[i] == 1 and clasificador2.c2_predict[i]==1):\n",
    "        tp_m2+=1\n",
    "    elif(clasificador2.median_list_c2[i] == 1 and clasificador2.c2_predict[i]==0):\n",
    "        fn_m2+=1\n",
    "    elif(clasificador2.median_list_c2[i] == 0 and clasificador2.c2_predict[i]==1):\n",
    "        fp_m2+=1\n",
    "    else:\n",
    "        tn_m2+=1\n",
    "\n",
    "p_m2=-1\n",
    "r_m2=-1\n",
    "if(tp_m2 + fp_m2 > 0):\n",
    "    p_m2 = tp_m2/(tp_m2 + fp_m2)\n",
    "if(tp_m2 + fn_m2):\n",
    "    r_m2 = tp_m2 / (tp_m2 + fn_m2)\n",
    "\n",
    "print(\"Predicter Median 2\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m2,\"\\t|\\t\", fp_m2, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m2, \"\\t|\\t\", tn_m2, \"\\t|\")\n",
    "if p_m2 > 0:\n",
    "    print(\"Presicion \", p_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m2 > 0:\n",
    "    print(\"Recall \", r_m2)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m2 > 0 and r_m2 > 0):\n",
    "    print(\"Accuracy \", (tp_m2 + fp_m2) / (tp_m2 + fp_m2 + tn_m2 + fn_m2))\n",
    "    print(\"E-measure \", 2*p_m2*r_m2/(p_m2 + r_m2))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c3) ):\n",
    "    if(clasificador2.median_list_c3[i] == 1 and clasificador2.c3_predict[i]==1):\n",
    "        tp_m3+=1\n",
    "    elif(clasificador2.median_list_c3[i] == 1 and clasificador2.c3_predict[i]==0):\n",
    "        fn_m3+=1\n",
    "    elif(clasificador2.median_list_c3[i] == 0 and clasificador2.c3_predict[i]==1):\n",
    "        fp_m3+=1\n",
    "    else:\n",
    "        tn_m3+=1\n",
    "\n",
    "p_m3=-1\n",
    "r_m3=-1\n",
    "if(tp_m3 + fp_m3 > 0):\n",
    "    p_m3 = tp_m3/(tp_m3 + fp_m3)\n",
    "if(tp_m3 + fn_m3):\n",
    "    r_m3 = tp_m3 / (tp_m3 + fn_m3)\n",
    "\n",
    "print(\"Predicter Median 3\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m3,\"\\t|\\t\", fp_m3, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m3, \"\\t|\\t\", tn_m3, \"\\t|\")\n",
    "if p_m3 > 0:\n",
    "    print(\"Presicion \", p_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m3 > 0:\n",
    "    print(\"Recall \", r_m3)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m3 > 0 and r_m3 > 0):\n",
    "    print(\"Accuracy \", (tp_m3 + fp_m3) / (tp_m3 + fp_m3 + tn_m3 + fn_m3))\n",
    "    print(\"E-measure \", 2*p_m3*r_m3/(p_m3 + r_m3))\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c4) ):\n",
    "    if(clasificador2.median_list_c4[i] == 1 and clasificador2.c4_predict[i]==1):\n",
    "        tp_m4+=1\n",
    "    elif(clasificador2.median_list_c4[i] == 1 and clasificador2.c4_predict[i]==0):\n",
    "        fn_m4+=1\n",
    "    elif(clasificador2.median_list_c4[i] == 0 and clasificador2.c4_predict[i]==1):\n",
    "        fp_m4+=1\n",
    "    else:\n",
    "        tn_m4+=1\n",
    "\n",
    "p_m4=-1\n",
    "r_m4=-1\n",
    "if(tp_m4 + fp_m4 > 0):\n",
    "    p_m4 = tp_m4/(tp_m4 + fp_m4)\n",
    "if(tp_m4 + fn_m4):\n",
    "    r_m4 = tp_m4 / (tp_m4 + fn_m4)\n",
    "\n",
    "print(\"Predicter Median 4\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m4,\"\\t|\\t\", fp_m4, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m4, \"\\t|\\t\", tn_m4, \"\\t|\")\n",
    "if p_m4 > 0:\n",
    "    print(\"Presicion \", p_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m4 > 0:\n",
    "    print(\"Recall \", r_m4)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m4 > 0 and r_m4 > 0):\n",
    "    print(\"Accuracy \", (tp_m4 + fp_m4) / (tp_m4 + fp_m4 + tn_m4 + fn_m4))\n",
    "    print(\"E-measure \", 2*p_m4*r_m4/(p_m4 + r_m4))\n",
    "\n",
    "\n",
    "for i in range( len(clasificador2.median_list_c5) ):\n",
    "    if(clasificador2.median_list_c5[i] == 1 and clasificador2.c5_predict[i]==1):\n",
    "        tp_m5+=1\n",
    "    elif(clasificador2.median_list_c5[i] == 1 and clasificador2.c5_predict[i]==0):\n",
    "        fn_m5+=1\n",
    "    elif(clasificador2.median_list_c5[i] == 0 and clasificador2.c5_predict[i]==1):\n",
    "        fp_m5+=1\n",
    "    else:\n",
    "        tn_m5+=1\n",
    "\n",
    "p_m5=-1\n",
    "r_m5=-1\n",
    "if(tp_m5 + fp_m5 > 0):\n",
    "    p_m5 = tp_m5/(tp_m5 + fp_m5)\n",
    "if(tp_m5 + fn_m5):\n",
    "    r_m5 = tp_m5 / (tp_m5 + fn_m5)\n",
    "\n",
    "print(\"Predicter Median 5\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m5,\"\\t|\\t\", fp_m5, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m5, \"\\t|\\t\", tn_m5, \"\\t|\")\n",
    "if p_m5 > 0:\n",
    "    print(\"Presicion \", p_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m5 > 0:\n",
    "    print(\"Recall \", r_m5)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m5 > 0 and r_m5 > 0):\n",
    "    print(\"Accuracy \", (tp_m5 + fp_m5) / (tp_m5 + fp_m5 + tn_m5 + fn_m5))\n",
    "    print(\"E-measure \", 2*p_m5*r_m5/(p_m5 + r_m5))\n",
    "    \n",
    "for i in range( len(clasificador2.median_list_c0) ):\n",
    "    if(clasificador2.median_list_c0[i] == 1 and clasificador2.c0_predict[i]==1):\n",
    "        tp_m0+=1\n",
    "    elif(clasificador2.median_list_c0[i] == 1 and clasificador2.c0_predict[i]==0):\n",
    "        fn_m0+=1\n",
    "    elif(clasificador2.median_list_c0[i] == 0 and clasificador2.c0_predict[i]==1):\n",
    "        fp_m0+=1\n",
    "    else:\n",
    "        tn_m0+=1\n",
    "\n",
    "p_m0=-1\n",
    "r_m0=-1\n",
    "if(tp_m0 + fp_m0 > 0):\n",
    "    p_m0 = tp_m0/(tp_m0 + fp_m0)\n",
    "if(tp_m0 + fn_m0):\n",
    "    r_m0 = tp_m0 / (tp_m0 + fn_m0)\n",
    "\n",
    "print(\"Predicter Median 0\")\n",
    "print(\"\\t\\t gold positive  | gold negative\")\n",
    "print(\"system positive|\\t\", tp_m0,\"\\t|\\t\", fp_m0, \"\\t|\")\n",
    "print(\"system negative|\\t\", fn_m0, \"\\t|\\t\", tn_m0, \"\\t|\")\n",
    "if p_m0 > 0:\n",
    "    print(\"Presicion \", p_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Presicion, division by zero\")\n",
    "if r_m0 > 0:\n",
    "    print(\"Recall \", r_m0)\n",
    "else:\n",
    "    print(\"Cant calculate Recall, division by zero\")\n",
    "if(p_m0 > 0 and r_m0 > 0):\n",
    "    print(\"Accuracy \", (tp_m0 + fp_m0) / (tp_m0 + fp_m0 + tn_m0 + fn_m0))\n",
    "    print(\"E-measure \", 2*p_m0*r_m0/(p_m0 + r_m0))\n",
    "    \n",
    "print(\"Confusion matrix\")\n",
    "print(\"\\t 0 \\t 1 \\t 2 \\t 3 \\t 4 \\t 5 \")\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c0_predict)):\n",
    "    if(clasificador2.c0_predict[pos] == 1 and clasificador2.median_list_c0[pos] == 0):\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"0 \\t\", tp_m0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c1_predict)):\n",
    "    if(clasificador2.c1_predict[pos] == 1 and clasificador2.median_list_c1[pos] == 0):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"1 \\t\", conf0, \"\\t\", tp_m1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c2_predict)):\n",
    "    if(clasificador2.c2_predict[pos] == 1 and clasificador2.median_list_c2[pos] == 0):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"2 \\t\", conf0, \"\\t\", conf1, \"\\t\", tp_m2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c3_predict)):\n",
    "    if(clasificador2.c3_predict[pos] == 1 and clasificador2.median_list_c3[pos] == 0):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"3 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", tp_m3, \"\\t\", conf4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c4_predict)):\n",
    "    if(clasificador2.c4_predict[pos] == 1 and clasificador2.median_list_c4[pos] == 0):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 5):\n",
    "            conf5+=1\n",
    "print(\"4 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", tp_m4,\"\\t\", conf5);\n",
    "\n",
    "conf0=0\n",
    "conf1=0\n",
    "conf2=0\n",
    "conf3=0\n",
    "conf4=0\n",
    "conf5=0\n",
    "\n",
    "\n",
    "for pos in range(len(clasificador2.c5_predict)):\n",
    "    if(clasificador2.c5_predict[pos] == 1 and clasificador2.median_list_c5[pos] == 0):\n",
    "        if(medians[pos] == 0):\n",
    "            conf0+=1\n",
    "        if(medians[pos] == 1):\n",
    "            conf1+=1\n",
    "        if(medians[pos] == 2):\n",
    "            conf2+=1\n",
    "        if(medians[pos] == 3):\n",
    "            conf3+=1\n",
    "        if(medians[pos] == 4):\n",
    "            conf4+=1\n",
    "print(\"5 \\t\", conf0, \"\\t\", conf1, \"\\t\", conf2,\"\\t\", conf3, \"\\t\", conf4,\"\\t\", tp_m5);\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
